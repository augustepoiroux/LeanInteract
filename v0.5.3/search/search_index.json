{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LeanInteract","text":"<p>LeanInteract is a Python package designed to seamlessly interact with Lean 4 through the Lean REPL.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd17 Interactivity: Execute Lean code and files directly from Python</li> <li>\ud83d\ude80 Ease of Use: LeanInteract abstracts the complexities of Lean setup and interaction</li> <li>\ud83d\udcbb Cross-platform: Works on Windows, macOS, and Linux operating systems</li> <li>\ud83d\udd27 Compatibility: Supports all Lean versions between <code>v4.7.0-rc1</code> and <code>v4.19.0</code></li> <li>We backport the latest features of Lean REPL to older versions of Lean</li> <li>\ud83d\udce6 Temporary Projects: Easily instantiate temporary Lean environments</li> <li>Useful for experimenting with benchmarks depending on Mathlib like ProofNet# and MiniF2F</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#install-the-package","title":"Install the package","text":"<pre><code>pip install lean-interact\n</code></pre>"},{"location":"#start-using-it-in-your-python-scripts","title":"Start using it in your Python scripts","text":"<pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Create a configuration for the Lean REPL\nconfig = LeanREPLConfig(verbose=True)  \n\n# Start the Lean server\nserver = LeanServer(config)  \n\n# Run a simple Lean theorem\nresponse = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\nprint(response)\n</code></pre> <pre><code>\u2714 [2/22] Built REPL.Util.Pickle\n\n\n\u2714 [3/22] Built REPL.Frontend\n\u2714 [4/22] Built REPL.Util.Pickle:c.o\n\n\n\u2714 [5/22] Built REPL.Lean.Environment\n\u2714 [6/22] Built REPL.Util.Path\n\u2714 [7/22] Built REPL.Lean.ContextInfo\n\n\n\u2714 [8/22] Built REPL.Util.Path:c.o\n\u2714 [9/22] Built REPL.Lean.ContextInfo:c.o\n\u2714 [10/22] Built REPL.Frontend:c.o\n\u2714 [11/22] Built REPL.Lean.Environment:c.o\n\n\n\u2714 [12/22] Built REPL.Lean.InfoTree\n\n\n\u2714 [13/22] Built REPL.JSON\n\n\n\u2714 [14/22] Built REPL.Snapshots\n\u2714 [15/22] Built REPL.Lean.InfoTree.ToJson\n\n\n\u2714 [16/22] Built REPL.Lean.InfoTree.ToJson:c.o\n\n\n\u2714 [17/22] Built REPL.Lean.InfoTree:c.o\n\u2714 [18/22] Built REPL.JSON:c.o\n\n\n\u2714 [19/22] Built REPL.Main\n\n\n\u2714 [20/22] Built REPL.Snapshots:c.o\n\n\n\u2714 [21/22] Built REPL.Main:c.o\n\n\n\u2714 [22/22] Built repl\nBuild completed successfully.\nCommandResponse(messages=[Message(severity='info', start_pos=Pos(line=1, column=0), data='Goals accomplished!', end_pos=Pos(line=1, column=42))], env=0)\n</code></pre> <p>Check out the Installation guide for setup instructions and the User Guide for detailed usage examples.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>This page documents the notable changes to LeanInteract.</p>"},{"location":"changelog/#v053-may-18-2025","title":"v0.5.3 (May 18, 2025)","text":""},{"location":"changelog/#whats-changed","title":"What's Changed","text":"<ul> <li>Add optional build boolean for LocalProject by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/16</li> <li>Slightly improve sorry detection in <code>lean_code_is_valid</code> by checking <code>message</code> instead of just <code>sorries</code> in REPL output.</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.2...v0.5.3</p>"},{"location":"changelog/#v052-may-01-2025","title":"v0.5.2 (May 01, 2025)","text":"<p>Introduce compatibility with Lean v4.19.0</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.1...v0.5.2</p>"},{"location":"changelog/#v051-april-30-2025","title":"v0.5.1 (April 30, 2025)","text":""},{"location":"changelog/#whats-changed_1","title":"What's Changed","text":"<ul> <li>Add fix for non-respected timeout by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/13</li> <li>Query Lake cache for all Project types by @habemus-papadum in https://github.com/augustepoiroux/LeanInteract/pull/10</li> <li>Bump REPL version to v1.0.7 fixing <code>\"auxiliary declaration cannot be created when declaration name is not available\"</code> in tactic mode for Lean &lt;= v4.18.0 https://github.com/leanprover-community/repl/issues/44#issuecomment-2814069261</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.0...v0.5.1</p>"},{"location":"changelog/#v050-april-21-2025","title":"v0.5.0 (April 21, 2025)","text":""},{"location":"changelog/#whats-changed_2","title":"What's Changed","text":"<ul> <li>Make LeanInteract cross-platform by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/4</li> <li>Fix infotree parsing issue by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/1</li> <li>Implement <code>async_run</code> + make calls to the REPL thread-safe by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/2</li> </ul>"},{"location":"changelog/#v041-april-18-2025","title":"v0.4.1 (April 18, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.4.0...v0.4.1</p>"},{"location":"changelog/#v040-april-11-2025","title":"v0.4.0 (April 11, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.3...v0.4.0</p>"},{"location":"changelog/#v033-april-04-2025","title":"v0.3.3 (April 04, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.2...v0.3.3</p>"},{"location":"changelog/#v032-april-03-2025","title":"v0.3.2 (April 03, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.1...v0.3.2</p>"},{"location":"changelog/#v031-april-02-2025","title":"v0.3.1 (April 02, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.0...v0.3.1</p>"},{"location":"changelog/#v030-april-02-2025","title":"v0.3.0 (April 02, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.2.0...v0.3.0</p>"},{"location":"changelog/#v020-march-18-2025","title":"v0.2.0 (March 18, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/commits/v0.2.0</p>"},{"location":"changelog/#pre-release-development","title":"Pre-release Development","text":"<p>For development history prior to the first release, please see the GitHub commit history.</p>"},{"location":"contributing/","title":"Contributing to LeanInteract","text":"<p>Contributions to LeanInteract are welcome and appreciated! This guide will help you understand how you can contribute to the project.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Clone your fork to your local machine.</li> <li>Create a feature branch: <code>git checkout -b feature-name</code></li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>Install the package in development mode:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#code-style-and-guidelines","title":"Code Style and Guidelines","text":"<ul> <li>Use ruff for code formatting.</li> <li>Write descriptive docstrings.</li> <li>Include type hints where appropriate.</li> <li>Follow the existing code structure.</li> <li>Write unit tests for new features.</li> </ul>"},{"location":"contributing/#submitting-contributions","title":"Submitting Contributions","text":"<ol> <li>Commit your changes: <code>git commit -am 'Add new feature'</code></li> <li>Push to your branch: <code>git push origin feature-name</code></li> <li>Submit a pull request to the main repository.</li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Describe your changes clearly and concisely.</li> <li>Link to any relevant issues using the # symbol (e.g., #42).</li> <li>Ensure your code passes all tests.</li> <li>Include tests for new features or bug fixes.</li> </ul>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code>python -m unittest discover -s ./tests\n</code></pre>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":"<p>You can build and preview the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>This will start a local web server at http://127.0.0.1:8000/ where you can preview the documentation as you make changes.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you find a bug or would like to request a feature:</p> <ol> <li>Check if the issue already exists in the GitHub issues.</li> <li>If not, create a new issue with a clear description and, if applicable, steps to reproduce.</li> </ol>"},{"location":"contributing/#contact","title":"Contact","text":"<p>If you have questions about contributing, feel free to contact the maintainer at auguste.poiroux@epfl.ch.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please be respectful and inclusive when contributing to this project. Harassment or abusive behavior will not be tolerated.</p> <p>Thank you for contributing to LeanInteract!</p>"},{"location":"examples/","title":"Examples","text":"<p>This page provides practical examples of using LeanInteract in different scenarios. You can find the full examples in the <code>examples</code> directory of the repository.</p>"},{"location":"examples/#basic-theorem-proving","title":"Basic Theorem Proving","text":"<p>This example demonstrates how to define a simple theorem with a partial proof in Lean using LeanInteract:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Initialize configuration and server\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Define a simple theorem\nserver.run(Command(cmd=\"\"\"\ntheorem add_comm (a b : Nat) : a + b = b + a := by\n  induction a with\n  | zero =&gt; simp\n  | succ a ih =&gt; sorry\n\"\"\"))\n</code></pre> <pre><code>CommandResponse(messages=[Message(start_pos=Pos(line=2, column=8), severity='warning', end_pos=Pos(line=2, column=16), data=\"declaration uses 'sorry'\")], sorries=[Sorry(start_pos=Pos(line=5, column=17), goal='case succ\\nb a : Nat\\nih : a + b = b + a\\n\u22a2 a + 1 + b = b + (a + 1)', proof_state=0, end_pos=Pos(line=5, column=22))], env=0)\n</code></pre>"},{"location":"examples/#working-with-mathlib","title":"Working with Mathlib","text":"<p>This example shows how to use Mathlib to work with more advanced mathematical concepts:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command, TempRequireProject\n\n# Create configuration with Mathlib\nconfig = LeanREPLConfig(\n    lean_version=\"v4.19.0\", \n    project=TempRequireProject(\"mathlib\")\n)\nserver = LeanServer(config)\n\n# Define a theorem using Mathlib's real numbers\nserver.run(Command(cmd=\"\"\"\nimport Mathlib\n\ntheorem irrational_plus_rational \n  (x : \u211d) (y : \u211a) : Irrational x \u2192 Irrational (x + y) := by\n  intro h\n  simp\n  assumption\n\"\"\"))\n</code></pre> <pre><code>CommandResponse(messages=[Message(start_pos=Pos(line=4, column=0), severity='info', end_pos=Pos(line=8, column=12), data='Goals accomplished!')], env=0)\n</code></pre>"},{"location":"examples/#real-world-examples","title":"Real-World Examples","text":"<p>For more comprehensive examples, check out the following scripts in the examples directory:</p> <ol> <li> <p>proof_generation_and_autoformalization.py    Shows how to use models like DeepSeek-Prover-V1.5 and Goedel-Prover on MiniF2F and ProofNet# benchmarks.</p> </li> <li> <p>beq_plus.py    Demonstrates how to run the autoformalization BEq+ metric on the ProofNetVerif benchmark.</p> </li> <li> <p>type_check.py    Shows how to optimize type checking using environment states.</p> </li> </ol>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing LeanInteract, ensure you have the following prerequisites:</p> <ul> <li>Python 3.10 or newer</li> <li>Git (for Lean installation)</li> <li>Lean 4 (optional - LeanInteract can install it for you)</li> </ul> <p>Your system should be one of:</p> <ul> <li>Windows</li> <li>macOS</li> <li>Linux</li> </ul>"},{"location":"installation/#installation-steps","title":"Installation Steps","text":""},{"location":"installation/#1-install-the-package","title":"1. Install the Package","text":"<p>You can install LeanInteract directly from PyPI:</p> <pre><code>pip install lean-interact\n</code></pre>"},{"location":"installation/#2-install-lean-4-if-not-already-installed","title":"2. Install Lean 4 (if not already installed)","text":"<p>LeanInteract provides a convenient command to install Lean 4 via the Elan version manager:</p> <pre><code>install-lean\n</code></pre> <p>This command will install Elan, which manages Lean versions. Your Elan version should be at least 4.0.0.</p>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>You can verify that LeanInteract is properly installed by running a simple Python script:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Create a configuration\nconfig = LeanREPLConfig(verbose=True)\n\n# Initialize the server\nserver = LeanServer(config)\n\n# Execute a simple Lean command\nresponse = server.run(Command(cmd=\"#eval 2 + 2\"))\nprint(response)\n</code></pre> <pre><code>Build completed successfully.\nCommandResponse(env=0, messages=[Message(severity='info', data='4', end_pos=Pos(line=1, column=5), start_pos=Pos(line=1, column=0))])\n</code></pre> <p>If everything is set up correctly, the script should output a successful response.</p> <p>Note</p> <p>The first time you run LeanInteract, it might take some time as it downloads and builds Lean REPL. Subsequent runs will be significantly faster due to caching.</p>"},{"location":"installation/#system-specific-notes","title":"System-Specific Notes","text":""},{"location":"installation/#windows","title":"Windows","text":"<p>On Windows, you might encounter path length limitations. If you get an error related to path length, you can enable long paths in Windows 10 and later versions by running the following command in an administrator PowerShell:</p> <pre><code>New-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" -Name LongPathsEnabled -Value 1 -PropertyType DWord -Force\ngit config --system core.longpaths true\n</code></pre> <p>For more information, refer to the Microsoft documentation.</p>"},{"location":"installation/#docker","title":"Docker","text":"<p>If you're using LeanInteract in a Docker container, make sure to include Git in your container and have sufficient memory allocated, especially if you're working with Mathlib.</p>"},{"location":"installation/#uninstallation","title":"Uninstallation","text":"<p>If you need to clear the LeanInteract cache (for troubleshooting or disk space reasons), you can use:</p> <pre><code>clear-lean-cache\n</code></pre> <p>To completely uninstall:</p> <pre><code>pip uninstall lean-interact\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This guide covers common issues you might encounter when using LeanInteract.</p>"},{"location":"troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"troubleshooting/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Symptoms:</p> <ul> <li>The application crashes with memory-related errors</li> <li>Python process is killed by the operating system</li> <li>Error messages mentioning \"MemoryError\" or \"Killed\"</li> </ul> <p>Solutions:</p> <ul> <li>Reduce parallel processing or increase system memory</li> <li>Use <code>AutoLeanServer</code> with conservative memory settings:</li> </ul> <pre><code>from lean_interact import AutoLeanServer\nserver = AutoLeanServer(config, memory_threshold_mb=1000)  # Limit to 1GB\n</code></pre> <ul> <li>Avoid working with large files or complex proofs in a single session</li> <li>Use environment pickling to save and restore states across sessions</li> </ul>"},{"location":"troubleshooting/#timeout-errors","title":"Timeout Errors","text":"<p>Symptoms:</p> <ul> <li>Commands take too long to execute</li> <li>Error messages mentioning \"TimeoutError\"</li> </ul> <p>Solutions:</p> <ul> <li>Increase the timeout in the configuration:</li> </ul> <pre><code>config = LeanREPLConfig(timeout=60)  # 60 seconds\n</code></pre> <ul> <li>Use <code>AutoLeanServer</code> for automatic recovery from timeouts:</li> </ul> <pre><code>server = AutoLeanServer(config)\n</code></pre> <ul> <li>Break complex commands into smaller, more manageable pieces</li> </ul>"},{"location":"troubleshooting/#long-waiting-times-during-first-run","title":"Long Waiting Times During First Run","text":"<p>Symptoms:</p> <ul> <li>Initial setup takes a long time</li> <li>Process seems stuck at \"Downloading\" or \"Building\"</li> </ul> <p>Solution: This is expected behavior as LeanInteract:</p> <ol> <li>Downloads and sets up the specified Lean version</li> <li>Downloads and builds Lean REPL</li> <li>If using Mathlib, downloads it and instantiates a project using it (which is resource-intensive)</li> </ol> <p>Subsequent runs will be much faster due to caching.</p>"},{"location":"troubleshooting/#lake-update-errors","title":"Lake Update Errors","text":"<p>Symptoms:</p> <ul> <li>Error: <code>Failed during Lean project setup: Command '['lake', 'update']' returned non-zero exit status 1.</code></li> </ul> <p>Solutions:</p> <ul> <li>Update your <code>elan</code> version (should be at least 4.0.0):</li> </ul> <pre><code>elan self update\n</code></pre> <ul> <li>Check your project's lake file for errors</li> <li>Ensure Git is properly installed and can access required repositories</li> </ul>"},{"location":"troubleshooting/#path-too-long-error-windows","title":"Path Too Long Error (Windows)","text":"<p>Symptoms:</p> <ul> <li>On Windows, errors related to path length limitations</li> <li>Git errors about paths exceeding 260 characters</li> </ul> <p>Solutions: Enable long paths in Windows 10/11:</p> <pre><code># Run in administrator PowerShell\nNew-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" -Name LongPathsEnabled -Value 1 -PropertyType DWord -Force\ngit config --system core.longpaths true\n</code></pre>"},{"location":"troubleshooting/#cache-issues","title":"Cache Issues","text":"<p>Symptoms:</p> <ul> <li>Unexpected behavior after upgrading LeanInteract</li> <li>Errors about incompatible versions</li> </ul> <p>Solution: Clear the LeanInteract cache:</p> <pre><code>clear-lean-cache\n</code></pre>"},{"location":"troubleshooting/#unexpected-lean-error-messages","title":"Unexpected Lean error messages","text":"<p>Symptom: LeanInteract returns error messages while the Lean code runs fine in VSCode.</p> <p>Solutions:</p> <ul> <li>Check you are using the same Lean version in both environments</li> <li>If you are creating a temporary project using LeanInteract, make sure your dependencies are correctly set and compatible with the Lean version you are using</li> <li> <p>A frequent issue is forgetting to include <code>mathlib</code> in the dependencies:</p> <pre><code>config = LeanREPLConfig(\n    lean_version=\"v4.19.0\", \n    project=TempRequireProject(\"mathlib\")\n)\n</code></pre> </li> <li> <p>Check if a similar issue for the Lean REPL has been reported</p> </li> </ul>"},{"location":"troubleshooting/#elan-is-not-recognized-as-an-internal-or-external-command","title":"\"'elan' is not recognized as an internal or external command\"","text":"<p>Symptom: Error when running LeanInteract on a new system</p> <p>Solution: Install Lean's version manager:</p> <pre><code>install-lean\n</code></pre>"},{"location":"troubleshooting/#getting-additional-help","title":"Getting Additional Help","text":"<p>If you encounter issues not covered in this guide:</p> <ol> <li>Check the GitHub repository for open issues</li> <li>Open a new issue with:</li> <li>A minimal reproducible example</li> <li>Your operating system and Python version</li> <li>LeanInteract version (<code>pip show lean-interact</code>)</li> <li>Complete error message/stack trace</li> </ol>"},{"location":"api/config/","title":"Configuration API","text":"<p>This page documents the configuration classes used to set up the Lean environment.</p>"},{"location":"api/config/#leanreplconfig","title":"LeanREPLConfig","text":""},{"location":"api/config/#lean_interact.config.LeanREPLConfig","title":"<code>lean_interact.config.LeanREPLConfig</code>","text":"Source code in <code>src/lean_interact/config.py</code> <pre><code>class LeanREPLConfig:\n    def __init__(\n        self,\n        lean_version: str | None = None,\n        project: BaseProject | None = None,\n        repl_rev: str = DEFAULT_REPL_VERSION,\n        repl_git: str = DEFAULT_REPL_GIT_URL,\n        cache_dir: str = DEFAULT_CACHE_DIR,\n        memory_hard_limit_mb: int | None = None,\n        verbose: bool = False,\n    ):\n        \"\"\"\n        Initialize the Lean REPL configuration.\n\n        Args:\n            lean_version:\n                The Lean version you want to use.\n                Default is `None`, which means the latest version compatible with the project will be selected.\n            project:\n                The project you want to use. There are 4 options:\n                - `None`: The project will only depend on Lean and its standard library.\n                - `LocalProject`: An existing local Lean project.\n                - `GitProject`: A git repository with a Lean project that will be cloned.\n                - `TemporaryProject`: A temporary Lean project with a custom lakefile.lean that will be created.\n                - `TempRequireProject`: A temporary Lean project with dependencies that will be created.\n            repl_rev:\n                The REPL version you want to use. It is not recommended to change this value unless you know what you are doing.\n            repl_git:\n                The git repository of the Lean REPL. It is not recommended to change this value unless you know what you are doing.\n            cache_dir:\n                The directory where the Lean REPL and temporary Lean projects with dependencies will be cached.\n                Default is inside the package directory.\n            memory_hard_limit_mb:\n                The maximum memory usage in MB for the Lean server. Setting this value too low may lead to more command processing failures.\n                Only available on Linux platforms.\n                Default is `None`, which means no limit.\n            verbose:\n                Whether to print additional information during the setup process.\n        \"\"\"\n        self.lean_version = lean_version\n        self.project = project\n        self.repl_git = repl_git\n        self.repl_rev = repl_rev\n        self.cache_dir = os.path.normpath(cache_dir)\n        self.memory_hard_limit_mb = memory_hard_limit_mb\n\n        self.verbose = verbose\n        self._stdout = None if self.verbose else subprocess.DEVNULL\n        self._stderr = None if self.verbose else subprocess.DEVNULL\n\n        repo_parts = self.repl_git.split(\"/\")\n        if len(repo_parts) &gt;= 2:\n            owner = repo_parts[-2]\n            repo = repo_parts[-1].replace(\".git\", \"\")\n            self.repo_name = os.path.join(owner, repo)\n        else:\n            self.repo_name = self.repl_git.replace(\".git\", \"\")\n\n        self.cache_clean_repl_dir = os.path.join(self.cache_dir, self.repo_name, \"repl_clean_copy\")\n\n        # check if lake is installed\n        if shutil.which(\"lake\") is None:\n            raise RuntimeError(\n                \"Lean 4 build system (`lake`) is not installed. You can try to run `install-lean` or find installation instructions here: https://leanprover-community.github.io/get_started.html\"\n            )\n\n        self._setup_repl()\n\n        assert isinstance(self.lean_version, str)\n\n        if self.project is None:\n            self._working_dir = self._cache_repl_dir\n        else:\n            self.project._instantiate(\n                cache_dir=self.cache_dir,\n                lean_version=self.lean_version,\n                verbose=self.verbose,\n            )\n            self._working_dir = self.project._get_directory(cache_dir=self.cache_dir, lean_version=self.lean_version)\n\n    def _setup_repl(self) -&gt; None:\n        assert isinstance(self.repl_rev, str)\n\n        # Lock the clean REPL directory during setup to prevent race conditions\n        with FileLock(f\"{self.cache_clean_repl_dir}.lock\", timeout=300):\n            # check if the repl is already cloned\n            if not os.path.exists(self.cache_clean_repl_dir):\n                os.makedirs(self.cache_clean_repl_dir, exist_ok=True)\n                Repo.clone_from(self.repl_git, self.cache_clean_repl_dir)\n\n            repo = Repo(self.cache_clean_repl_dir)\n            try:\n                repo.git.checkout(self.repl_rev)\n            except GitCommandError:\n                repo.remote().pull()\n                try:\n                    repo.git.checkout(self.repl_rev)\n                except GitCommandError as e:\n                    raise ValueError(f\"Lean REPL version `{self.repl_rev}` is not available.\") from e\n\n            # check if the Lean version is available in the repository\n            lean_versions_sha = self._get_available_lean_versions_sha()\n            lean_versions_sha_dict = dict(lean_versions_sha)\n            if not lean_versions_sha:\n                raise ValueError(\"No Lean versions are available in the Lean REPL repository.\")\n            if self.lean_version is None:\n                if self.project is None or isinstance(self.project, (TemporaryProject, TempRequireProject)):\n                    self.lean_version = lean_versions_sha[-1][0]\n                elif isinstance(self.project, (LocalProject, GitProject)):\n                    # get the Lean version from the project\n                    inferred_ver = get_project_lean_version(self.project._get_directory(self.cache_dir))\n                    self.lean_version = inferred_ver if inferred_ver else lean_versions_sha[-1][0]\n            if self.lean_version not in lean_versions_sha_dict:\n                raise ValueError(\n                    f\"Lean version `{self.lean_version}` is required but not available in the Lean REPL repository.\"\n                )\n\n        # check if the repl revision is already in the cache\n        self._cache_repl_dir = os.path.join(self.cache_dir, self.repo_name, f\"repl_{self.repl_rev}_{self.lean_version}\")\n\n        # Lock the version-specific REPL directory during setup\n        with FileLock(f\"{self._cache_repl_dir}.lock\", timeout=300):  # 5 minute timeout for long-running operations\n            if not os.path.exists(self._cache_repl_dir):\n                # copy the repository to the version directory and checkout the required revision\n                os.makedirs(self._cache_repl_dir, exist_ok=True)\n                shutil.copytree(self.cache_clean_repl_dir, self._cache_repl_dir, dirs_exist_ok=True)\n                cached_repo = Repo(self._cache_repl_dir)\n                cached_repo.git.checkout(lean_versions_sha_dict[self.lean_version])\n\n            # check that the lean version is correct\n            assert self.lean_version == get_project_lean_version(self._cache_repl_dir), (\n                f\"An error occured while preparing the Lean REPL. The requested Lean version `{self.lean_version}` \"\n                f\"does not match the fetched Lean version in the repository `{get_project_lean_version(self._cache_repl_dir)}`.\"\n                f\"Please open an issue on GitHub if you think this is a bug.\"\n            )\n\n            try:\n                subprocess.run(\n                    [\"lake\", \"build\"], cwd=self._cache_repl_dir, check=True, stdout=self._stdout, stderr=self._stderr\n                )\n            except subprocess.CalledProcessError as e:\n                logger.error(\"Failed to build the REPL: %s\", e)\n                raise\n\n    def _get_available_lean_versions_sha(self) -&gt; list[tuple[str, str]]:\n        \"\"\"\n        Get the available Lean versions for the selected REPL.\n        \"\"\"\n        repo = Repo(self.cache_clean_repl_dir)\n        return [\n            (str(commit.message.strip()), commit.hexsha)\n            for commit in repo.iter_commits(f\"{self.repl_rev}...master\")\n            if str(commit.message.strip()).startswith(\"v4\")\n        ]\n\n    def get_available_lean_versions(self) -&gt; list[str]:\n        \"\"\"\n        Get the available Lean versions for the selected REPL.\n        \"\"\"\n        return [commit[0] for commit in self._get_available_lean_versions_sha()]\n\n    @property\n    def working_dir(self) -&gt; str:\n        \"\"\"Get the working directory for the Lean environment.\"\"\"\n        return self._working_dir\n\n    @property\n    def cache_repl_dir(self) -&gt; str:\n        \"\"\"Get the cache directory for the Lean REPL.\"\"\"\n        return self._cache_repl_dir\n\n    def is_setup(self) -&gt; bool:\n        return hasattr(self, \"_working_dir\")\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.cache_repl_dir","title":"<code>cache_repl_dir</code>  <code>property</code>","text":"<p>Get the cache directory for the Lean REPL.</p>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Get the working directory for the Lean environment.</p>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.__init__","title":"<code>__init__(lean_version=None, project=None, repl_rev=DEFAULT_REPL_VERSION, repl_git=DEFAULT_REPL_GIT_URL, cache_dir=DEFAULT_CACHE_DIR, memory_hard_limit_mb=None, verbose=False)</code>","text":"<p>Initialize the Lean REPL configuration.</p> <p>Parameters:</p> Name Type Description Default <code>lean_version</code> <code>str | None</code> <p>The Lean version you want to use. Default is <code>None</code>, which means the latest version compatible with the project will be selected.</p> <code>None</code> <code>project</code> <code>BaseProject | None</code> <p>The project you want to use. There are 4 options: - <code>None</code>: The project will only depend on Lean and its standard library. - <code>LocalProject</code>: An existing local Lean project. - <code>GitProject</code>: A git repository with a Lean project that will be cloned. - <code>TemporaryProject</code>: A temporary Lean project with a custom lakefile.lean that will be created. - <code>TempRequireProject</code>: A temporary Lean project with dependencies that will be created.</p> <code>None</code> <code>repl_rev</code> <code>str</code> <p>The REPL version you want to use. It is not recommended to change this value unless you know what you are doing.</p> <code>DEFAULT_REPL_VERSION</code> <code>repl_git</code> <code>str</code> <p>The git repository of the Lean REPL. It is not recommended to change this value unless you know what you are doing.</p> <code>DEFAULT_REPL_GIT_URL</code> <code>cache_dir</code> <code>str</code> <p>The directory where the Lean REPL and temporary Lean projects with dependencies will be cached. Default is inside the package directory.</p> <code>DEFAULT_CACHE_DIR</code> <code>memory_hard_limit_mb</code> <code>int | None</code> <p>The maximum memory usage in MB for the Lean server. Setting this value too low may lead to more command processing failures. Only available on Linux platforms. Default is <code>None</code>, which means no limit.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional information during the setup process.</p> <code>False</code> Source code in <code>src/lean_interact/config.py</code> <pre><code>def __init__(\n    self,\n    lean_version: str | None = None,\n    project: BaseProject | None = None,\n    repl_rev: str = DEFAULT_REPL_VERSION,\n    repl_git: str = DEFAULT_REPL_GIT_URL,\n    cache_dir: str = DEFAULT_CACHE_DIR,\n    memory_hard_limit_mb: int | None = None,\n    verbose: bool = False,\n):\n    \"\"\"\n    Initialize the Lean REPL configuration.\n\n    Args:\n        lean_version:\n            The Lean version you want to use.\n            Default is `None`, which means the latest version compatible with the project will be selected.\n        project:\n            The project you want to use. There are 4 options:\n            - `None`: The project will only depend on Lean and its standard library.\n            - `LocalProject`: An existing local Lean project.\n            - `GitProject`: A git repository with a Lean project that will be cloned.\n            - `TemporaryProject`: A temporary Lean project with a custom lakefile.lean that will be created.\n            - `TempRequireProject`: A temporary Lean project with dependencies that will be created.\n        repl_rev:\n            The REPL version you want to use. It is not recommended to change this value unless you know what you are doing.\n        repl_git:\n            The git repository of the Lean REPL. It is not recommended to change this value unless you know what you are doing.\n        cache_dir:\n            The directory where the Lean REPL and temporary Lean projects with dependencies will be cached.\n            Default is inside the package directory.\n        memory_hard_limit_mb:\n            The maximum memory usage in MB for the Lean server. Setting this value too low may lead to more command processing failures.\n            Only available on Linux platforms.\n            Default is `None`, which means no limit.\n        verbose:\n            Whether to print additional information during the setup process.\n    \"\"\"\n    self.lean_version = lean_version\n    self.project = project\n    self.repl_git = repl_git\n    self.repl_rev = repl_rev\n    self.cache_dir = os.path.normpath(cache_dir)\n    self.memory_hard_limit_mb = memory_hard_limit_mb\n\n    self.verbose = verbose\n    self._stdout = None if self.verbose else subprocess.DEVNULL\n    self._stderr = None if self.verbose else subprocess.DEVNULL\n\n    repo_parts = self.repl_git.split(\"/\")\n    if len(repo_parts) &gt;= 2:\n        owner = repo_parts[-2]\n        repo = repo_parts[-1].replace(\".git\", \"\")\n        self.repo_name = os.path.join(owner, repo)\n    else:\n        self.repo_name = self.repl_git.replace(\".git\", \"\")\n\n    self.cache_clean_repl_dir = os.path.join(self.cache_dir, self.repo_name, \"repl_clean_copy\")\n\n    # check if lake is installed\n    if shutil.which(\"lake\") is None:\n        raise RuntimeError(\n            \"Lean 4 build system (`lake`) is not installed. You can try to run `install-lean` or find installation instructions here: https://leanprover-community.github.io/get_started.html\"\n        )\n\n    self._setup_repl()\n\n    assert isinstance(self.lean_version, str)\n\n    if self.project is None:\n        self._working_dir = self._cache_repl_dir\n    else:\n        self.project._instantiate(\n            cache_dir=self.cache_dir,\n            lean_version=self.lean_version,\n            verbose=self.verbose,\n        )\n        self._working_dir = self.project._get_directory(cache_dir=self.cache_dir, lean_version=self.lean_version)\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.get_available_lean_versions","title":"<code>get_available_lean_versions()</code>","text":"<p>Get the available Lean versions for the selected REPL.</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>def get_available_lean_versions(self) -&gt; list[str]:\n    \"\"\"\n    Get the available Lean versions for the selected REPL.\n    \"\"\"\n    return [commit[0] for commit in self._get_available_lean_versions_sha()]\n</code></pre>"},{"location":"api/config/#examples","title":"Examples","text":"<pre><code># Basic configuration with default settings\nconfig = LeanREPLConfig(verbose=True)\n\n# Configuration with specific Lean version\nconfig = LeanREPLConfig(lean_version=\"v4.19.0\", verbose=True)\n\n# Configuration with memory limits\nconfig = LeanREPLConfig(memory_hard_limit_mb=2000)\n</code></pre>"},{"location":"api/config/#project-classes","title":"Project Classes","text":""},{"location":"api/config/#baseproject","title":"BaseProject","text":""},{"location":"api/config/#lean_interact.config.BaseProject","title":"<code>lean_interact.config.BaseProject</code>  <code>dataclass</code>","text":"<p>Base class for Lean projects</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass BaseProject:\n    \"\"\"Base class for Lean projects\"\"\"\n\n    def _get_directory(self, cache_dir: str, lean_version: str | None = None) -&gt; str:\n        \"\"\"Get the project directory.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    def _instantiate(self, cache_dir: str, lean_version: str, verbose: bool = True) -&gt; None:\n        \"\"\"Instantiate the project.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api/config/#localproject","title":"LocalProject","text":""},{"location":"api/config/#lean_interact.config.LocalProject","title":"<code>lean_interact.config.LocalProject</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseProject</code></p> <p>Use an existing local Lean project directory</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass LocalProject(BaseProject):\n    \"\"\"Use an existing local Lean project directory\"\"\"\n\n    directory: str\n    build: bool = True\n\n    def _get_directory(self, cache_dir: str, lean_version: str | None = None) -&gt; str:\n        \"\"\"Get the project directory.\"\"\"\n        return self.directory\n\n    def _instantiate(self, cache_dir: str, lean_version: str, verbose: bool = True):\n        \"\"\"Instantiate the local project.\"\"\"\n        if not self.build:\n            return\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n\n        with FileLock(f\"{self.directory}.lock\"):\n            try:\n                subprocess.run(\n                    [\"lake\", \"exe\", \"cache\", \"get\"], cwd=self.directory, check=False, stdout=stdout, stderr=stderr\n                )\n                subprocess.run([\"lake\", \"build\"], cwd=self.directory, check=True, stdout=stdout, stderr=stderr)\n            except subprocess.CalledProcessError as e:\n                logger.error(\"Failed to build local project: %s\", e)\n                raise\n</code></pre>"},{"location":"api/config/#gitproject","title":"GitProject","text":""},{"location":"api/config/#lean_interact.config.GitProject","title":"<code>lean_interact.config.GitProject</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseProject</code></p> <p>Use an online git repository with a Lean project</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass GitProject(BaseProject):\n    \"\"\"Use an online git repository with a Lean project\"\"\"\n\n    url: str\n    rev: str | None = None\n\n    def _get_directory(self, cache_dir: str, lean_version: str | None = None) -&gt; str:\n        repo_parts = self.url.split(\"/\")\n        if len(repo_parts) &gt;= 2:\n            owner = repo_parts[-2]\n            repo = repo_parts[-1].replace(\".git\", \"\")\n            return os.path.join(cache_dir, \"git_projects\", owner, repo, self.rev or \"latest\")\n        else:\n            # Fallback for malformed URLs\n            repo_name = self.url.replace(\".git\", \"\").split(\"/\")[-1]\n            return os.path.join(cache_dir, \"git_projects\", repo_name, self.rev or \"latest\")\n\n    def _instantiate(self, cache_dir: str, lean_version: str, verbose: bool = True):\n        \"\"\"Instantiate the git project.\"\"\"\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n\n        project_dir = self._get_directory(cache_dir)\n\n        with FileLock(f\"{project_dir}.lock\"):\n            # check if the git repository is already cloned\n            repo = Repo(project_dir) if os.path.exists(project_dir) else Repo.clone_from(self.url, project_dir)\n\n            if self.rev:\n                repo.git.checkout(self.rev)\n            else:\n                repo.git.pull()\n\n            repo.submodule_update(init=True, recursive=True)\n\n            try:\n                subprocess.run(\n                    [\"lake\", \"exe\", \"cache\", \"get\"], cwd=project_dir, check=False, stdout=stdout, stderr=stderr\n                )\n                subprocess.run([\"lake\", \"build\"], cwd=project_dir, check=True, stdout=stdout, stderr=stderr)\n            except subprocess.CalledProcessError as e:\n                logger.error(\"Failed to build the git project: %s\", e)\n                raise\n</code></pre>"},{"location":"api/config/#basetempproject","title":"BaseTempProject","text":""},{"location":"api/config/#lean_interact.config.BaseTempProject","title":"<code>lean_interact.config.BaseTempProject</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseProject</code></p> <p>Base class for temporary Lean projects</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass BaseTempProject(BaseProject):\n    \"\"\"Base class for temporary Lean projects\"\"\"\n\n    def _get_directory(self, cache_dir: str, lean_version: str | None = None) -&gt; str:\n        if lean_version is None:\n            raise ValueError(\"`lean_version` cannot be `None`\")\n        # create a unique hash to allow for caching\n        hash_content = self._get_hash_content(lean_version)\n        tmp_project_dir = os.path.join(cache_dir, \"tmp_projects\", lean_version, hash_content)\n        os.makedirs(tmp_project_dir, exist_ok=True)\n        return tmp_project_dir\n\n    def _instantiate(self, cache_dir: str, lean_version: str, verbose: bool = True):\n        \"\"\"Instantiate the temporary project.\"\"\"\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n\n        tmp_project_dir = self._get_directory(cache_dir, lean_version)\n\n        # Lock the temporary project directory during setup\n        with FileLock(f\"{tmp_project_dir}.lock\"):\n            # check if the Lean project already exists\n            if not os.path.exists(os.path.join(tmp_project_dir, \"lake-manifest.json\")):\n                # clean the content of the folder in case of a previous aborted build\n                shutil.rmtree(tmp_project_dir, ignore_errors=True)\n                os.makedirs(tmp_project_dir, exist_ok=True)\n\n                # initialize the Lean project\n                cmd_init = [\"lake\", f\"+{lean_version}\", \"init\", \"dummy\", \"exe.lean\"]\n                if lean_version.startswith(\"v4\") and int(lean_version.split(\".\")[1]) &lt;= 7:\n                    cmd_init = [\"lake\", f\"+{lean_version}\", \"init\", \"dummy\", \"exe\"]\n\n                try:\n                    subprocess.run(cmd_init, cwd=tmp_project_dir, check=True, stdout=stdout, stderr=stderr)\n                except subprocess.CalledProcessError as e:\n                    logger.error(\"Failed to initialize Lean project: %s\", e)\n                    raise\n\n                # Create or modify the lakefile\n                self._modify_lakefile(tmp_project_dir, lean_version)\n\n                logger.info(\"Preparing Lean environment with dependencies (may take a while the first time)...\")\n\n                # Run lake commands with appropriate platform handling\n                try:\n                    subprocess.run([\"lake\", \"update\"], cwd=tmp_project_dir, check=True, stdout=stdout, stderr=stderr)\n                    # in case mathlib is used as a dependency, we try to get the cache\n                    subprocess.run(\n                        [\"lake\", \"exe\", \"cache\", \"get\"], cwd=tmp_project_dir, check=False, stdout=stdout, stderr=stderr\n                    )\n                    subprocess.run([\"lake\", \"build\"], cwd=tmp_project_dir, check=True, stdout=stdout, stderr=stderr)\n                except subprocess.CalledProcessError as e:\n                    logger.error(\"Failed during Lean project setup: %s\", e)\n                    # delete the project directory to avoid conflicts\n                    shutil.rmtree(tmp_project_dir, ignore_errors=True)\n                    raise\n\n    def _get_hash_content(self, lean_version: str) -&gt; str:\n        \"\"\"Return a unique hash for the project content.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    def _modify_lakefile(self, project_dir: str, lean_version: str) -&gt; None:\n        \"\"\"Modify the lakefile according to project needs.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api/config/#temporaryproject","title":"TemporaryProject","text":""},{"location":"api/config/#lean_interact.config.TemporaryProject","title":"<code>lean_interact.config.TemporaryProject</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseTempProject</code></p> <p>Use custom lakefile.lean content to create a temporary Lean project</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass TemporaryProject(BaseTempProject):\n    \"\"\"Use custom lakefile.lean content to create a temporary Lean project\"\"\"\n\n    content: str\n\n    def _get_hash_content(self, lean_version: str) -&gt; str:\n        \"\"\"Return a unique hash based on the content.\"\"\"\n        return hashlib.sha256(self.content.encode()).hexdigest()\n\n    def _modify_lakefile(self, project_dir: str, lean_version: str) -&gt; None:\n        \"\"\"Write the content to the lakefile.\"\"\"\n        with open(os.path.join(project_dir, \"lakefile.lean\"), \"w\", encoding=\"utf-8\") as f:\n            f.write(self.content)\n</code></pre>"},{"location":"api/config/#project-dependencies","title":"Project Dependencies","text":""},{"location":"api/config/#leanrequire","title":"LeanRequire","text":""},{"location":"api/config/#lean_interact.config.LeanRequire","title":"<code>lean_interact.config.LeanRequire</code>  <code>dataclass</code>","text":"<p>Lean project dependency</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass LeanRequire:\n    \"\"\"Lean project dependency\"\"\"\n\n    name: str\n    git: str\n    rev: str | None = None\n\n    def __hash__(self):\n        return hash((self.name, self.git, self.rev))\n</code></pre>"},{"location":"api/config/#temprequireproject","title":"TempRequireProject","text":""},{"location":"api/config/#lean_interact.config.TempRequireProject","title":"<code>lean_interact.config.TempRequireProject</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseTempProject</code></p> <p>Set up a temporary project with dependencies. As Mathlib is a common dependency, you can just set <code>require=\"mathlib\"</code> and a compatible version of mathlib will be used. This feature has been developed mostly to be able to run benchmarks using Mathlib as a dependency (such as ProofNet# or MiniF2F) without having to manually set up a Lean project.</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>@dataclass(frozen=True)\nclass TempRequireProject(BaseTempProject):\n    \"\"\"\n    Set up a temporary project with dependencies.\n    As Mathlib is a common dependency, you can just set `require=\"mathlib\"` and a compatible version of mathlib will be used.\n    This feature has been developed mostly to be able to run benchmarks using Mathlib as a dependency\n    (such as [ProofNet#](https://huggingface.co/datasets/PAug/ProofNetSharp) or\n    [MiniF2F](https://github.com/yangky11/miniF2F-lean4)) without having to manually set up a Lean project.\n    \"\"\"\n\n    require: Literal[\"mathlib\"] | LeanRequire | list[LeanRequire | Literal[\"mathlib\"]]\n\n    def _normalize_require(self, lean_version: str) -&gt; list[LeanRequire]:\n        \"\"\"Normalize the require field to always be a list.\"\"\"\n        require = self.require\n        if not isinstance(require, list):\n            require = [require]\n\n        normalized_require: list[LeanRequire] = []\n        for req in require:\n            if req == \"mathlib\":\n                normalized_require.append(\n                    LeanRequire(\"mathlib\", \"https://github.com/leanprover-community/mathlib4.git\", lean_version)\n                )\n            elif isinstance(req, LeanRequire):\n                normalized_require.append(req)\n            else:\n                raise ValueError(f\"Invalid requirement type: {type(req)}\")\n\n        return sorted(normalized_require, key=lambda x: x.name)\n\n    def _get_hash_content(self, lean_version: str) -&gt; str:\n        \"\"\"Return a unique hash based on dependencies.\"\"\"\n        require = self._normalize_require(lean_version)\n        return hashlib.sha256(str(require).encode()).hexdigest()\n\n    def _modify_lakefile(self, project_dir: str, lean_version: str) -&gt; None:\n        \"\"\"Add requirements to the lakefile.\"\"\"\n        require = self._normalize_require(lean_version)\n        with open(os.path.join(project_dir, \"lakefile.lean\"), \"a\", encoding=\"utf-8\") as f:\n            for req in require:\n                f.write(f'\\n\\nrequire {req.name} from git\\n  \"{req.git}\"' + (f' @ \"{req.rev}\"' if req.rev else \"\"))\n</code></pre>"},{"location":"api/interface/","title":"Interface API","text":"<p>This page documents the interface classes used to communicate with the Lean REPL.</p>"},{"location":"api/interface/#commands","title":"Commands","text":""},{"location":"api/interface/#command","title":"Command","text":""},{"location":"api/interface/#lean_interact.interface.Command","title":"<code>lean_interact.interface.Command</code>","text":"<p>               Bases: <code>BaseREPLQuery</code>, <code>CommandOptions</code></p> <p>Command to be executed in the REPL. Attributes:     cmd: The command to be executed.     env: The environment to be used (optional). If <code>env = None</code>, starts a new session (in which you can use <code>import</code>).         If <code>env</code> is set, the command is executed in the given environment.     all_tactics: If true, return all tactics used in the command with their associated information.     root_goals: If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.     infotree: Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class Command(BaseREPLQuery, CommandOptions):\n    \"\"\"Command to be executed in the REPL.\n    Attributes:\n        cmd: The command to be executed.\n        env: The environment to be used (optional). If `env = None`, starts a new session (in which you can use `import`).\n            If `env` is set, the command is executed in the given environment.\n        all_tactics: If true, return all tactics used in the command with their associated information.\n        root_goals: If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.\n        infotree: Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.\n    \"\"\"\n\n    cmd: Annotated[str, Field(min_length=1)]\n    env: int | None = None\n</code></pre>"},{"location":"api/interface/#filecommand","title":"FileCommand","text":""},{"location":"api/interface/#lean_interact.interface.FileCommand","title":"<code>lean_interact.interface.FileCommand</code>","text":"<p>               Bases: <code>BaseREPLQuery</code>, <code>CommandOptions</code></p> <p>Command for file operations in the REPL. Attributes:     path: The path of the file to be operated on.     all_tactics: If true, return all tactics used in the command with their associated information.     root_goals: If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.     infotree: Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class FileCommand(BaseREPLQuery, CommandOptions):\n    \"\"\"Command for file operations in the REPL.\n    Attributes:\n        path: The path of the file to be operated on.\n        all_tactics: If true, return all tactics used in the command with their associated information.\n        root_goals: If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.\n        infotree: Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.\n    \"\"\"\n\n    path: Annotated[str, Field(min_length=1)]\n</code></pre>"},{"location":"api/interface/#proofstep","title":"ProofStep","text":""},{"location":"api/interface/#lean_interact.interface.ProofStep","title":"<code>lean_interact.interface.ProofStep</code>","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Proof step in the REPL. Attributes:     proof_state: The proof state to start from.     tactic: The tactic to be applied.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class ProofStep(BaseREPLQuery):\n    \"\"\"Proof step in the REPL.\n    Attributes:\n        proof_state: The proof state to start from.\n        tactic: The tactic to be applied.\n    \"\"\"\n\n    proof_state: Annotated[int, Field(alias=\"proofState\")]\n    tactic: Annotated[str, Field(min_length=1)]\n</code></pre>"},{"location":"api/interface/#pickleenvironment","title":"PickleEnvironment","text":""},{"location":"api/interface/#lean_interact.interface.PickleEnvironment","title":"<code>lean_interact.interface.PickleEnvironment</code>","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Environment for pickling in the REPL. Attributes:     env: The environment to be used.     pickle_to: The path to save the pickle file.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class PickleEnvironment(BaseREPLQuery):\n    \"\"\"Environment for pickling in the REPL.\n    Attributes:\n        env: The environment to be used.\n        pickle_to: The path to save the pickle file.\n    \"\"\"\n\n    env: int\n    pickle_to: Annotated[str, Field(min_length=1, alias=\"pickleTo\")]\n</code></pre>"},{"location":"api/interface/#unpickleenvironment","title":"UnpickleEnvironment","text":""},{"location":"api/interface/#lean_interact.interface.UnpickleEnvironment","title":"<code>lean_interact.interface.UnpickleEnvironment</code>","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Environment for unpickling in the REPL. Attributes:     unpickle_env_from: The path to the pickle file.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class UnpickleEnvironment(BaseREPLQuery):\n    \"\"\"Environment for unpickling in the REPL.\n    Attributes:\n        unpickle_env_from: The path to the pickle file.\n    \"\"\"\n\n    unpickle_env_from: Annotated[str, Field(min_length=1, alias=\"unpickleEnvFrom\")]\n</code></pre>"},{"location":"api/interface/#pickleproofstate","title":"PickleProofState","text":""},{"location":"api/interface/#lean_interact.interface.PickleProofState","title":"<code>lean_interact.interface.PickleProofState</code>","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Proof state for pickling in the REPL. Attributes:     proof_state: The proof state to be pickled.     pickle_to: The path to save the pickle file.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class PickleProofState(BaseREPLQuery):\n    \"\"\"Proof state for pickling in the REPL.\n    Attributes:\n        proof_state: The proof state to be pickled.\n        pickle_to: The path to save the pickle file.\n    \"\"\"\n\n    proof_state: Annotated[int, Field(alias=\"proofState\")]\n    pickle_to: Annotated[str, Field(min_length=1, alias=\"pickleTo\")]\n</code></pre>"},{"location":"api/interface/#unpickleproofstate","title":"UnpickleProofState","text":""},{"location":"api/interface/#lean_interact.interface.UnpickleProofState","title":"<code>lean_interact.interface.UnpickleProofState</code>","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Environment for unpickling in the REPL. Attributes:     unpickle_proof_state_from: The path to the pickle file.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class UnpickleProofState(BaseREPLQuery):\n    \"\"\"Environment for unpickling in the REPL.\n    Attributes:\n        unpickle_proof_state_from: The path to the pickle file.\n    \"\"\"\n\n    unpickle_proof_state_from: Annotated[str, Field(min_length=1, alias=\"unpickleProofStateFrom\")]\n    env: int | None = None\n</code></pre>"},{"location":"api/interface/#responses","title":"Responses","text":""},{"location":"api/interface/#basereplresponse","title":"BaseREPLResponse","text":""},{"location":"api/interface/#lean_interact.interface.BaseREPLResponse","title":"<code>lean_interact.interface.BaseREPLResponse</code>","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Base class for all Lean responses. Attributes:     messages: List of messages in the response.     sorries: List of sorries found in the submitted code.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class BaseREPLResponse(REPLBaseModel):\n    \"\"\"Base class for all Lean responses.\n    Attributes:\n        messages: List of messages in the response.\n        sorries: List of sorries found in the submitted code.\n    \"\"\"\n\n    messages: list[Message] = Field(default_factory=list)\n    sorries: list[Sorry] = Field(default_factory=list)\n\n    def __init__(self, **data):\n        if self.__class__ == BaseREPLResponse:\n            raise TypeError(\"BaseResponse cannot be instantiated directly\")\n        super().__init__(**data)\n\n    def get_errors(self) -&gt; list[Message]:\n        \"\"\"Return all error messages\"\"\"\n        return [msg for msg in self.messages if msg.severity == \"error\"]\n\n    def get_warnings(self) -&gt; list[Message]:\n        \"\"\"Return all warning messages\"\"\"\n        return [msg for msg in self.messages if msg.severity == \"warning\"]\n\n    def has_errors(self) -&gt; bool:\n        \"\"\"Check if response contains any error messages\"\"\"\n        return any(msg.severity == \"error\" for msg in self.messages)\n\n    def lean_code_is_valid(\n        self,\n        start_pos: Pos | None = None,\n        end_pos: Pos | None = None,\n        allow_sorry: bool = True,\n    ) -&gt; bool:\n        \"\"\"Check if the submitted code is valid Lean code.\"\"\"\n        # check only the messages intersecting the code\n        errors = [\n            message\n            for message in self.messages\n            if message_intersects_code(message, start_pos, end_pos) and message.severity == \"error\"\n        ]\n        sorries = [message for message in self.sorries if message_intersects_code(message, start_pos, end_pos)] + [\n            message\n            for message in self.messages\n            if message_intersects_code(message, start_pos, end_pos) and message.data == \"declaration uses 'sorry'\"\n        ]\n        return not errors and (allow_sorry or not sorries)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BaseREPLResponse.get_errors","title":"<code>get_errors()</code>","text":"<p>Return all error messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def get_errors(self) -&gt; list[Message]:\n    \"\"\"Return all error messages\"\"\"\n    return [msg for msg in self.messages if msg.severity == \"error\"]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BaseREPLResponse.get_warnings","title":"<code>get_warnings()</code>","text":"<p>Return all warning messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def get_warnings(self) -&gt; list[Message]:\n    \"\"\"Return all warning messages\"\"\"\n    return [msg for msg in self.messages if msg.severity == \"warning\"]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BaseREPLResponse.has_errors","title":"<code>has_errors()</code>","text":"<p>Check if response contains any error messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def has_errors(self) -&gt; bool:\n    \"\"\"Check if response contains any error messages\"\"\"\n    return any(msg.severity == \"error\" for msg in self.messages)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BaseREPLResponse.lean_code_is_valid","title":"<code>lean_code_is_valid(start_pos=None, end_pos=None, allow_sorry=True)</code>","text":"<p>Check if the submitted code is valid Lean code.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def lean_code_is_valid(\n    self,\n    start_pos: Pos | None = None,\n    end_pos: Pos | None = None,\n    allow_sorry: bool = True,\n) -&gt; bool:\n    \"\"\"Check if the submitted code is valid Lean code.\"\"\"\n    # check only the messages intersecting the code\n    errors = [\n        message\n        for message in self.messages\n        if message_intersects_code(message, start_pos, end_pos) and message.severity == \"error\"\n    ]\n    sorries = [message for message in self.sorries if message_intersects_code(message, start_pos, end_pos)] + [\n        message\n        for message in self.messages\n        if message_intersects_code(message, start_pos, end_pos) and message.data == \"declaration uses 'sorry'\"\n    ]\n    return not errors and (allow_sorry or not sorries)\n</code></pre>"},{"location":"api/interface/#commandresponse","title":"CommandResponse","text":""},{"location":"api/interface/#lean_interact.interface.CommandResponse","title":"<code>lean_interact.interface.CommandResponse</code>","text":"<p>               Bases: <code>BaseREPLResponse</code></p> <p>Response to a command in the REPL. Attributes:     env: The environment state after running the code in the command     tactics: List of tactics in the code. Returned only if <code>all_tactics</code> is true.     infotree: The infotree of the code. Returned only if <code>infotree</code> is true.     messages: List of messages in the response.     sorries: List of sorries found in the submitted code.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class CommandResponse(BaseREPLResponse):\n    \"\"\"Response to a command in the REPL.\n    Attributes:\n        env: The environment state after running the code in the command\n        tactics: List of tactics in the code. Returned only if `all_tactics` is true.\n        infotree: The infotree of the code. Returned only if `infotree` is true.\n        messages: List of messages in the response.\n        sorries: List of sorries found in the submitted code.\n    \"\"\"\n\n    env: int\n    tactics: list[Tactic] = Field(default_factory=list)\n    infotree: list | None = None\n</code></pre>"},{"location":"api/interface/#proofstepresponse","title":"ProofStepResponse","text":""},{"location":"api/interface/#lean_interact.interface.ProofStepResponse","title":"<code>lean_interact.interface.ProofStepResponse</code>","text":"<p>               Bases: <code>BaseREPLResponse</code></p> <p>Response to a proof step in the REPL. Attributes:     proof_status: The proof status of the whole proof. Possible values: <code>Completed</code>, <code>Incomplete</code>, <code>Error</code>.     proof_state: The proof state after the proof step.     goals: List of goals after the proof step.     traces: List of traces in the proof step.     messages: List of messages in the response.     sorries: List of sorries found in the submitted code.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class ProofStepResponse(BaseREPLResponse):\n    \"\"\"Response to a proof step in the REPL.\n    Attributes:\n        proof_status: The proof status of the whole proof. Possible values: `Completed`, `Incomplete`, `Error`.\n        proof_state: The proof state after the proof step.\n        goals: List of goals after the proof step.\n        traces: List of traces in the proof step.\n        messages: List of messages in the response.\n        sorries: List of sorries found in the submitted code.\n    \"\"\"\n\n    proof_status: Annotated[str, Field(alias=\"proofStatus\")]\n    proof_state: Annotated[int, Field(alias=\"proofState\")]\n    goals: list[str] = Field(default_factory=list)\n    traces: list[str] = Field(default_factory=list)\n</code></pre>"},{"location":"api/interface/#helper-classes","title":"Helper Classes","text":""},{"location":"api/interface/#message","title":"Message","text":""},{"location":"api/interface/#lean_interact.interface.Message","title":"<code>lean_interact.interface.Message</code>","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Message in the REPL. Attributes:     start_pos: The starting position of the message.     end_pos: The ending position of the message.     severity: The severity of the message.     data: The data associated with the message.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class Message(REPLBaseModel):\n    \"\"\"Message in the REPL.\n    Attributes:\n        start_pos: The starting position of the message.\n        end_pos: The ending position of the message.\n        severity: The severity of the message.\n        data: The data associated with the message.\n    \"\"\"\n\n    start_pos: Annotated[Pos, Field(alias=\"pos\")]\n    end_pos: Annotated[Pos | None, Field(alias=\"endPos\")] = None\n    severity: Literal[\"error\", \"warning\", \"info\", \"trace\"]\n    data: str\n</code></pre>"},{"location":"api/interface/#sorry","title":"Sorry","text":""},{"location":"api/interface/#lean_interact.interface.Sorry","title":"<code>lean_interact.interface.Sorry</code>","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Sorry message in the REPL. Attributes:     start_pos: The starting position of the sorry message.     end_pos: The ending position of the sorry message.     goal: The proof goal at the sorry location.     proof_state: The proof state associated to the sorry.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class Sorry(REPLBaseModel):\n    \"\"\"Sorry message in the REPL.\n    Attributes:\n        start_pos: The starting position of the sorry message.\n        end_pos: The ending position of the sorry message.\n        goal: The proof goal at the sorry location.\n        proof_state: The proof state associated to the sorry.\n    \"\"\"\n\n    start_pos: Annotated[Pos | None, Field(alias=\"pos\")] = None\n    end_pos: Annotated[Pos | None, Field(alias=\"endPos\")] = None\n    goal: str\n    proof_state: Annotated[int | None, Field(alias=\"proofState\")] = None\n</code></pre>"},{"location":"api/interface/#pos","title":"Pos","text":""},{"location":"api/interface/#lean_interact.interface.Pos","title":"<code>lean_interact.interface.Pos</code>","text":"<p>               Bases: <code>REPLBaseModel</code></p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class Pos(REPLBaseModel):\n    line: int\n    column: int\n\n    def __le__(self, other: \"Pos\") -&gt; bool:\n        if self.line &lt; other.line:\n            return True\n        if self.line == other.line:\n            return self.column &lt;= other.column\n        return False\n\n    def __lt__(self, other: \"Pos\") -&gt; bool:\n        return self &lt;= other and not self == other\n</code></pre>"},{"location":"api/interface/#tactic","title":"Tactic","text":""},{"location":"api/interface/#lean_interact.interface.Tactic","title":"<code>lean_interact.interface.Tactic</code>","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Tactic in the REPL. Attributes:     start_pos: The starting position of the tactic.     end_pos: The ending position of the tactic.     goals: The goals associated with the tactic.     tactic: The applied tactic.     proof_state: The proof state associated with the tactic.     used_constants: The constants used in the tactic.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>class Tactic(REPLBaseModel):\n    \"\"\"Tactic in the REPL.\n    Attributes:\n        start_pos: The starting position of the tactic.\n        end_pos: The ending position of the tactic.\n        goals: The goals associated with the tactic.\n        tactic: The applied tactic.\n        proof_state: The proof state associated with the tactic.\n        used_constants: The constants used in the tactic.\n    \"\"\"\n\n    start_pos: Annotated[Pos, Field(alias=\"pos\")]\n    end_pos: Annotated[Pos, Field(alias=\"endPos\")]\n    goals: str\n    tactic: str\n    proof_state: Annotated[int | None, Field(alias=\"proofState\")] = None\n    used_constants: Annotated[list[str], Field(default_factory=list, alias=\"usedConstants\")]\n</code></pre>"},{"location":"api/server/","title":"LeanServer API","text":"<p>This page documents the server classes responsible for communicating with the Lean REPL.</p>"},{"location":"api/server/#leanserver","title":"LeanServer","text":""},{"location":"api/server/#lean_interact.server.LeanServer","title":"<code>lean_interact.server.LeanServer</code>","text":"Source code in <code>src/lean_interact/server.py</code> <pre><code>class LeanServer:\n    config: LeanREPLConfig\n    _proc: subprocess.Popen | None\n    _lock: threading.Lock\n\n    def __init__(self, config: LeanREPLConfig):\n        \"\"\"\n        This class is a Python wrapper for the Lean REPL. Please refer to the \\\n        [Lean REPL documentation](https://github.com/leanprover-community/repl) to learn more about the Lean REPL commands.\n\n        \\u26a0 Multiprocessing: instantiate one config before starting multiprocessing. Then instantiate one `LeanServer`\n        per process by passing the config instance to the constructor. This will ensure that the REPL is already set up\n        for your specific environment and avoid concurrency conflicts.\n\n        Args:\n            config: The configuration for the Lean server.\n        \"\"\"\n        self.config = config\n        assert self.config.is_setup(), \"The Lean environment has not been set up properly.\"\n        self._proc = None\n        self._lock = threading.Lock()\n        self.start()\n\n    @property\n    def lean_version(self) -&gt; str | None:\n        return self.config.lean_version\n\n    def start(self) -&gt; None:\n        self._proc = subprocess.Popen(\n            [\"lake\", \"env\", os.path.join(self.config._cache_repl_dir, \".lake\", \"build\", \"bin\", \"repl\")],\n            cwd=self.config.working_dir,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            encoding=\"utf-8\",\n            text=True,\n            bufsize=1,\n            start_new_session=True,\n            preexec_fn=None\n            if platform.system() != \"Linux\"\n            else lambda: _limit_memory(self.config.memory_hard_limit_mb),\n        )\n\n    def _sendline(self, line: str) -&gt; None:\n        assert self._proc is not None and self._proc.stdin is not None\n        self._proc.stdin.write(line + \"\\n\")\n        self._proc.stdin.flush()\n\n    def is_alive(self) -&gt; bool:\n        return self._proc is not None and self._proc.poll() is None\n\n    def kill(self) -&gt; None:\n        if self._proc:\n            try:\n                proc = psutil.Process(self._proc.pid)\n                # Terminate the process tree\n                children = proc.children(recursive=True)\n                for child in children:\n                    try:\n                        child.terminate()\n                    except Exception:\n                        pass\n                proc.terminate()\n                _, alive = psutil.wait_procs([proc] + children, timeout=1)\n                for p in alive:\n                    try:\n                        p.kill()\n                    except Exception:\n                        pass\n            except Exception:\n                pass\n            self._proc = None\n        gc.collect()\n\n    def restart(self) -&gt; None:\n        self.kill()\n        self.start()\n\n    def __del__(self):\n        self.kill()\n\n    def _execute_cmd_in_repl(self, json_query: str, verbose: bool, timeout: float | None) -&gt; str:\n        \"\"\"Send JSON queries to the Lean REPL and wait for the standard delimiter.\"\"\"\n        assert self._proc is not None and self._proc.stdin is not None and self._proc.stdout is not None\n        with self._lock:\n            if verbose:\n                logger.info(\"Sending query: %s\", json_query)\n            self._proc.stdin.write(json_query + \"\\n\\n\")\n            self._proc.stdin.flush()\n\n            output: str = \"\"\n\n            def reader():\n                # Read until delimiter \"\\n\\n\" or timeout\n                nonlocal output\n                assert self._proc is not None and self._proc.stdout is not None\n                while True:\n                    line = self._proc.stdout.readline()\n                    if not line:\n                        break  # EOF\n                    output += line\n                    if output.endswith(\"\\n\\n\"):\n                        break\n\n            t = threading.Thread(target=reader)\n            t.start()\n            t.join(timeout)\n            if t.is_alive():\n                self.kill()\n                raise TimeoutError(f\"The Lean server did not respond in time ({timeout=}) and is now killed.\")\n            if output:\n                return output\n            raise BrokenPipeError(\"The Lean server returned no output.\")\n\n    def _parse_repl_output(self, raw_output: str, verbose: bool) -&gt; dict:\n        \"\"\"Parse JSON response.\"\"\"\n        if verbose:\n            logger.info(\"Server output: `%s`\", raw_output)\n        try:\n            return json.loads(raw_output)\n        except json.JSONDecodeError as e:\n            raise json.JSONDecodeError(\n                msg=f\"Could not parse the Lean server output: `{repr(raw_output)}`.\", doc=e.doc, pos=e.pos\n            ) from e\n\n    def run_dict(self, request: dict, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT) -&gt; dict:\n        \"\"\"\n        Run a Lean REPL dictionary request and return the Lean server output as a dictionary.\n        Args:\n            request: The Lean REPL request to execute. Must be a dictionary.\n            verbose: Whether to print additional information during the verification process.\n            timeout: The timeout for the request in seconds\n        Returns:\n            The output of the Lean server as a dictionary.\n        \"\"\"\n        if not self.is_alive():\n            raise ChildProcessError(\"The Lean server is not running.\")\n\n        json_query = json.dumps(request, ensure_ascii=False)\n        try:\n            raw_output = self._execute_cmd_in_repl(json_query, verbose, timeout)\n        except TimeoutError as e:\n            self.kill()\n            raise TimeoutError(f\"The Lean server did not respond in time ({timeout=}) and is now killed.\") from e\n        except BrokenPipeError as e:\n            self.kill()\n            raise ConnectionAbortedError(\n                \"The Lean server closed unexpectedly. Possible reasons (not exhaustive):\\n\"\n                \"- An uncaught exception in the Lean REPL (for example, an inexistent file has been requested)\\n\"\n                \"- Not enough memory and/or compute available\\n\"\n                \"- The cached Lean REPL is corrupted. In this case, clear the cache\"\n                \" using the `clear-lean-cache` command.\"\n            ) from e\n\n        return self._parse_repl_output(raw_output, verbose)\n\n    # Type hints for IDE and static analysis\n    @overload\n    def run(\n        self,\n        request: Command | FileCommand | PickleEnvironment | UnpickleEnvironment,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n    ) -&gt; CommandResponse | LeanError: ...\n\n    @overload\n    def run(\n        self,\n        request: ProofStep | PickleProofState | UnpickleProofState,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n    ) -&gt; ProofStepResponse | LeanError: ...\n\n    def run(\n        self, request: BaseREPLQuery, *, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT, **kwargs\n    ) -&gt; BaseREPLResponse | LeanError:\n        \"\"\"\n        Run a Lean REPL request.\n\n        Thread-safe: Uses a threading.Lock to ensure only one operation runs at a time.\n\n        Args:\n            request: The Lean REPL request to execute. Must be one of the following types:\n                - `Command`\n                - `File`\n                - `ProofStep`\n                - `PickleEnvironment`\n                - `PickleProofState`\n                - `UnpickleEnvironment`\n                - `UnpickleProofState`\n            verbose: Whether to print additional information\n            timeout: The timeout for the request in seconds\n\n        Returns:\n            Depending on the request type, the response will be one of the following:\n            - `CommandResponse`\n            - `ProofStepResponse`\n            - `LeanError`\n        \"\"\"\n        request_dict = request.model_dump(exclude_none=True, by_alias=True)\n        result_dict = self.run_dict(request=request_dict, verbose=verbose, timeout=timeout, **kwargs)\n\n        if set(result_dict.keys()) == {\"message\"}:\n            return LeanError.model_validate(result_dict)\n\n        if isinstance(request, (Command, FileCommand, PickleEnvironment, UnpickleEnvironment)):\n            return CommandResponse.model_validate(result_dict)\n        elif isinstance(request, (ProofStep, PickleProofState, UnpickleProofState)):\n            return ProofStepResponse.model_validate(result_dict)\n        else:\n            return BaseREPLResponse.model_validate(result_dict)\n\n    # Type hints for IDE and static analysis\n    @overload\n    async def async_run(\n        self,\n        request: Command | FileCommand | PickleEnvironment | UnpickleEnvironment,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n    ) -&gt; CommandResponse | LeanError: ...\n\n    @overload\n    async def async_run(\n        self,\n        request: ProofStep | PickleProofState | UnpickleProofState,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n    ) -&gt; ProofStepResponse | LeanError: ...\n\n    async def async_run(\n        self, request: BaseREPLQuery, *, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT, **kwargs\n    ) -&gt; BaseREPLResponse | LeanError:\n        \"\"\"\n        Asynchronous version of run(). Runs the blocking run() in a thread pool.\n\n        Thread-safe: Uses a threading.Lock to ensure only one operation runs at a time.\n        \"\"\"\n        return await asyncio.to_thread(self.run, request, verbose=verbose, timeout=timeout, **kwargs)  # type: ignore\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.__init__","title":"<code>__init__(config)</code>","text":"<p>This class is a Python wrapper for the Lean REPL. Please refer to the         Lean REPL documentation to learn more about the Lean REPL commands.</p> <p>\u26a0 Multiprocessing: instantiate one config before starting multiprocessing. Then instantiate one <code>LeanServer</code> per process by passing the config instance to the constructor. This will ensure that the REPL is already set up for your specific environment and avoid concurrency conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LeanREPLConfig</code> <p>The configuration for the Lean server.</p> required Source code in <code>src/lean_interact/server.py</code> <pre><code>def __init__(self, config: LeanREPLConfig):\n    \"\"\"\n    This class is a Python wrapper for the Lean REPL. Please refer to the \\\n    [Lean REPL documentation](https://github.com/leanprover-community/repl) to learn more about the Lean REPL commands.\n\n    \\u26a0 Multiprocessing: instantiate one config before starting multiprocessing. Then instantiate one `LeanServer`\n    per process by passing the config instance to the constructor. This will ensure that the REPL is already set up\n    for your specific environment and avoid concurrency conflicts.\n\n    Args:\n        config: The configuration for the Lean server.\n    \"\"\"\n    self.config = config\n    assert self.config.is_setup(), \"The Lean environment has not been set up properly.\"\n    self._proc = None\n    self._lock = threading.Lock()\n    self.start()\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.async_run","title":"<code>async_run(request, *, verbose=False, timeout=DEFAULT_TIMEOUT, **kwargs)</code>  <code>async</code>","text":"<pre><code>async_run(\n    request: Command\n    | FileCommand\n    | PickleEnvironment\n    | UnpickleEnvironment,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n) -&gt; CommandResponse | LeanError\n</code></pre><pre><code>async_run(\n    request: ProofStep\n    | PickleProofState\n    | UnpickleProofState,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n) -&gt; ProofStepResponse | LeanError\n</code></pre> <p>Asynchronous version of run(). Runs the blocking run() in a thread pool.</p> <p>Thread-safe: Uses a threading.Lock to ensure only one operation runs at a time.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>async def async_run(\n    self, request: BaseREPLQuery, *, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT, **kwargs\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Asynchronous version of run(). Runs the blocking run() in a thread pool.\n\n    Thread-safe: Uses a threading.Lock to ensure only one operation runs at a time.\n    \"\"\"\n    return await asyncio.to_thread(self.run, request, verbose=verbose, timeout=timeout, **kwargs)  # type: ignore\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.run","title":"<code>run(request, *, verbose=False, timeout=DEFAULT_TIMEOUT, **kwargs)</code>","text":"<pre><code>run(\n    request: Command\n    | FileCommand\n    | PickleEnvironment\n    | UnpickleEnvironment,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n) -&gt; CommandResponse | LeanError\n</code></pre><pre><code>run(\n    request: ProofStep\n    | PickleProofState\n    | UnpickleProofState,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n) -&gt; ProofStepResponse | LeanError\n</code></pre> <p>Run a Lean REPL request.</p> <p>Thread-safe: Uses a threading.Lock to ensure only one operation runs at a time.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BaseREPLQuery</code> <p>The Lean REPL request to execute. Must be one of the following types: - <code>Command</code> - <code>File</code> - <code>ProofStep</code> - <code>PickleEnvironment</code> - <code>PickleProofState</code> - <code>UnpickleEnvironment</code> - <code>UnpickleProofState</code></p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <p>Returns:</p> Type Description <code>BaseREPLResponse | LeanError</code> <p>Depending on the request type, the response will be one of the following:</p> <code>BaseREPLResponse | LeanError</code> <ul> <li><code>CommandResponse</code></li> </ul> <code>BaseREPLResponse | LeanError</code> <ul> <li><code>ProofStepResponse</code></li> </ul> <code>BaseREPLResponse | LeanError</code> <ul> <li><code>LeanError</code></li> </ul> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run(\n    self, request: BaseREPLQuery, *, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT, **kwargs\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Run a Lean REPL request.\n\n    Thread-safe: Uses a threading.Lock to ensure only one operation runs at a time.\n\n    Args:\n        request: The Lean REPL request to execute. Must be one of the following types:\n            - `Command`\n            - `File`\n            - `ProofStep`\n            - `PickleEnvironment`\n            - `PickleProofState`\n            - `UnpickleEnvironment`\n            - `UnpickleProofState`\n        verbose: Whether to print additional information\n        timeout: The timeout for the request in seconds\n\n    Returns:\n        Depending on the request type, the response will be one of the following:\n        - `CommandResponse`\n        - `ProofStepResponse`\n        - `LeanError`\n    \"\"\"\n    request_dict = request.model_dump(exclude_none=True, by_alias=True)\n    result_dict = self.run_dict(request=request_dict, verbose=verbose, timeout=timeout, **kwargs)\n\n    if set(result_dict.keys()) == {\"message\"}:\n        return LeanError.model_validate(result_dict)\n\n    if isinstance(request, (Command, FileCommand, PickleEnvironment, UnpickleEnvironment)):\n        return CommandResponse.model_validate(result_dict)\n    elif isinstance(request, (ProofStep, PickleProofState, UnpickleProofState)):\n        return ProofStepResponse.model_validate(result_dict)\n    else:\n        return BaseREPLResponse.model_validate(result_dict)\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.run_dict","title":"<code>run_dict(request, verbose=False, timeout=DEFAULT_TIMEOUT)</code>","text":"<p>Run a Lean REPL dictionary request and return the Lean server output as a dictionary. Args:     request: The Lean REPL request to execute. Must be a dictionary.     verbose: Whether to print additional information during the verification process.     timeout: The timeout for the request in seconds Returns:     The output of the Lean server as a dictionary.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run_dict(self, request: dict, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT) -&gt; dict:\n    \"\"\"\n    Run a Lean REPL dictionary request and return the Lean server output as a dictionary.\n    Args:\n        request: The Lean REPL request to execute. Must be a dictionary.\n        verbose: Whether to print additional information during the verification process.\n        timeout: The timeout for the request in seconds\n    Returns:\n        The output of the Lean server as a dictionary.\n    \"\"\"\n    if not self.is_alive():\n        raise ChildProcessError(\"The Lean server is not running.\")\n\n    json_query = json.dumps(request, ensure_ascii=False)\n    try:\n        raw_output = self._execute_cmd_in_repl(json_query, verbose, timeout)\n    except TimeoutError as e:\n        self.kill()\n        raise TimeoutError(f\"The Lean server did not respond in time ({timeout=}) and is now killed.\") from e\n    except BrokenPipeError as e:\n        self.kill()\n        raise ConnectionAbortedError(\n            \"The Lean server closed unexpectedly. Possible reasons (not exhaustive):\\n\"\n            \"- An uncaught exception in the Lean REPL (for example, an inexistent file has been requested)\\n\"\n            \"- Not enough memory and/or compute available\\n\"\n            \"- The cached Lean REPL is corrupted. In this case, clear the cache\"\n            \" using the `clear-lean-cache` command.\"\n        ) from e\n\n    return self._parse_repl_output(raw_output, verbose)\n</code></pre>"},{"location":"api/server/#autoleanserver","title":"AutoLeanServer","text":""},{"location":"api/server/#lean_interact.server.AutoLeanServer","title":"<code>lean_interact.server.AutoLeanServer</code>","text":"<p>               Bases: <code>LeanServer</code></p> Source code in <code>src/lean_interact/server.py</code> <pre><code>class AutoLeanServer(LeanServer):\n    def __init__(\n        self,\n        config: LeanREPLConfig,\n        max_total_memory: float = 0.8,\n        max_process_memory: float | None = 0.8,\n        max_restart_attempts: int = 5,\n    ):\n        \"\"\"\n        This class is a Python wrapper for the Lean REPL. `AutoLeanServer` differs from `LeanServer` by automatically \\\n        restarting when it runs out of memory to clear Lean environment states. \\\n        It also automatically recovers from timeouts (). \\\n        An exponential backoff strategy is used to restart the server, making this class slightly more friendly for multiprocessing\n        than `LeanServer` when multiple instances are competing for resources. \\\n        Please refer to the original [Lean REPL documentation](https://github.com/leanprover-community/repl) to learn more about the \\\n        Lean REPL commands.\n\n        A session cache is implemented to keep user-selected environment / proof states across these automatic restarts. \\\n        Use the `add_to_session_cache` parameter in the different class methods to add the command to \\\n        the session cache. `AutoLeanServer` works best when only a few states are cached simultaneously. \\\n        You can use `remove_from_session_cache` and `clear_session_cache` to clear the session cache. \\\n        Cached state indices are negative integers starting from -1 to not conflict with the positive integers used by the Lean REPL.\n\n        **Note:** the session cache is specific to each `AutoLeanServer` instance and is cleared when the instance is deleted. \\\n        If you want truly persistent states, you can use the `pickle` and `unpickle` methods to save and load states to disk.\n\n        \\u26a0 Multiprocessing: instantiate the config before starting multiprocessing. Then instantiate one `LeanServer`\n        per process by passing the config instance to the constructor. This will ensure that the REPL is already set up\n        for your specific environment and avoid concurrency conflicts.\n\n        Args:\n            config: The configuration for the Lean server.\n            max_total_memory: The maximum proportion of system-wide memory usage (across all processes) before triggering a Lean server restart. This is a soft limit ranging from 0.0 to 1.0, with default 0.8 (80%). When system memory exceeds this threshold, the server restarts to free memory. Particularly useful in multiprocessing environments to prevent simultaneous crashes.\n            max_process_memory: The maximum proportion of the memory hard limit (set in `LeanREPLConfig.memory_hard_limit_mb`) that the Lean server process can use before restarting. This soft limit ranges from 0.0 to 1.0, with default 0.8 (80%). Only applied if a hard limit is configured in `LeanREPLConfig`.\n            max_restart_attempts: The maximum number of consecutive restart attempts allowed before raising a `MemoryError` exception. Default is 5. The server uses exponential backoff between restart attempts.\n        \"\"\"\n        self._state_counter = 0\n        self._restart_persistent_session_cache: dict[int, _SessionState] = {}\n        self._max_total_memory = max_total_memory\n        self._max_process_memory = max_process_memory\n        self._max_restart_attempts = max_restart_attempts\n        super().__init__(config=config)\n\n    def _get_repl_state_id(self, state_id: int | None) -&gt; int | None:\n        if state_id is None:\n            return None\n        if state_id &gt;= 0:\n            return state_id\n        return self._restart_persistent_session_cache[state_id].repl_id\n\n    def _reload_session_cache(self, verbose: bool = False) -&gt; None:\n        \"\"\"\n        Reload the session cache. This method should be called only after a restart of the Lean REPL.\n        \"\"\"\n        for state_data in self._restart_persistent_session_cache.values():\n            # Use file lock when accessing the pickle file to prevent cache invalidation\n            # from multiple concurrent processes\n            with FileLock(f\"{state_data.pickle_file}.lock\", timeout=60):\n                if state_data.is_proof_state:\n                    cmd = UnpickleProofState(unpickle_proof_state_from=state_data.pickle_file, env=state_data.repl_id)\n                else:\n                    cmd = UnpickleEnvironment(unpickle_env_from=state_data.pickle_file)\n                result = self.run(\n                    cmd,\n                    verbose=verbose,\n                    timeout=DEFAULT_TIMEOUT,\n                    add_to_session_cache=False,\n                )\n                if isinstance(result, LeanError):\n                    raise ValueError(\n                        f\"Could not reload the session cache. The Lean server returned an error: {result.message}\"\n                    )\n                elif isinstance(result, CommandResponse):\n                    state_data.repl_id = result.env\n                elif isinstance(result, ProofStepResponse):\n                    state_data.repl_id = result.proof_state\n                else:\n                    raise ValueError(\n                        f\"Could not reload the session cache. The Lean server returned an unexpected response: {result}\"\n                    )\n\n    def restart(self, verbose: bool = False) -&gt; None:\n        super().restart()\n        self._reload_session_cache(verbose=verbose)\n\n    def remove_from_session_cache(self, session_state_id: int) -&gt; None:\n        \"\"\"\n        Remove an environment from the session cache.\n\n        Args:\n            session_state_id: The session state id to remove.\n        \"\"\"\n        if (state_cache := self._restart_persistent_session_cache.pop(session_state_id, None)) is not None:\n            pickle_file = state_cache.pickle_file\n            with FileLock(f\"{pickle_file}.lock\", timeout=60):\n                if os.path.exists(pickle_file):\n                    os.remove(pickle_file)\n\n    def clear_session_cache(self, force: bool = False) -&gt; None:\n        \"\"\"\n        Clear the session cache.\n\n        Args:\n            force: Whether to directly clear the session cache. \\\n                `force=False` will only clear the session cache the next time the server runs out of memory while \\\n                still allowing you to add new content in the session cache in the meantime.\n        \"\"\"\n        states_data = list(self._restart_persistent_session_cache.values())\n        for state_data in states_data:\n            self.remove_from_session_cache(session_state_id=state_data.session_id)\n        self._restart_persistent_session_cache = {}\n        if force:\n            self.restart()\n\n    def __del__(self):\n        # delete the session cache\n        for state_data in self._restart_persistent_session_cache.values():\n            try:\n                os.remove(state_data.pickle_file)\n            except FileNotFoundError:\n                pass\n\n        super().__del__()\n\n    def _store_session_cache(\n        self, hash_key: str, repl_id: int, is_proof_state: bool = False, verbose: bool = False\n    ) -&gt; int:\n        self._state_counter -= 1\n        process_id = os.getpid()  # use process id to avoid conflicts in multiprocessing\n        pickle_file = os.path.join(\n            self.config.working_dir,\n            f\"session_cache/{hashlib.sha256(hash_key.encode()).hexdigest()}_{process_id}.olean\",\n        )\n        os.makedirs(os.path.dirname(pickle_file), exist_ok=True)\n        if is_proof_state:\n            request = PickleProofState(proof_state=repl_id, pickle_to=pickle_file)\n        else:\n            request = PickleEnvironment(env=repl_id, pickle_to=pickle_file)\n\n        # Use file lock when accessing the pickle file to prevent cache invalidation\n        # from multiple concurrent processes\n        with FileLock(f\"{pickle_file}.lock\", timeout=60):\n            result = self.run(request, verbose=verbose, timeout=DEFAULT_TIMEOUT)\n            if isinstance(result, LeanError):\n                raise ValueError(\n                    f\"Could not store the result in the session cache. The Lean server returned an error: {result.message}\"\n                )\n\n            self._restart_persistent_session_cache[self._state_counter] = _SessionState(\n                session_id=self._state_counter,\n                repl_id=repl_id,\n                pickle_file=pickle_file,\n                is_proof_state=is_proof_state,\n            )\n\n        return self._state_counter\n\n    def _run_dict_backoff(self, request: dict, verbose: bool, timeout: float | None, restart_counter: int = 0) -&gt; dict:\n        if (psutil.virtual_memory().percent &gt;= 100 * self._max_total_memory) or (\n            self.is_alive()\n            and self._proc is not None\n            and self.config.memory_hard_limit_mb is not None\n            and self._max_process_memory is not None\n            and get_total_memory_usage(psutil.Process())\n            &gt;= self._max_process_memory * self.config.memory_hard_limit_mb * 1024**2\n        ):\n            self.kill()\n            if restart_counter &gt;= self._max_restart_attempts:\n                raise MemoryError(\n                    f\"Memory usage is too high. We attempted to restart the Lean server {self._max_restart_attempts} times without success.\"\n                )\n            if verbose:\n                logger.info(\"Memory usage is too high. Reloading the Lean server...\")\n            sleep(2**restart_counter)\n            return self._run_dict_backoff(\n                request=request, verbose=verbose, timeout=timeout, restart_counter=restart_counter + 1\n            )\n\n        if not self.is_alive():\n            self.start()\n            self._reload_session_cache(verbose=verbose)\n\n        # Replace the negative environment / proof state ids with the corresponding REPL ids\n        if request.get(\"env\", 0) &lt; 0:\n            request = deepcopy(request)\n            request[\"env\"] = self._get_repl_state_id(request[\"env\"])\n        if request.get(\"proofState\", 0) &lt; 0:\n            request = deepcopy(request)\n            request[\"proofState\"] = self._get_repl_state_id(request[\"proofState\"])\n\n        return super().run_dict(request=request, verbose=verbose, timeout=timeout)\n\n    def run_dict(self, request: dict, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT) -&gt; dict:\n        raise NotImplementedError(\n            \"This method is not available with automated memory management. Please use `run`, or use `run_dict` from the `LeanServer` class.\"\n        )\n\n    # Type hints for IDE and static analysis\n    @overload\n    def run(\n        self,\n        request: Command | FileCommand | PickleEnvironment | UnpickleEnvironment,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n        add_to_session_cache: bool = False,\n    ) -&gt; CommandResponse | LeanError: ...\n\n    @overload\n    def run(\n        self,\n        request: ProofStep | PickleProofState | UnpickleProofState,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n        add_to_session_cache: bool = False,\n    ) -&gt; ProofStepResponse | LeanError: ...\n\n    def run(\n        self,\n        request: BaseREPLQuery,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n        add_to_session_cache: bool = False,\n    ) -&gt; BaseREPLResponse | LeanError:\n        \"\"\"\n        Run a Lean REPL request with optional session caching.\n\n        Args:\n            request: The Lean REPL request to execute. Must be one of the following types:\n                - `Command`\n                - `File`\n                - `ProofStep`\n                - `PickleEnvironment`\n                - `PickleProofState`\n                - `UnpickleEnvironment`\n                - `UnpickleProofState`\n            verbose: Whether to print additional information\n            timeout: The timeout for the request in seconds\n\n        Returns:\n            Depending on the request type, the response will be one of the following:\n            - `CommandResponse`\n            - `ProofStepResponse`\n            - `LeanError`\n        \"\"\"\n        request_dict = request.model_dump(exclude_none=True, by_alias=True)\n        result_dict = self._run_dict_backoff(request=request_dict, verbose=verbose, timeout=timeout)\n\n        if set(result_dict.keys()) == {\"message\"} or result_dict == {}:\n            result = LeanError.model_validate(result_dict)\n        elif isinstance(request, (Command, FileCommand, PickleEnvironment, UnpickleEnvironment)):\n            result = CommandResponse.model_validate(result_dict)\n            if add_to_session_cache:\n                env_id = result.env\n                hash_key = f\"request_{type(request).__name__}_{id(request)}\"\n                new_env_id = self._store_session_cache(\n                    hash_key=hash_key, repl_id=env_id, is_proof_state=False, verbose=verbose\n                )\n                result = result.model_copy(update={\"env\": new_env_id})\n        elif isinstance(request, (ProofStep, PickleProofState, UnpickleProofState)):\n            result = ProofStepResponse.model_validate(result_dict)\n            if add_to_session_cache:\n                proof_state_id = result.proof_state\n                hash_key = f\"proofstep_{type(request).__name__}_{id(request)}\"\n                new_proof_state_id = self._store_session_cache(\n                    hash_key=hash_key, repl_id=proof_state_id, is_proof_state=True, verbose=verbose\n                )\n                result = result.model_copy(update={\"proofState\": new_proof_state_id})\n        else:\n            result = BaseREPLResponse.model_validate(result_dict)\n\n        return result\n\n    # Type hints for IDE and static analysis\n    @overload\n    async def async_run(\n        self,\n        request: Command | FileCommand | PickleEnvironment | UnpickleEnvironment,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n        add_to_session_cache: bool = False,\n    ) -&gt; CommandResponse | LeanError: ...\n\n    @overload\n    async def async_run(\n        self,\n        request: ProofStep | PickleProofState | UnpickleProofState,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n        add_to_session_cache: bool = False,\n    ) -&gt; ProofStepResponse | LeanError: ...\n\n    async def async_run(\n        self,\n        request: BaseREPLQuery,\n        *,\n        verbose: bool = False,\n        timeout: float | None = DEFAULT_TIMEOUT,\n        add_to_session_cache: bool = False,\n    ) -&gt; BaseREPLResponse | LeanError:\n        \"\"\"\n        Asynchronous version of run() for AutoLeanServer. Runs the blocking run() in a thread pool.\n        \"\"\"\n        return await asyncio.to_thread(\n            self.run,\n            request,  # type: ignore\n            verbose=verbose,\n            timeout=timeout,\n            add_to_session_cache=add_to_session_cache,\n        )\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.__init__","title":"<code>__init__(config, max_total_memory=0.8, max_process_memory=0.8, max_restart_attempts=5)</code>","text":"<p>This class is a Python wrapper for the Lean REPL. <code>AutoLeanServer</code> differs from <code>LeanServer</code> by automatically         restarting when it runs out of memory to clear Lean environment states.         It also automatically recovers from timeouts ().         An exponential backoff strategy is used to restart the server, making this class slightly more friendly for multiprocessing than <code>LeanServer</code> when multiple instances are competing for resources.         Please refer to the original Lean REPL documentation to learn more about the         Lean REPL commands.</p> <p>A session cache is implemented to keep user-selected environment / proof states across these automatic restarts.         Use the <code>add_to_session_cache</code> parameter in the different class methods to add the command to         the session cache. <code>AutoLeanServer</code> works best when only a few states are cached simultaneously.         You can use <code>remove_from_session_cache</code> and <code>clear_session_cache</code> to clear the session cache.         Cached state indices are negative integers starting from -1 to not conflict with the positive integers used by the Lean REPL.</p> <p>Note: the session cache is specific to each <code>AutoLeanServer</code> instance and is cleared when the instance is deleted.         If you want truly persistent states, you can use the <code>pickle</code> and <code>unpickle</code> methods to save and load states to disk.</p> <p>\u26a0 Multiprocessing: instantiate the config before starting multiprocessing. Then instantiate one <code>LeanServer</code> per process by passing the config instance to the constructor. This will ensure that the REPL is already set up for your specific environment and avoid concurrency conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LeanREPLConfig</code> <p>The configuration for the Lean server.</p> required <code>max_total_memory</code> <code>float</code> <p>The maximum proportion of system-wide memory usage (across all processes) before triggering a Lean server restart. This is a soft limit ranging from 0.0 to 1.0, with default 0.8 (80%). When system memory exceeds this threshold, the server restarts to free memory. Particularly useful in multiprocessing environments to prevent simultaneous crashes.</p> <code>0.8</code> <code>max_process_memory</code> <code>float | None</code> <p>The maximum proportion of the memory hard limit (set in <code>LeanREPLConfig.memory_hard_limit_mb</code>) that the Lean server process can use before restarting. This soft limit ranges from 0.0 to 1.0, with default 0.8 (80%). Only applied if a hard limit is configured in <code>LeanREPLConfig</code>.</p> <code>0.8</code> <code>max_restart_attempts</code> <code>int</code> <p>The maximum number of consecutive restart attempts allowed before raising a <code>MemoryError</code> exception. Default is 5. The server uses exponential backoff between restart attempts.</p> <code>5</code> Source code in <code>src/lean_interact/server.py</code> <pre><code>def __init__(\n    self,\n    config: LeanREPLConfig,\n    max_total_memory: float = 0.8,\n    max_process_memory: float | None = 0.8,\n    max_restart_attempts: int = 5,\n):\n    \"\"\"\n    This class is a Python wrapper for the Lean REPL. `AutoLeanServer` differs from `LeanServer` by automatically \\\n    restarting when it runs out of memory to clear Lean environment states. \\\n    It also automatically recovers from timeouts (). \\\n    An exponential backoff strategy is used to restart the server, making this class slightly more friendly for multiprocessing\n    than `LeanServer` when multiple instances are competing for resources. \\\n    Please refer to the original [Lean REPL documentation](https://github.com/leanprover-community/repl) to learn more about the \\\n    Lean REPL commands.\n\n    A session cache is implemented to keep user-selected environment / proof states across these automatic restarts. \\\n    Use the `add_to_session_cache` parameter in the different class methods to add the command to \\\n    the session cache. `AutoLeanServer` works best when only a few states are cached simultaneously. \\\n    You can use `remove_from_session_cache` and `clear_session_cache` to clear the session cache. \\\n    Cached state indices are negative integers starting from -1 to not conflict with the positive integers used by the Lean REPL.\n\n    **Note:** the session cache is specific to each `AutoLeanServer` instance and is cleared when the instance is deleted. \\\n    If you want truly persistent states, you can use the `pickle` and `unpickle` methods to save and load states to disk.\n\n    \\u26a0 Multiprocessing: instantiate the config before starting multiprocessing. Then instantiate one `LeanServer`\n    per process by passing the config instance to the constructor. This will ensure that the REPL is already set up\n    for your specific environment and avoid concurrency conflicts.\n\n    Args:\n        config: The configuration for the Lean server.\n        max_total_memory: The maximum proportion of system-wide memory usage (across all processes) before triggering a Lean server restart. This is a soft limit ranging from 0.0 to 1.0, with default 0.8 (80%). When system memory exceeds this threshold, the server restarts to free memory. Particularly useful in multiprocessing environments to prevent simultaneous crashes.\n        max_process_memory: The maximum proportion of the memory hard limit (set in `LeanREPLConfig.memory_hard_limit_mb`) that the Lean server process can use before restarting. This soft limit ranges from 0.0 to 1.0, with default 0.8 (80%). Only applied if a hard limit is configured in `LeanREPLConfig`.\n        max_restart_attempts: The maximum number of consecutive restart attempts allowed before raising a `MemoryError` exception. Default is 5. The server uses exponential backoff between restart attempts.\n    \"\"\"\n    self._state_counter = 0\n    self._restart_persistent_session_cache: dict[int, _SessionState] = {}\n    self._max_total_memory = max_total_memory\n    self._max_process_memory = max_process_memory\n    self._max_restart_attempts = max_restart_attempts\n    super().__init__(config=config)\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.async_run","title":"<code>async_run(request, *, verbose=False, timeout=DEFAULT_TIMEOUT, add_to_session_cache=False)</code>  <code>async</code>","text":"<pre><code>async_run(\n    request: Command\n    | FileCommand\n    | PickleEnvironment\n    | UnpickleEnvironment,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; CommandResponse | LeanError\n</code></pre><pre><code>async_run(\n    request: ProofStep\n    | PickleProofState\n    | UnpickleProofState,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; ProofStepResponse | LeanError\n</code></pre> <p>Asynchronous version of run() for AutoLeanServer. Runs the blocking run() in a thread pool.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>async def async_run(\n    self,\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Asynchronous version of run() for AutoLeanServer. Runs the blocking run() in a thread pool.\n    \"\"\"\n    return await asyncio.to_thread(\n        self.run,\n        request,  # type: ignore\n        verbose=verbose,\n        timeout=timeout,\n        add_to_session_cache=add_to_session_cache,\n    )\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.clear_session_cache","title":"<code>clear_session_cache(force=False)</code>","text":"<p>Clear the session cache.</p> <p>Parameters:</p> Name Type Description Default <code>force</code> <code>bool</code> <p>Whether to directly clear the session cache.                 <code>force=False</code> will only clear the session cache the next time the server runs out of memory while                 still allowing you to add new content in the session cache in the meantime.</p> <code>False</code> Source code in <code>src/lean_interact/server.py</code> <pre><code>def clear_session_cache(self, force: bool = False) -&gt; None:\n    \"\"\"\n    Clear the session cache.\n\n    Args:\n        force: Whether to directly clear the session cache. \\\n            `force=False` will only clear the session cache the next time the server runs out of memory while \\\n            still allowing you to add new content in the session cache in the meantime.\n    \"\"\"\n    states_data = list(self._restart_persistent_session_cache.values())\n    for state_data in states_data:\n        self.remove_from_session_cache(session_state_id=state_data.session_id)\n    self._restart_persistent_session_cache = {}\n    if force:\n        self.restart()\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.remove_from_session_cache","title":"<code>remove_from_session_cache(session_state_id)</code>","text":"<p>Remove an environment from the session cache.</p> <p>Parameters:</p> Name Type Description Default <code>session_state_id</code> <code>int</code> <p>The session state id to remove.</p> required Source code in <code>src/lean_interact/server.py</code> <pre><code>def remove_from_session_cache(self, session_state_id: int) -&gt; None:\n    \"\"\"\n    Remove an environment from the session cache.\n\n    Args:\n        session_state_id: The session state id to remove.\n    \"\"\"\n    if (state_cache := self._restart_persistent_session_cache.pop(session_state_id, None)) is not None:\n        pickle_file = state_cache.pickle_file\n        with FileLock(f\"{pickle_file}.lock\", timeout=60):\n            if os.path.exists(pickle_file):\n                os.remove(pickle_file)\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.run","title":"<code>run(request, *, verbose=False, timeout=DEFAULT_TIMEOUT, add_to_session_cache=False)</code>","text":"<pre><code>run(\n    request: Command\n    | FileCommand\n    | PickleEnvironment\n    | UnpickleEnvironment,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; CommandResponse | LeanError\n</code></pre><pre><code>run(\n    request: ProofStep\n    | PickleProofState\n    | UnpickleProofState,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; ProofStepResponse | LeanError\n</code></pre> <p>Run a Lean REPL request with optional session caching.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BaseREPLQuery</code> <p>The Lean REPL request to execute. Must be one of the following types: - <code>Command</code> - <code>File</code> - <code>ProofStep</code> - <code>PickleEnvironment</code> - <code>PickleProofState</code> - <code>UnpickleEnvironment</code> - <code>UnpickleProofState</code></p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <p>Returns:</p> Type Description <code>BaseREPLResponse | LeanError</code> <p>Depending on the request type, the response will be one of the following:</p> <code>BaseREPLResponse | LeanError</code> <ul> <li><code>CommandResponse</code></li> </ul> <code>BaseREPLResponse | LeanError</code> <ul> <li><code>ProofStepResponse</code></li> </ul> <code>BaseREPLResponse | LeanError</code> <ul> <li><code>LeanError</code></li> </ul> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run(\n    self,\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Run a Lean REPL request with optional session caching.\n\n    Args:\n        request: The Lean REPL request to execute. Must be one of the following types:\n            - `Command`\n            - `File`\n            - `ProofStep`\n            - `PickleEnvironment`\n            - `PickleProofState`\n            - `UnpickleEnvironment`\n            - `UnpickleProofState`\n        verbose: Whether to print additional information\n        timeout: The timeout for the request in seconds\n\n    Returns:\n        Depending on the request type, the response will be one of the following:\n        - `CommandResponse`\n        - `ProofStepResponse`\n        - `LeanError`\n    \"\"\"\n    request_dict = request.model_dump(exclude_none=True, by_alias=True)\n    result_dict = self._run_dict_backoff(request=request_dict, verbose=verbose, timeout=timeout)\n\n    if set(result_dict.keys()) == {\"message\"} or result_dict == {}:\n        result = LeanError.model_validate(result_dict)\n    elif isinstance(request, (Command, FileCommand, PickleEnvironment, UnpickleEnvironment)):\n        result = CommandResponse.model_validate(result_dict)\n        if add_to_session_cache:\n            env_id = result.env\n            hash_key = f\"request_{type(request).__name__}_{id(request)}\"\n            new_env_id = self._store_session_cache(\n                hash_key=hash_key, repl_id=env_id, is_proof_state=False, verbose=verbose\n            )\n            result = result.model_copy(update={\"env\": new_env_id})\n    elif isinstance(request, (ProofStep, PickleProofState, UnpickleProofState)):\n        result = ProofStepResponse.model_validate(result_dict)\n        if add_to_session_cache:\n            proof_state_id = result.proof_state\n            hash_key = f\"proofstep_{type(request).__name__}_{id(request)}\"\n            new_proof_state_id = self._store_session_cache(\n                hash_key=hash_key, repl_id=proof_state_id, is_proof_state=True, verbose=verbose\n            )\n            result = result.model_copy(update={\"proofState\": new_proof_state_id})\n    else:\n        result = BaseREPLResponse.model_validate(result_dict)\n\n    return result\n</code></pre>"},{"location":"api/server/#session-state-helper","title":"Session State Helper","text":""},{"location":"api/server/#lean_interact.server._SessionState","title":"<code>lean_interact.server._SessionState</code>  <code>dataclass</code>","text":"Source code in <code>src/lean_interact/server.py</code> <pre><code>@dataclass\nclass _SessionState:\n    session_id: int\n    repl_id: int\n    pickle_file: str\n    is_proof_state: bool\n</code></pre>"},{"location":"api/server/#timeout-configuration","title":"Timeout Configuration","text":""},{"location":"api/utils/","title":"Utilities API","text":"<p>This page documents the utility functions and classes used in LeanInteract.</p>"},{"location":"api/utils/#installation-and-cache-management","title":"Installation and Cache Management","text":""},{"location":"api/utils/#lean_interact.utils.install_lean","title":"<code>lean_interact.utils.install_lean()</code>","text":"<p>Install Lean 4 version manager (elan) in a cross-platform compatible way. Uses platform-specific methods for Windows, macOS, and Linux.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def install_lean():\n    \"\"\"\n    Install Lean 4 version manager (elan) in a cross-platform compatible way.\n    Uses platform-specific methods for Windows, macOS, and Linux.\n    \"\"\"\n    try:\n        os_name = platform.system()\n        logger.info(\"Detected operating system: %s\", os_name)\n\n        if os_name == \"Windows\":\n            # Check long path support on Windows before installing Lean\n            check_windows_long_paths()\n\n            # Windows installation - use PowerShell with proper error handling\n            logger.info(\"Installing elan for Windows...\")\n\n            # Download the PowerShell script\n            dl_cmd = \"curl -O --location https://raw.githubusercontent.com/leanprover/elan/master/elan-init.ps1\"\n            subprocess.run(dl_cmd, shell=True, check=True)\n\n            ps_cmd = \"powershell -ExecutionPolicy Bypass -Command \\\"&amp; './elan-init.ps1' -NoPrompt $true -DefaultToolchain stable\\\"\"\n            subprocess.run(ps_cmd, shell=True, check=True)\n\n            cleanup_cmd = \"del elan-init.ps1\"\n            subprocess.run(cleanup_cmd, shell=True, check=True)\n\n            logger.info(\n                \"Elan has been installed. You may need to restart your terminal for the PATH changes to take effect.\"\n            )\n\n        else:  # Unix-like systems\n            if os_name in [\"Linux\", \"Darwin\"]:\n                command = \"curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh -s -- -y --default-toolchain stable\"\n            else:\n                raise RuntimeError(\n                    f\"Unsupported operating system: {os_name}. Please install elan manually: \"\n                    \"https://leanprover-community.github.io/get_started.html\"\n                )\n\n            subprocess.run(command, shell=True, check=True)\n\n            # Add to PATH in common shell config files\n            user_home = os.path.expanduser(\"~\")\n            shell_configs = [\".bashrc\", \".zshrc\", \".bash_profile\", \".profile\"]\n            for config in shell_configs:\n                config_path = os.path.join(user_home, config)\n                if os.path.exists(config_path):\n                    try:\n                        with open(config_path, \"a\", encoding=\"utf-8\") as file:\n                            file.write('\\nexport PATH=\"$HOME/.elan/bin:$PATH\"\\n')\n                        logger.info(\"Added elan to PATH in %s\", config_path)\n                    except Exception as e:\n                        logger.warning(\"Could not modify %s: %s\", config_path, e)\n\n            logger.info(\"Please restart your terminal or run 'source ~/.profile' to update your PATH\")\n\n        logger.info(\"Lean installation completed successfully.\")\n\n    except subprocess.CalledProcessError as e:\n        logger.warning(\n            \"An error occurred during Lean installation: %s\\n\"\n            \"Please check https://leanprover-community.github.io/get_started.html for more information.\",\n            e,\n        )\n        raise e\n    except Exception as e:\n        logger.warning(\n            \"Unexpected error during Lean installation: %s\\nPlease try installing manually: https://leanprover-community.github.io/get_started.html\",\n            e,\n        )\n        raise e\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.clear_cache","title":"<code>lean_interact.utils.clear_cache()</code>","text":"Source code in <code>src/lean_interact/utils.py</code> <pre><code>def clear_cache():\n    shutil.rmtree(DEFAULT_CACHE_DIR, ignore_errors=True)\n</code></pre>"},{"location":"api/utils/#project-utilities","title":"Project Utilities","text":""},{"location":"api/utils/#lean_interact.utils.get_project_lean_version","title":"<code>lean_interact.utils.get_project_lean_version(project_dir)</code>","text":"<p>Get the Lean version used in a project.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def get_project_lean_version(project_dir: str) -&gt; str | None:\n    \"\"\"\n    Get the Lean version used in a project.\n    \"\"\"\n    toolchain_file = os.path.join(project_dir, \"lean-toolchain\")\n    if os.path.isfile(toolchain_file):\n        with open(toolchain_file, \"r\", encoding=\"utf-8\") as f:\n            content = f.read().strip()\n            if content:\n                try:\n                    return content.split(\":\")[-1]\n                except Exception:\n                    pass\n    return None\n</code></pre>"},{"location":"api/utils/#windows-path-utilities","title":"Windows Path Utilities","text":""},{"location":"api/utils/#lean_interact.utils.check_windows_long_paths","title":"<code>lean_interact.utils.check_windows_long_paths()</code>","text":"<p>Check if long paths are enabled if running on Windows.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def check_windows_long_paths():\n    \"\"\"Check if long paths are enabled if running on Windows.\"\"\"\n    if platform.system() != \"Windows\":\n        return\n\n    # Try to check if long paths are enabled via registry key\n    try:\n        import winreg\n\n        key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, r\"SYSTEM\\CurrentControlSet\\Control\\FileSystem\")\n        value, _ = winreg.QueryValueEx(key, \"LongPathsEnabled\")\n        if value == 1:\n            logger.info(\"Windows long paths already enabled\")\n        else:\n            logger.info(\"For optimal use on Windows, enable long paths by running this command as administrator:\")\n            logger.info(\n                'New-ItemProperty -Path \"HKLM:\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\FileSystem\" -Name LongPathsEnabled -Value 1 -PropertyType DWord -Force'\n            )\n    except Exception as e:\n        logger.warning(f\"Could not check Windows long path setting: {e}\")\n\n    # Check if git core.longpaths is already configured\n    result = subprocess.run(\n        [\"git\", \"config\", \"--get\", \"core.longpaths\"],\n        check=False,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n    )\n\n    if result.returncode == 0 and result.stdout.strip() == \"true\":\n        logger.info(\"Git already configured for long paths\")\n    else:\n        logger.info(\"For optimal use on Windows, configure git for long paths by running:\")\n        logger.info(\"git config --global core.longpaths true\")\n</code></pre>"},{"location":"api/utils/#memory-management","title":"Memory Management","text":""},{"location":"api/utils/#lean_interact.utils.get_total_memory_usage","title":"<code>lean_interact.utils.get_total_memory_usage(proc)</code>","text":"<p>Get total resident memory usage of a process and its children (in bytes).</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def get_total_memory_usage(proc: psutil.Process):\n    \"\"\"Get total resident memory usage of a process and its children (in bytes).\"\"\"\n    try:\n        total = proc.memory_info().rss\n        for child in proc.children(recursive=True):\n            total += child.memory_info().rss\n        return total\n    except psutil.NoSuchProcess:\n        return 0\n</code></pre>"},{"location":"api/utils/#lean_interact.utils._limit_memory","title":"<code>lean_interact.utils._limit_memory(max_mb)</code>","text":"<p>Limit the memory usage of the current process.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def _limit_memory(max_mb: int | None):\n    \"\"\"Limit the memory usage of the current process.\"\"\"\n    if max_mb is None:\n        return\n    try:\n        import resource\n\n        resource.setrlimit(resource.RLIMIT_AS, (max_mb * 1024 * 1024, max_mb * 1024 * 1024))\n        # logger.info(\"Memory usage limited to %d MB\", max_mb)\n    except ValueError:\n        # logger.warning(\"Failed to set memory limit to %d MB.\", max_mb)\n        pass\n    except ImportError:\n        # logger.warning(\"Memory limits not supported on this platform.\")\n        pass\n    except Exception as e:\n        # logger.warning(\"Error while setting memory limit: %s\", e)\n        pass\n</code></pre>"},{"location":"api/utils/#code-processing-utilities","title":"Code Processing Utilities","text":""},{"location":"api/utils/#lean_interact.utils.indent_code","title":"<code>lean_interact.utils.indent_code(code, nb_spaces=2)</code>","text":"Source code in <code>src/lean_interact/utils.py</code> <pre><code>def indent_code(code: str, nb_spaces: int = 2) -&gt; str:\n    return \"\\n\".join(\" \" * nb_spaces + line for line in code.split(\"\\n\"))\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.compress_newlines","title":"<code>lean_interact.utils.compress_newlines(lean_code)</code>","text":"Source code in <code>src/lean_interact/utils.py</code> <pre><code>def compress_newlines(lean_code: str):\n    # compress lines containing only whitespaces\n    lean_code = re.sub(r\"^\\s+$\", \"\", lean_code, flags=re.MULTILINE)\n    # Compress multiple consecutive newlines\n    lean_code = re.sub(r\"\\n\\n+\", \"\\n\\n\", lean_code)\n    lean_code = lean_code.lstrip()\n    if lean_code.endswith(\"\\n\"):\n        lean_code = lean_code.rstrip() + \"\\n\"\n    return lean_code\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.lean_comments_ranges","title":"<code>lean_interact.utils.lean_comments_ranges(lean_code, multiline_comment_suffix='', remove_single_line_comments=True)</code>","text":"<p>Extract the ranges of Lean comments from a Lean code snippet.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def lean_comments_ranges(\n    lean_code: str, multiline_comment_suffix: str = \"\", remove_single_line_comments: bool = True\n) -&gt; list[tuple[int, int]]:\n    \"\"\"Extract the ranges of Lean comments from a Lean code snippet.\"\"\"\n    # multiline comments\n    open_comment_indices = [m.start() for m in re.finditer(r\"/-\" + multiline_comment_suffix, lean_code)]\n    close_comment_indices = [\n        m.start() + len(multiline_comment_suffix) + 2 for m in re.finditer(multiline_comment_suffix + r\"-/\", lean_code)\n    ]\n\n    if len(open_comment_indices) == len(close_comment_indices) + 1:\n        # the last comment has probably not been closed due to partial code\n        close_comment_indices.append(len(lean_code))\n\n    elif len(open_comment_indices) + 1 == len(close_comment_indices):\n        # the first comment has probably been opened before the code snippet\n        open_comment_indices.insert(0, 0)\n\n    elif len(open_comment_indices) != len(close_comment_indices):\n        raise ValueError(\"Mismatched open and close comment indices.\")\n\n    # trick to handle nested comments in a simple way\n    multiline_comment_ranges = list(zip(open_comment_indices, close_comment_indices))\n\n    if remove_single_line_comments:\n        # single line comments\n        single_line_comment_ranges = [\n            (m.start(), lean_code.find(\"\\n\", m.start())) for m in re.finditer(r\"--\", lean_code)\n        ]\n        multiline_comment_ranges += single_line_comment_ranges\n\n    # merge potential overlapping ranges\n    comment_ranges = sorted(multiline_comment_ranges, key=lambda x: x[0])\n    merged_comment_ranges: list[tuple[int, int]] = []\n    for start, end in comment_ranges:\n        if merged_comment_ranges and start &lt;= merged_comment_ranges[-1][1]:\n            merged_comment_ranges[-1] = (merged_comment_ranges[-1][0], max(merged_comment_ranges[-1][1], end))\n        else:\n            merged_comment_ranges.append((start, end))\n\n    return merged_comment_ranges\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.remove_lean_comments","title":"<code>lean_interact.utils.remove_lean_comments(lean_code)</code>","text":"Source code in <code>src/lean_interact/utils.py</code> <pre><code>def remove_lean_comments(lean_code: str) -&gt; str | None:\n    try:\n        comment_ranges = lean_comments_ranges(lean_code)\n\n        new_lean_code = \"\"\n        prev_start = 0\n        for start, end in comment_ranges:\n            new_lean_code += lean_code[prev_start:start]\n            prev_start = end\n\n        new_lean_code += lean_code[prev_start:]\n        return new_lean_code\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.split_implementation","title":"<code>lean_interact.utils.split_implementation(declaration, start=0)</code>","text":"Source code in <code>src/lean_interact/utils.py</code> <pre><code>def split_implementation(declaration: str, start: int = 0):\n    # for a theorem, an implementation is the proof\n    if \":=\" in declaration:\n        # we have to be careful here as \":=\" can be used inside the declaration itself\n        indices = set([m.start() for m in re.finditer(r\":=\", declaration)])\n\n        # we remove the ones related to \"let\", \"haveI\", ... declarations\n        for keyword in [\"let\", \"haveI\"]:\n            regex = rf\"{keyword}\\s+\\S*?\\s*(:=)\"\n            decl_indices = set([m.start(1) for m in re.finditer(regex, declaration)])\n            indices = indices - decl_indices\n\n        # implementation using pcre2 blows up the memory, and it turns out it is faster to use a python loop\n        counters = {\"(\": 0, \"{\": 0, \"[\": 0}\n        closing = {\")\": \"(\", \"}\": \"{\", \"]\": \"[\"}\n        for i, c in enumerate(declaration[start:]):\n            if c in counters:\n                counters[c] += 1\n            elif c in [\")\", \"}\", \"]\"]:\n                counters[closing[c]] -= 1\n            if all([v == 0 for v in counters.values()]) and (i + start) in indices:\n                return i + start\n    return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.split_conclusion","title":"<code>lean_interact.utils.split_conclusion(declaration, start=0)</code>","text":"Source code in <code>src/lean_interact/utils.py</code> <pre><code>def split_conclusion(declaration: str, start: int = 0) -&gt; int | None:\n    counters = {\"(\": 0, \"{\": 0, \"[\": 0}\n    closing = {\")\": \"(\", \"}\": \"{\", \"]\": \"[\"}\n    for i, c in enumerate(declaration[start:]):\n        if c in counters:\n            counters[c] += 1\n        elif c in [\")\", \"}\", \"]\"]:\n            counters[closing[c]] -= 1\n        if all([v == 0 for v in counters.values()]) and c == \":\":\n            return i + start\n    return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.clean_theorem_string","title":"<code>lean_interact.utils.clean_theorem_string(theorem_string, new_theorem_name='dummy', add_sorry=True)</code>","text":"<p>Clean a theorem string by removing the proof, comments, and updating the theorem name. This method assumes that no other declarations are present in the theorem string.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def clean_theorem_string(theorem_string: str, new_theorem_name: str = \"dummy\", add_sorry: bool = True) -&gt; str | None:\n    \"\"\"Clean a theorem string by removing the proof, comments, and updating the theorem name.\n    This method assumes that no other declarations are present in the theorem string.\"\"\"\n    try:\n        # clean the theorem string\n        clean_formal = remove_lean_comments(theorem_string)\n        if clean_formal is None:\n            raise ValueError(\"Comment removal failed.\")\n        clean_formal = clean_formal.strip()\n\n        # we remove the first part of the string until the first \"theorem\" or \"lemma\" keyword\n        theorem_decl_keywords = \"|\".join([\"theorem\", \"lemma\", \"example\"])\n        re_match = re.search(rf\"\\b{theorem_decl_keywords}\\s\", clean_formal)\n        if re_match is None:\n            raise ValueError(\"Theorem declaration keyword not found.\")\n        idx_theorem = re_match.start()\n        clean_formal = clean_formal[idx_theorem:]\n\n        # if a proof is provided we remove it\n        idx_implement = split_implementation(clean_formal)\n        if idx_implement is not None:\n            clean_formal = clean_formal[:idx_implement].strip()\n\n        # remove \"theorem\" and the theorem name\n        if clean_formal.strip().startswith(\"example\"):\n            clean_formal = re.sub(r\"^[^\\s]+\", \"\", clean_formal).strip()\n        else:\n            clean_formal = re.sub(r\"^[^\\s]+\", \"\", clean_formal).strip()\n            clean_formal = re.sub(r\"^[^\\s:({\\[]+\", \"\", clean_formal).strip()\n        clean_formal = f\"theorem {new_theorem_name} \" + clean_formal\n        if add_sorry:\n            clean_formal += \" := by sorry\"\n        return clean_formal\n    except Exception:\n        return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.extract_last_theorem","title":"<code>lean_interact.utils.extract_last_theorem(lean_code)</code>","text":"<p>Extract the last theorem from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def extract_last_theorem(lean_code: str) -&gt; int:\n    \"\"\"Extract the last theorem from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.\"\"\"\n    comments_ranges = lean_comments_ranges(lean_code)\n\n    # find last theorem by looking for `theorem` keyword surrounded by whitespaces, or by being at the beginning of the string\n    theorem_decl_keywords = [\"theorem\", \"lemma\", \"example\"]\n    theorem_indices = []\n    for keyword in theorem_decl_keywords:\n        theorem_indices += [m.start() for m in re.finditer(rf\"\\b{keyword}\\s\", lean_code)]\n\n    # remove matches that are inside comments\n    theorem_indices = [idx for idx in theorem_indices if not any(start &lt;= idx &lt;= end for start, end in comments_ranges)]\n\n    if not theorem_indices:\n        raise ValueError(f\"No theorem found in the provided Lean code:\\n{lean_code}\")\n\n    return theorem_indices[-1]\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.clean_last_theorem_string","title":"<code>lean_interact.utils.clean_last_theorem_string(lean_code, new_theorem_name='dummy', add_sorry=False)</code>","text":"<p>Clean the last theorem string from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def clean_last_theorem_string(lean_code: str, new_theorem_name: str = \"dummy\", add_sorry: bool = False) -&gt; str:\n    \"\"\"Clean the last theorem string from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.\"\"\"\n    idx_last_theorem = extract_last_theorem(lean_code)\n    clean_thm = clean_theorem_string(lean_code[idx_last_theorem:], new_theorem_name, add_sorry=add_sorry)\n    if clean_thm is not None:\n        return lean_code[:idx_last_theorem] + clean_thm\n\n    raise ValueError(f\"Theorem extraction failed for the following Lean code:\\n{lean_code}\")\n</code></pre>"},{"location":"api/utils/#constants","title":"Constants","text":""},{"location":"user-guide/basic-usage/","title":"Basic Usage","text":"<p>This guide covers the fundamental operations and command types in LeanInteract.</p>"},{"location":"user-guide/basic-usage/#basic-command-execution","title":"Basic Command Execution","text":"<p>The most common operation in LeanInteract is executing Lean code directly using the <code>Command</code> class:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Run a simple theorem\nserver.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\n</code></pre> <pre><code>CommandResponse(env=0, messages=[Message(data='Goals accomplished!', end_pos=Pos(line=1, column=42), severity='info', start_pos=Pos(line=1, column=0))])\n</code></pre> <p>The response contains:</p> <ul> <li>An environment state (<code>env</code>) that can be used for subsequent commands</li> <li>Messages returned by Lean (errors, information, etc.)</li> </ul>"},{"location":"user-guide/basic-usage/#working-with-environment-states","title":"Working with Environment States","text":"<p>Each command execution creates a new environment state. You can use this state in subsequent commands:</p> <pre><code># First command creates environment state\nresponse1 = server.run(Command(cmd=\"def x := 5\"))\n\n# Use environment state 0 for the next command\nserver.run(Command(cmd=\"#check x\", env=response1.env))\n</code></pre> <pre><code>CommandResponse(env=2, messages=[Message(data='x : Nat', end_pos=Pos(line=1, column=6), severity='info', start_pos=Pos(line=1, column=0))])\n</code></pre>"},{"location":"user-guide/basic-usage/#processing-lean-files","title":"Processing Lean Files","text":"<p>You can process entire Lean files using the <code>FileCommand</code> class:</p> <pre><code>from lean_interact import FileCommand\n\n# Process a Lean file\nresponse = server.run(FileCommand(path=\"myfile.lean\"))\n\n# With options to get more information about goals\nresponse = server.run(FileCommand(path=\"myfile.lean\", root_goals=True))\n</code></pre>"},{"location":"user-guide/basic-usage/#available-options","title":"Available Options","text":"<p>Both <code>Command</code> and <code>FileCommand</code> support several options:</p> <ul> <li><code>all_tactics</code>: Get information about tactics used</li> <li><code>root_goals</code>: Get information about goals in theorems and definitions</li> <li><code>infotree</code>: Get Lean infotree containing various informations about declarations and tactics</li> </ul> <p>Example with options:</p> <pre><code>response = server.run(Command(\n    cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := by simp\",\n    all_tactics=True\n))\nprint(response.tactics)  # Shows tactics used\n</code></pre> <pre><code>[Tactic(proof_state=0, used_constants=['Init.Core._auxLemma.4', 'instOfNatNat', 'Nat', 'of_eq_true', 'OfNat.ofNat', 'Eq'], end_pos=Pos(line=1, column=47), start_pos=Pos(line=1, column=43), goals='n : Nat\\n\u22a2 n = 5 \u2192 n = 5', tactic='simp')]\n</code></pre>"},{"location":"user-guide/basic-usage/#working-with-sorries","title":"Working with Sorries","text":"<p>When Lean code contains <code>sorry</code> (incomplete proofs), LeanInteract returns information about these <code>sorry</code>:</p> <pre><code>response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nprint(response.sorries[0])\n</code></pre> <pre><code>Sorry(proof_state=1, goal='n : Nat\\n\u22a2 n = 5 \u2192 n = 5', end_pos=Pos(line=1, column=45), start_pos=Pos(line=1, column=40))\n</code></pre> <p>This response will include a list of <code>Sorry</code> objects, each containing:</p> <ul> <li>Position in the code</li> <li>Goal to be proven</li> <li>Proof state ID (can be used with <code>ProofStep</code> commands)</li> </ul>"},{"location":"user-guide/basic-usage/#error-handling","title":"Error Handling","text":"<p>It's good practice to handle errors that might occur during execution:</p> <pre><code>from lean_interact.interface import LeanError\n\ntry:\n    response = server.run(Command(cmd=\"invalid Lean code\"))\n    if isinstance(response, LeanError):\n        print(\"Command failed with fatal error(s):\", response.message)\n    else:\n        print(\"Command succeeded:\", response) # but the content may contain errors !!\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n</code></pre> <pre><code>Command succeeded: CommandResponse(env=5, messages=[Message(data='unexpected identifier; expected command', end_pos=Pos(line=1, column=7), severity='error', start_pos=Pos(line=1, column=0))])\n</code></pre>"},{"location":"user-guide/basic-usage/#next-steps","title":"Next Steps","text":"<p>Now that you understand basic operations, you can:</p> <ul> <li>Learn about tactic mode for step-by-step proof interaction</li> <li>Configure custom Lean environments</li> <li>Explore the API Reference for more command options</li> </ul>"},{"location":"user-guide/custom-lean-configuration/","title":"Custom Lean Configuration","text":"<p>LeanInteract provides flexible ways to configure the Lean environment to suit different use cases. This guide covers the various configuration options available.</p>"},{"location":"user-guide/custom-lean-configuration/#specifying-lean-versions","title":"Specifying Lean Versions","text":"<p>You can specify which version of Lean 4 you want to use:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer\n\n# Use a specific Lean version\nconfig = LeanREPLConfig(lean_version=\"v4.7.0\")\nserver = LeanServer(config)\n</code></pre> <p>LeanInteract supports all Lean versions between <code>v4.7.0-rc1</code> and <code>v4.19.0</code>.</p>"},{"location":"user-guide/custom-lean-configuration/#working-with-existing-projects","title":"Working with Existing Projects","text":""},{"location":"user-guide/custom-lean-configuration/#local-lean-projects","title":"Local Lean Projects","text":"<p>To work with a local Lean project:</p> <pre><code>from lean_interact import LeanREPLConfig, LocalProject, LeanServer\n\n# Configure with a local project\nconfig = LeanREPLConfig(project=LocalProject(\"path/to/your/project\"))\nserver = LeanServer(config)\n</code></pre> <p>Important</p> <p>Ensure the project can be successfully built with <code>lake build</code> before using it with LeanInteract.</p>"},{"location":"user-guide/custom-lean-configuration/#git-based-projects","title":"Git-Based Projects","text":"<p>You can also work with projects hosted on Git:</p> <pre><code>from lean_interact import LeanREPLConfig, GitProject, LeanServer\n\n# Configure with a Git-hosted project\nconfig = LeanREPLConfig(project=GitProject(\"https://github.com/yangky11/lean4-example\"))\nserver = LeanServer(config)\n</code></pre>"},{"location":"user-guide/custom-lean-configuration/#working-with-temporary-projects","title":"Working with Temporary Projects","text":"<p>LeanInteract allows you to create temporary projects with dependencies for experimentation without affecting your local environment.</p>"},{"location":"user-guide/custom-lean-configuration/#simple-temporary-projects-with-dependencies","title":"Simple Temporary Projects with Dependencies","text":"<p>To create a temporary project with dependencies:</p> <pre><code>from lean_interact import LeanREPLConfig, TempRequireProject, LeanRequire\n\n# Create a temporary project with Mathlib as a dependency\nconfig = LeanREPLConfig(\n    lean_version=\"v4.7.0\",\n    project=TempRequireProject([\n        LeanRequire(\n            name=\"mathlib\",\n            git=\"https://github.com/leanprover-community/mathlib4.git\",\n            rev=\"v4.7.0\"\n        )\n    ])\n)\n</code></pre> <p>For the common case of requiring Mathlib, there's a shortcut:</p> <pre><code>config = LeanREPLConfig(lean_version=\"v4.7.0\", project=TempRequireProject(\"mathlib\"))\n</code></pre>"},{"location":"user-guide/custom-lean-configuration/#fine-grained-temporary-projects","title":"Fine-Grained Temporary Projects","text":"<p>For more control over the temporary project, you can specify the complete lakefile content:</p> <pre><code>from lean_interact import LeanREPLConfig, TemporaryProject\n\nconfig = LeanREPLConfig(\n    lean_version=\"v4.18.0\",\n    project=TemporaryProject(\"\"\"\nimport Lake\nopen Lake DSL\n\npackage \"dummy\" where\n  version := v!\"0.1.0\"\n\n@[default_target]\nlean_exe \"dummy\" where\n  root := `Main\n\nrequire mathlib from git\n  \"https://github.com/leanprover-community/mathlib4.git\" @ \"v4.18.0\"\n\"\"\")\n)\n</code></pre> <p>This approach gives you full control over the Lake configuration.</p>"},{"location":"user-guide/custom-lean-configuration/#best-practices","title":"Best Practices","text":"<ul> <li>Check the Lean version your project is compatible with and use that version in your configuration</li> <li>Initialize <code>LeanREPLConfig</code> before starting parallel processes to avoid conflicts, and then copy it in the child processes when instantiating <code>LeanServer</code></li> </ul>"},{"location":"user-guide/getting-started/","title":"Getting Started with LeanInteract","text":"<p>This guide will help you take your first steps with LeanInteract and understand its core concepts.</p>"},{"location":"user-guide/getting-started/#overview","title":"Overview","text":"<p>LeanInteract provides a Python interface to the Lean 4 theorem prover via the Lean REPL (Read-Evaluate-Print Loop). It enables you to:</p> <ul> <li>Execute Lean code from Python</li> <li>Process Lean files</li> <li>Interact with proofs step by step</li> <li>Save and restore proof states</li> </ul>"},{"location":"user-guide/getting-started/#quick-example","title":"Quick Example","text":"<p>Here's a minimal example to help you get started:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Create a Lean REPL configuration\nconfig = LeanREPLConfig(verbose=True)\n\n# Start a Lean server with the configuration\nserver = LeanServer(config)\n\n# Execute a simple theorem\nresponse = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\n\n# Print the response\nprint(response)\n</code></pre> <pre><code>Build completed successfully.\nCommandResponse(env=0, messages=[Message(data='Goals accomplished!', start_pos=Pos(line=1, column=0), end_pos=Pos(line=1, column=42), severity='info')])\n</code></pre> <p>This will:</p> <ol> <li>Initialize a Lean REPL configuration</li> <li>Start a Lean server</li> <li>Execute a simple Lean theorem</li> <li>Return a response containing the Lean environment state and any messages</li> </ol>"},{"location":"user-guide/getting-started/#understanding-core-components","title":"Understanding Core Components","text":"<p>Let's break down the key components:</p>"},{"location":"user-guide/getting-started/#leanreplconfig","title":"LeanREPLConfig","text":"<p><code>LeanREPLConfig</code> sets up the Lean environment:</p> <pre><code>config = LeanREPLConfig(\n    lean_version=\"v4.19.0\",  # Specify Lean version (optional)\n    verbose=True,            # Print detailed logs\n)\n</code></pre> <pre><code>Build completed successfully.\n</code></pre>"},{"location":"user-guide/getting-started/#leanserver","title":"LeanServer","text":"<p><code>LeanServer</code> manages communication with the Lean REPL:</p> <pre><code>server = LeanServer(config)\n</code></pre> <p>A more robust alternative is <code>AutoLeanServer</code>, which automatically recovers from (some) crashes:</p> <pre><code>from lean_interact import AutoLeanServer\nauto_server = AutoLeanServer(config)\n</code></pre>"},{"location":"user-guide/getting-started/#commands","title":"Commands","text":"<p>LeanInteract provides several types of commands:</p> <ul> <li><code>Command</code>: Execute Lean code directly</li> <li><code>FileCommand</code>: Process Lean files</li> <li><code>ProofStep</code>: Work with proofs step by step using tactics</li> </ul> <p>Basic command execution:</p> <pre><code>response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\n</code></pre>"},{"location":"user-guide/getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics, you can:</p> <ul> <li>Learn about basic usage patterns</li> <li>Explore tactic mode for step-by-step proof interaction</li> <li>Configure custom Lean environments</li> </ul> <p>Or check out the API Reference for detailed information on all available classes and methods.</p>"},{"location":"user-guide/tactic-mode/","title":"Tactic Mode","text":"<p>Tactic mode in LeanInteract allows you to work with Lean's proof tactics step-by-step, providing an interactive way to develop and explore proofs.</p> <p>Experimental Feature</p> <p>The tactic mode feature is experimental in Lean REPL and may not work as expected in all situations. Some valid proofs might be incorrectly rejected. Please report any issues you encounter on the Lean REPL GitHub repository.</p>"},{"location":"user-guide/tactic-mode/#getting-started-with-tactics","title":"Getting Started with Tactics","text":"<p>Using tactics in LeanInteract involves two main steps:</p> <ol> <li>Creating a proof state using <code>sorry</code> in a theorem</li> <li>Applying tactics to this proof state using <code>ProofStep</code></li> </ol>"},{"location":"user-guide/tactic-mode/#creating-a-proof-state","title":"Creating a Proof State","text":"<p>First, let's create a proof state by defining a theorem with <code>sorry</code>:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Define a theorem with sorry\nresponse = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nprint(response.sorries[0])\n</code></pre> <pre><code>Sorry(proof_state=0, goal='n : Nat\\n\u22a2 n = 5 \u2192 n = 5', start_pos=Pos(line=1, column=40), end_pos=Pos(line=1, column=45))\n</code></pre> <p>This response contains a <code>Sorry</code> object that includes:</p> <ul> <li>A <code>proof_state</code> ID that you can use for tactic commands</li> <li>The current goal that needs to be proven</li> </ul>"},{"location":"user-guide/tactic-mode/#applying-tactics","title":"Applying Tactics","text":"<p>Once you have a proof state, you can apply tactics using the <code>ProofStep</code> class:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command, ProofStep\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Define a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply a single tactic (intro) to the proof state\nserver.run(ProofStep(tactic=\"intro h\", proof_state=proof_state_id))\n</code></pre> <pre><code>ProofStepResponse(proof_status='Incomplete: open goals remain', proof_state=1, goals=['n : Nat\\nh : n = 5\\n\u22a2 n = 5'])\n</code></pre> <p>The response contains:</p> <ul> <li>A new proof state ID for chaining additional tactics</li> <li>The current goal(s)</li> <li>The proof status (complete or incomplete)</li> </ul>"},{"location":"user-guide/tactic-mode/#chaining-tactics","title":"Chaining Tactics","text":"<p>You can chain multiple tactics by using the proof state from each response:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command, ProofStep\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Define a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply 'intro' tactic\nintro_response = server.run(ProofStep(tactic=\"intro h\", proof_state=proof_state_id))\n\n# Apply 'exact' tactic to the resulting proof state\nserver.run(ProofStep(tactic=\"exact h\", proof_state=intro_response.proof_state))\n</code></pre> <pre><code>ProofStepResponse(proof_status='Completed', proof_state=2, goals=[])\n</code></pre>"},{"location":"user-guide/tactic-mode/#applying-multiple-tactics-at-once","title":"Applying Multiple Tactics at Once","text":"<p>You can also apply multiple tactics at once by wrapping them in parentheses:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command, ProofStep\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Define a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply multiple tactics at once\nmulti_response = server.run(ProofStep(tactic=\"\"\"(\nintro h\nexact h\n)\"\"\", proof_state=proof_state_id))\nprint(multi_response)\n</code></pre> <pre><code>ProofStepResponse(proof_status='Completed', proof_state=1, goals=[])\n</code></pre>"},{"location":"user-guide/tactic-mode/#complete-proof-session","title":"Complete Proof Session","text":"<p>The <code>ProofStepResponse</code> contains a <code>proof_status</code> field that indicates whether the proof is complete. Here's a complete example of working with tactics:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command, ProofStep\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Create a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem my_theorem (x : Nat) : x = x := sorry\"))\nprint(\"Initial goal:\", theorem_response.sorries[0].goal)\n\n# Get the proof state from the sorry\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply reflexivity tactic\nfinal_response = server.run(ProofStep(tactic=\"rfl\", proof_state=proof_state_id))\n\n# Check if the proof is complete\nif final_response.proof_status == \"Completed\":\n    print(\"Proof completed successfully!\")\nelse:\n    print(\"Proof failed:\", final_response)\n</code></pre> <pre><code>Initial goal: x : Nat\n\u22a2 x = x\nProof completed successfully!\n</code></pre>"}]}