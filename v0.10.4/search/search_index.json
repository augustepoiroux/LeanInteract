{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LeanInteract","text":"<p>LeanInteract is a Python package designed to seamlessly interact with Lean 4 through the Lean REPL.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd17 Interactivity: Execute Lean code and files directly from Python</li> <li>\ud83d\ude80 Ease of Use: LeanInteract abstracts the complexities of Lean setup and interaction</li> <li>\ud83d\udcbb Cross-platform: Works on Windows, macOS, and Linux operating systems</li> <li>\ud83d\udd27 Compatibility: Supports all Lean versions between <code>v4.8.0-rc1</code> and <code>v4.26.0-rc2</code><ul> <li>We backport the latest features of Lean REPL to older versions of Lean (see fork).</li> </ul> </li> <li>\ud83d\udce6 Temporary Projects: Easily instantiate temporary Lean environments<ul> <li>Useful for experimenting with benchmarks depending on Mathlib like ProofNet# and MiniF2F</li> </ul> </li> <li>\ud83e\uddfe Data extraction: Extract declarations and info trees for analysis and dataset building.</li> <li>\u26a1 Incremental + Parallel elaboration: Automatically reuse partial computations from previous commands, and enable <code>Elab.async</code> for faster processing.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#install-the-package","title":"Install the package","text":"<pre><code>pip install lean-interact\n</code></pre> <p>Install Lean 4 (if not already installed) using the following command coming with LeanInteract:</p> <pre><code>install-lean\n</code></pre>"},{"location":"#start-using-it-in-your-python-scripts","title":"Start using it in your Python scripts","text":"<pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Create a configuration for the Lean REPL\nconfig = LeanREPLConfig(verbose=True)  \n\n# Start the Lean server\nserver = LeanServer(config)  \n\n# Run a simple Lean theorem\nserver.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\n</code></pre> <p>Check out the Installation guide for detailed setup instructions and the User Guide for usage examples.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>This page documents the notable changes to LeanInteract.</p>"},{"location":"changelog/#v0104-december-01-2025","title":"v0.10.4 (December 01, 2025)","text":"<ul> <li>Fix <code>auto_build</code> parameter for git and temporary projects</li> <li>Make REPL build skippable</li> <li>Print <code>check_lake</code> output for debugging (when <code>verbose=True</code>)</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.10.3...v0.10.4</p>"},{"location":"changelog/#v0103-november-25-2025","title":"v0.10.3 (November 25, 2025)","text":"<p>Add support for Lean v4.24.1 and v4.25.2</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.10.2...v0.10.3</p>"},{"location":"changelog/#v0102-november-24-2025","title":"v0.10.2 (November 24, 2025)","text":"<p>Add support for Lean v4.26.0-rc2</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.10.1...v0.10.2</p>"},{"location":"changelog/#v0101-november-24-2025","title":"v0.10.1 (November 24, 2025)","text":"<p>Add support for Lean v4.26.0-rc1</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.10.0...v0.10.1</p>"},{"location":"changelog/#v0100-november-18-2025","title":"v0.10.0 (November 18, 2025)","text":"<ul> <li>Add <code>ReplaySessionCache</code> to replay commands, offering a more reliable alternative to <code>PickleSessionCache</code>. <code>ReplaySessionCache</code> is now the default in <code>AutoLeanServer</code>.</li> <li>Make session caching thread-safe</li> <li>Add support for Lean v4.25.1</li> <li>Add multi-threading examples</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.9.3...v0.10.0</p>"},{"location":"changelog/#v093-november-17-2025","title":"v0.9.3 (November 17, 2025)","text":"<p>Add support for Lean v4.25.0</p>"},{"location":"changelog/#v092-october-22-2025","title":"v0.9.2 (October 22, 2025)","text":"<p>Add support for Lean v4.25.0-rc1 and v4.25.0-rc2.</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.9.1...v0.9.2</p>"},{"location":"changelog/#v091-october-14-2025","title":"v0.9.1 (October 14, 2025)","text":"<p>Add support for Lean v4.24.0</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.9.0...v0.9.1</p>"},{"location":"changelog/#v090-october-13-2025","title":"v0.9.0 (October 13, 2025)","text":""},{"location":"changelog/#whats-changed","title":"What's Changed","text":"<p>New features:</p> <ul> <li>Fine-grained data extraction for Lean declarations https://github.com/leanprover-community/repl/pull/119</li> <li>Incremental elaboration https://github.com/leanprover-community/repl/pull/110<ul> <li>also fixes #6</li> </ul> </li> <li>Parallel elaboration (through <code>set_option</code> support)</li> <li><code>set_option</code> support https://github.com/leanprover-community/repl/pull/119</li> </ul> <p>A few fixes:</p> <ul> <li>https://github.com/leanprover-community/repl/pull/108</li> <li>https://github.com/leanprover-community/repl/pull/109</li> </ul> <p>Add py.typed</p> <ul> <li> </li> </ul> <p>Breaking changes:</p> <ul> <li>Support for Lean v4.7.0 is dropped</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.8.3...v0.9.0</p>"},{"location":"changelog/#32","title":"32","text":""},{"location":"changelog/#v083-september-15-2025","title":"v0.8.3 (September 15, 2025)","text":"<p>Add support for Lean v4.23.0 and v4.24.0-rc1</p>"},{"location":"changelog/#v082-august-15-2025","title":"v0.8.2 (August 15, 2025)","text":"<p>Add support for Lean v4.23.0-rc1 and v4.23.0-rc2</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.8.1...v0.8.2</p>"},{"location":"changelog/#v081-august-14-2025","title":"v0.8.1 (August 14, 2025)","text":"<p>Add support for Lean v4.22.0</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.8.0...v0.8.1</p>"},{"location":"changelog/#v080-july-24-2025","title":"v0.8.0 (July 24, 2025)","text":""},{"location":"changelog/#whats-changed_1","title":"What's Changed","text":"<ul> <li>Separate Lean projects and <code>LeanREPLConfig</code> set up logic by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/30<ul> <li>Project classes can now be used as independent units for managing Lean projects.</li> <li>For new usage, check the projects page in the documentation (minimal breaking changes).</li> </ul> </li> <li>Major update to the documentation (link)<ul> <li>Online documentation now shows documentation for previous package versions by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/31</li> <li>Improved doc interface and content</li> <li>Improved docstrings in the Python package</li> </ul> </li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.7.0...v0.8.0</p>"},{"location":"changelog/#v070-july-04-2025","title":"v0.7.0 (July 04, 2025)","text":""},{"location":"changelog/#whats-changed_2","title":"What's Changed","text":"<ul> <li>Check Lean version formatting by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/27</li> <li>Improve git-related operations by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/28<ul> <li><code>GitProject</code> has a <code>force_pull</code> argument to enforce pulling / reset if the project is already in the cache</li> <li>Similarly, <code>LeanREPLConfig</code> has a <code>force_pull_repl</code> argument. Useful when working on a custom REPL living on an evolving git branch.</li> </ul> </li> <li>Bump REPL to v1.0.12 by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/29<ul> <li><code>FileCommand</code> has now an <code>env</code> field https://github.com/leanprover-community/repl/pull/99</li> <li>Various REPL fixes: https://github.com/leanprover-community/repl/pull/106, https://github.com/leanprover-community/repl/pull/98, https://github.com/leanprover-community/repl/pull/72</li> <li>Syntax nodes now export a few more attributes https://github.com/leanprover-community/repl/pull/89</li> </ul> </li> <li>New <code>LeanServer.get_memory_usage</code> method to monitor REPL memory usage.</li> <li>Add InfoTree pydantic models by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/3<ul> <li>Leverage the new exported attributes for syntax nodes https://github.com/leanprover-community/repl/pull/89</li> </ul> </li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.6.3...v0.7.0</p>"},{"location":"changelog/#v063-july-01-2025","title":"v0.6.3 (July 01, 2025)","text":""},{"location":"changelog/#whats-changed_3","title":"What's Changed","text":"<ul> <li>Add support for Lean v4.22.0-rc1 and v4.22.0-rc2</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.6.2...v0.6.3</p>"},{"location":"changelog/#v062-june-30-2025","title":"v0.6.2 (June 30, 2025)","text":""},{"location":"changelog/#whats-changed_4","title":"What's Changed","text":"<ul> <li>Add support for Lean v4.21.0</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.6.1...v0.6.2</p>"},{"location":"changelog/#v061-june-24-2025","title":"v0.6.1 (June 24, 2025)","text":""},{"location":"changelog/#whats-changed_5","title":"What's Changed","text":"<ul> <li>Fix Lean version inference for <code>LocalProject</code> and <code>GitProject</code> by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/26</li> <li>Fix <code>ResourceWarning</code> issues when killing the REPL</li> <li>Improve memory monitoring in <code>AutoLeanServer</code></li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.6.0...v0.6.1</p>"},{"location":"changelog/#v060-june-05-2025","title":"v0.6.0 (June 05, 2025)","text":""},{"location":"changelog/#whats-changed_6","title":"What's Changed","text":"<ul> <li>Support for local / custom REPL + Lean versions up to v4.21.0-rc3 by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/21</li> <li>Separate the session cache logic from <code>AutoLeanServer</code> by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/18</li> <li>Add documentation by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/19</li> <li>Add support for modern Python Path by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/20</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.3...v0.6.0</p>"},{"location":"changelog/#v053-may-18-2025","title":"v0.5.3 (May 18, 2025)","text":""},{"location":"changelog/#whats-changed_7","title":"What's Changed","text":"<ul> <li>Add optional build boolean for LocalProject by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/16</li> <li>Slightly improve sorry detection in <code>lean_code_is_valid</code> by checking <code>message</code> instead of just <code>sorries</code> in REPL output.</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.2...v0.5.3</p>"},{"location":"changelog/#v052-may-01-2025","title":"v0.5.2 (May 01, 2025)","text":"<p>Introduce compatibility with Lean v4.19.0</p> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.1...v0.5.2</p>"},{"location":"changelog/#v051-april-30-2025","title":"v0.5.1 (April 30, 2025)","text":""},{"location":"changelog/#whats-changed_8","title":"What's Changed","text":"<ul> <li>Add fix for non-respected timeout by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/13</li> <li>Query Lake cache for all Project types by @habemus-papadum in https://github.com/augustepoiroux/LeanInteract/pull/10</li> <li>Bump REPL version to v1.0.7 fixing <code>\"auxiliary declaration cannot be created when declaration name is not available\"</code> in tactic mode for Lean \\&lt;= v4.18.0 https://github.com/leanprover-community/repl/issues/44#issuecomment-2814069261</li> </ul> <p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.5.0...v0.5.1</p>"},{"location":"changelog/#v050-april-21-2025","title":"v0.5.0 (April 21, 2025)","text":""},{"location":"changelog/#whats-changed_9","title":"What's Changed","text":"<ul> <li>Make LeanInteract cross-platform by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/4</li> <li>Fix infotree parsing issue by @sorgfresser in https://github.com/augustepoiroux/LeanInteract/pull/1</li> <li>Implement <code>async_run</code> + make calls to the REPL thread-safe by @augustepoiroux in https://github.com/augustepoiroux/LeanInteract/pull/2</li> </ul>"},{"location":"changelog/#v041-april-18-2025","title":"v0.4.1 (April 18, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.4.0...v0.4.1</p>"},{"location":"changelog/#v040-april-11-2025","title":"v0.4.0 (April 11, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.3...v0.4.0</p>"},{"location":"changelog/#v033-april-04-2025","title":"v0.3.3 (April 04, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.2...v0.3.3</p>"},{"location":"changelog/#v032-april-03-2025","title":"v0.3.2 (April 03, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.1...v0.3.2</p>"},{"location":"changelog/#v031-april-02-2025","title":"v0.3.1 (April 02, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.3.0...v0.3.1</p>"},{"location":"changelog/#v030-april-02-2025","title":"v0.3.0 (April 02, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/compare/v0.2.0...v0.3.0</p>"},{"location":"changelog/#v020-march-18-2025","title":"v0.2.0 (March 18, 2025)","text":"<p>Full Changelog: https://github.com/augustepoiroux/LeanInteract/commits/v0.2.0</p>"},{"location":"changelog/#pre-release-development","title":"Pre-release Development","text":"<p>For development history prior to the first release, please see the GitHub commit history.</p>"},{"location":"contributing/","title":"Contributing to LeanInteract","text":"<p>Thank you for your interest in contributing to LeanInteract! This guide will help you get started, follow best practices, and make your contributions easy to review.</p>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Describe your changes clearly and concisely in the PR description.</li> <li>Link to relevant issues using <code>#</code> (e.g., #42).</li> <li>Include tests for new features or bug fixes.</li> <li>Update documentation if your change affects usage or APIs.</li> <li>Ensure all tests pass before requesting review.</li> </ul>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Fork the repository on GitHub and clone your fork locally.</p> </li> <li> <p>Install development dependencies: we recommend using uv.</p> </li> </ol> <pre><code>uv pip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#code-style-quality","title":"Code Style &amp; Quality","text":"<ul> <li>Type hints: All functions and methods should have type annotations.</li> <li>Docstrings: Write clear, descriptive docstrings for all public classes, functions, and modules.</li> <li>Tests: All new features and bug fixes must include unit tests.</li> <li>Documentation: Update or add documentation as needed.</li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Run all tests:</li> </ul> <pre><code>uv run python -m unittest discover tests\n</code></pre> <ul> <li>Run a specific test module:</li> </ul> <pre><code>uv run python -m unittest tests/test_server.py\n</code></pre> <ul> <li>First-time setup is slow: Lean toolchain and dependencies may take several minutes to install/compile.</li> <li>Concurrency tests timeout: Use generous timeouts and check system resources.</li> </ul>"},{"location":"contributing/#documentation-versioning","title":"Documentation &amp; Versioning","text":"<p>LeanInteract uses <code>mkdocs</code> and <code>mike</code> for versioned documentation. Documentation is auto-deployed on <code>main</code> branch changes and version tags.</p> <ul> <li>Preview docs locally:</li> </ul> <pre><code>uv run mkdocs serve\n</code></pre>"},{"location":"contributing/#reporting-issues-getting-help","title":"Reporting Issues &amp; Getting Help","text":"<p>Bugs/Feature requests:</p> <ol> <li>Check GitHub issues first (open or closed).</li> <li>If new, open an issue with a clear description and steps to reproduce.</li> </ol> <p>Contact: For questions, contact the maintainer.</p> <p>Thank you for contributing to LeanInteract!</p>"},{"location":"api/config/","title":"REPL Configuration","text":""},{"location":"api/config/#lean_interact.config","title":"Configuration","text":"<p>Module: <code>lean_interact.config</code></p> <p>This module provides the <code>LeanREPLConfig</code> class, which is used to configure the Lean REPL (Read-Eval-Print Loop) used by the Lean servers in <code>lean_interact.server</code>.</p>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig","title":"LeanREPLConfig","text":"<pre><code>LeanREPLConfig(\n    lean_version: str | None = None,\n    project: BaseProject | None = None,\n    repl_rev: str = DEFAULT_REPL_VERSION,\n    repl_git: str = DEFAULT_REPL_GIT_URL,\n    force_pull_repl: bool = False,\n    cache_dir: str | PathLike = DEFAULT_CACHE_DIR,\n    local_repl_path: str | PathLike | None = None,\n    build_repl: bool = True,\n    lake_path: str | PathLike = \"lake\",\n    memory_hard_limit_mb: int | None = None,\n    enable_incremental_optimization: bool = True,\n    enable_parallel_elaboration: bool = True,\n    verbose: bool = False,\n)\n</code></pre> <p>Initialize the Lean REPL configuration.</p> <p>Parameters:</p> Name Type Description Default <code>lean_version</code> <code>str | None</code> <p>The Lean version you want to use. Should only be set when <code>project</code> is <code>None</code>. When <code>project</code> is provided, the Lean version will be inferred from the project. Default is <code>None</code>, which means the latest available version will be selected if <code>project</code> is <code>None</code>.</p> <code>None</code> <code>project</code> <code>BaseProject | None</code> <p>The project you want to use. Options: - <code>None</code>: The REPL sessions will only depend on Lean and its standard library. - <code>LocalProject</code>: An existing local Lean project. - <code>GitProject</code>: A git repository with a Lean project that will be cloned. - <code>TemporaryProject</code>: A temporary Lean project with a custom lakefile that will be created. - <code>TempRequireProject</code>: A temporary Lean project with dependencies that will be created.</p> <code>None</code> <code>repl_rev</code> <code>str</code> <p>The REPL version / git revision you want to use. It is not recommended to change this value unless you know what you are doing. It will first attempt to checkout <code>{repl_rev}_lean-toolchain-{lean_version}</code>, and fallback to <code>{repl_rev}</code> if it fails. Note: Ignored when <code>local_repl_path</code> is provided.</p> <code>DEFAULT_REPL_VERSION</code> <code>repl_git</code> <code>str</code> <p>The git repository of the Lean REPL. It is not recommended to change this value unless you know what you are doing. Note: Ignored when <code>local_repl_path</code> is provided.</p> <code>DEFAULT_REPL_GIT_URL</code> <code>force_pull_repl</code> <code>bool</code> <p>If True, always pull the latest changes from the REPL git repository before checking out the revision. By default, it is <code>False</code> to limit hitting GitHub API rate limits.</p> <code>False</code> <code>cache_dir</code> <code>str | PathLike</code> <p>The directory where the Lean REPL will be cached. Default is inside the package directory.</p> <code>DEFAULT_CACHE_DIR</code> <code>local_repl_path</code> <code>str | PathLike | None</code> <p>A local path to the Lean REPL. This is useful if you want to use a local copy of the REPL. When provided, the REPL will not be downloaded from the git repository. This is particularly useful during REPL development.</p> <code>None</code> <code>build_repl</code> <code>bool</code> <p>Whether to build the REPL. Can be set to False if the REPL is already built (e.g., when using a local REPL path or using an already cached REPL).</p> <code>True</code> <code>lake_path</code> <code>str | PathLike</code> <p>The path to the lake executable. Default is \"lake\", which assumes it is in the system PATH.</p> <code>'lake'</code> <code>memory_hard_limit_mb</code> <code>int | None</code> <p>The maximum memory usage in MB for the Lean server. Setting this value too low may lead to more command processing failures. Only available on Linux platforms. Default is <code>None</code>, which means no limit.</p> <code>None</code> <code>enable_incremental_optimization</code> <code>bool</code> <p>Whether to enable incremental optimization for all commands in the Lean REPL. This can significantly speed up processing and decrease memory usage of commands by automatically reusing partial computations from previous commands. Only available for Lean &gt;= v4.8.0-rc1. Default is <code>True</code>.</p> <code>True</code> <code>enable_parallel_elaboration</code> <code>bool</code> <p>Whether to enable parallel elaboration in the Lean REPL. This can significantly speed up processing of commands, especially in large files. Only available for Lean &gt;= v4.19.0. Default is <code>True</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional information during the setup process.</p> <code>False</code> <p>Examples:</p> <pre><code># Basic configuration with default settings\nconfig = LeanREPLConfig(verbose=True)\n\n# Configuration with specific Lean version\nconfig = LeanREPLConfig(lean_version=\"v4.19.0\", verbose=True)\n\n# Configuration with memory limits\nconfig = LeanREPLConfig(memory_hard_limit_mb=2000)\n\n# Configuration with custom REPL version and repository\nconfig = LeanREPLConfig(\n    repl_rev=\"v4.21.0-rc3\",\n    repl_git=\"https://github.com/leanprover-community/repl\"\n)\n\n# Working with projects\nconfig = LeanREPLConfig(\n    project=LocalProject(directory=\"/path/to/project\"),\n    verbose=True\n)\n</code></pre> Source code in <code>src/lean_interact/config.py</code> <pre><code>def __init__(\n    self,\n    lean_version: str | None = None,\n    project: BaseProject | None = None,\n    repl_rev: str = DEFAULT_REPL_VERSION,\n    repl_git: str = DEFAULT_REPL_GIT_URL,\n    force_pull_repl: bool = False,\n    cache_dir: str | PathLike = DEFAULT_CACHE_DIR,\n    local_repl_path: str | PathLike | None = None,\n    build_repl: bool = True,\n    lake_path: str | PathLike = \"lake\",\n    memory_hard_limit_mb: int | None = None,\n    enable_incremental_optimization: bool = True,\n    enable_parallel_elaboration: bool = True,\n    verbose: bool = False,\n):\n    \"\"\"\n    Initialize the Lean REPL configuration.\n\n    Args:\n        lean_version:\n            The Lean version you want to use. Should only be set when `project` is `None`.\n            When `project` is provided, the Lean version will be inferred from the project.\n            Default is `None`, which means the latest available version will be selected if `project` is `None`.\n        project:\n            The project you want to use. Options:\n            - `None`: The REPL sessions will only depend on Lean and its standard library.\n            - `LocalProject`: An existing local Lean project.\n            - `GitProject`: A git repository with a Lean project that will be cloned.\n            - `TemporaryProject`: A temporary Lean project with a custom lakefile that will be created.\n            - `TempRequireProject`: A temporary Lean project with dependencies that will be created.\n        repl_rev:\n            The REPL version / git revision you want to use. It is not recommended to change this value unless you know what you are doing.\n            It will first attempt to checkout `{repl_rev}_lean-toolchain-{lean_version}`, and fallback to `{repl_rev}` if it fails.\n            Note: Ignored when `local_repl_path` is provided.\n        repl_git:\n            The git repository of the Lean REPL. It is not recommended to change this value unless you know what you are doing.\n            Note: Ignored when `local_repl_path` is provided.\n        force_pull_repl:\n            If True, always pull the latest changes from the REPL git repository before checking out the revision.\n            By default, it is `False` to limit hitting GitHub API rate limits.\n        cache_dir:\n            The directory where the Lean REPL will be cached.\n            Default is inside the package directory.\n        local_repl_path:\n            A local path to the Lean REPL. This is useful if you want to use a local copy of the REPL.\n            When provided, the REPL will not be downloaded from the git repository.\n            This is particularly useful during REPL development.\n        build_repl:\n            Whether to build the REPL. Can be set to False if the REPL is already built (e.g., when using a local REPL path or using an already cached REPL).\n        lake_path:\n            The path to the lake executable. Default is \"lake\", which assumes it is in the system PATH.\n        memory_hard_limit_mb:\n            The maximum memory usage in MB for the Lean server. Setting this value too low may lead to more command processing failures.\n            Only available on Linux platforms.\n            Default is `None`, which means no limit.\n        enable_incremental_optimization:\n            Whether to enable incremental optimization for all commands in the Lean REPL. This can significantly speed up processing\n            and decrease memory usage of commands by automatically reusing partial computations from previous commands.\n            Only available for Lean &gt;= v4.8.0-rc1. Default is `True`.\n        enable_parallel_elaboration:\n            Whether to enable parallel elaboration in the Lean REPL. This can significantly speed up processing\n            of commands, especially in large files. Only available for Lean &gt;= v4.19.0. Default is `True`.\n        verbose:\n            Whether to print additional information during the setup process.\n\n    Examples:\n        ```python\n        # Basic configuration with default settings\n        config = LeanREPLConfig(verbose=True)\n\n        # Configuration with specific Lean version\n        config = LeanREPLConfig(lean_version=\"v4.19.0\", verbose=True)\n\n        # Configuration with memory limits\n        config = LeanREPLConfig(memory_hard_limit_mb=2000)\n\n        # Configuration with custom REPL version and repository\n        config = LeanREPLConfig(\n            repl_rev=\"v4.21.0-rc3\",\n            repl_git=\"https://github.com/leanprover-community/repl\"\n        )\n\n        # Working with projects\n        config = LeanREPLConfig(\n            project=LocalProject(directory=\"/path/to/project\"),\n            verbose=True\n        )\n        ```\n    \"\"\"\n    if project is not None and lean_version is not None:\n        raise ValueError(\n            \"lean_version should only be set when project is None. When a project is provided, the Lean version is inferred from the project.\"\n        )\n\n    # Initialize basic configuration\n    if lean_version:\n        lean_version = parse_lean_version(lean_version)\n        if lean_version is None:\n            raise ValueError(f\"Unable to parse Lean version format: `{lean_version}`\")\n    self.lean_version = lean_version\n    self.project = project\n    self.repl_git = repl_git\n    self.repl_rev = repl_rev\n    self.force_pull_repl = force_pull_repl\n    self.cache_dir = Path(cache_dir)\n    self.local_repl_path = Path(local_repl_path) if local_repl_path else None\n    self.build_repl = build_repl\n    self.memory_hard_limit_mb = memory_hard_limit_mb\n    self.enable_incremental_optimization = enable_incremental_optimization\n    self.enable_parallel_elaboration = enable_parallel_elaboration\n    self.lake_path = Path(lake_path)\n    self.verbose = verbose\n    self._timeout_lock = 300\n\n    if self.project is not None:\n        self.lean_version = self.project.get_lean_version()\n        if self.project.directory is None:\n            raise ValueError(\"Project directory cannot be None\")\n\n    self._setup_repl()\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.lean_version","title":"lean_version  <code>instance-attribute</code>","text":"<pre><code>lean_version = lean_version\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.project","title":"project  <code>instance-attribute</code>","text":"<pre><code>project = project\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.repl_git","title":"repl_git  <code>instance-attribute</code>","text":"<pre><code>repl_git = repl_git\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.repl_rev","title":"repl_rev  <code>instance-attribute</code>","text":"<pre><code>repl_rev = repl_rev\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.force_pull_repl","title":"force_pull_repl  <code>instance-attribute</code>","text":"<pre><code>force_pull_repl = force_pull_repl\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.cache_dir","title":"cache_dir  <code>instance-attribute</code>","text":"<pre><code>cache_dir = Path(cache_dir)\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.local_repl_path","title":"local_repl_path  <code>instance-attribute</code>","text":"<pre><code>local_repl_path = (\n    Path(local_repl_path) if local_repl_path else None\n)\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.build_repl","title":"build_repl  <code>instance-attribute</code>","text":"<pre><code>build_repl = build_repl\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.memory_hard_limit_mb","title":"memory_hard_limit_mb  <code>instance-attribute</code>","text":"<pre><code>memory_hard_limit_mb = memory_hard_limit_mb\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.enable_incremental_optimization","title":"enable_incremental_optimization  <code>instance-attribute</code>","text":"<pre><code>enable_incremental_optimization = (\n    enable_incremental_optimization\n)\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.enable_parallel_elaboration","title":"enable_parallel_elaboration  <code>instance-attribute</code>","text":"<pre><code>enable_parallel_elaboration = enable_parallel_elaboration\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.lake_path","title":"lake_path  <code>instance-attribute</code>","text":"<pre><code>lake_path = Path(lake_path)\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.verbose","title":"verbose  <code>instance-attribute</code>","text":"<pre><code>verbose = verbose\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.cache_repl_dir","title":"cache_repl_dir  <code>property</code>","text":"<pre><code>cache_repl_dir: str\n</code></pre> <p>Get the cache directory for the Lean REPL.</p>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.working_dir","title":"working_dir  <code>property</code>","text":"<pre><code>working_dir: str\n</code></pre> <p>Get the working directory, where the commands are executed.</p>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.get_available_lean_versions","title":"get_available_lean_versions","text":"<pre><code>get_available_lean_versions() -&gt; list[str]\n</code></pre> <p>Get the available Lean versions for the selected REPL.</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>def get_available_lean_versions(self) -&gt; list[str]:\n    \"\"\"\n    Get the available Lean versions for the selected REPL.\n    \"\"\"\n    return [commit[0] for commit in self._get_available_lean_versions()]\n</code></pre>"},{"location":"api/config/#lean_interact.config.LeanREPLConfig.is_setup","title":"is_setup","text":"<pre><code>is_setup() -&gt; bool\n</code></pre> <p>Check if the Lean environment has been set up.</p> Source code in <code>src/lean_interact/config.py</code> <pre><code>def is_setup(self) -&gt; bool:\n    \"\"\"Check if the Lean environment has been set up.\"\"\"\n    return hasattr(self, \"_cache_repl_dir\") and self._cache_repl_dir is not None\n</code></pre>"},{"location":"api/interface/","title":"Interface","text":""},{"location":"api/interface/#lean_interact.interface","title":"Interface","text":"<p>Module: <code>lean_interact.interface</code></p> <p>This module provides the base classes and data models for interacting with the Lean REPL (Read-Eval-Print Loop). It defines the request and response structures used for sending commands to the Lean server and receiving results. These are aligned with the Lean REPL's API.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTreeOptions","title":"InfoTreeOptions","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Options for InfoTree detail levels.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTreeOptions.full","title":"full  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>full = 'full'\n</code></pre> <p>No filtering: include the entire InfoTree (tactic information, term / elaboration information, messages, goal states, traces, etc.).</p>"},{"location":"api/interface/#lean_interact.interface.InfoTreeOptions.tactics","title":"tactics  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tactics = 'tactics'\n</code></pre> <p>Keep only the nodes produced by tactics. Drops unrelated term / elaboration / non-tactic bookkeeping nodes.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTreeOptions.original","title":"original  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>original = 'original'\n</code></pre> <p>First keep the tactic-related nodes, then further restrict to the \"original\" sub\u2011parts of those tactic nodes (i.e. non-synthetic nodes).</p>"},{"location":"api/interface/#lean_interact.interface.InfoTreeOptions.substantive","title":"substantive  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>substantive = 'substantive'\n</code></pre> <p>Keep only the substantive content coming from tactic nodes, removing nodes that are merely a tactic combinator (e.g. <code>by</code>, <code>;</code>, multiline, parentheses).</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions","title":"CommandOptions","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Common options for <code>Command</code> and <code>FileCommand</code>.</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.all_tactics","title":"all_tactics  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>all_tactics: bool | None = None\n</code></pre> <p>If true, return all tactics used in the command with their associated information.</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.declarations","title":"declarations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>declarations: bool | None = None\n</code></pre> <p>If true, return detailed information about declarations in the command.</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.root_goals","title":"root_goals  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>root_goals: bool | None = None\n</code></pre> <p>If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.infotree","title":"infotree  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>infotree: InfoTreeOptions | str | None = None\n</code></pre> <p>Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.incrementality","title":"incrementality  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>incrementality: bool | None = None\n</code></pre> <p>If true, enable incremental optimization for the command.</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.set_options","title":"set_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_options: Options | None = None\n</code></pre> <p>Options to be set before executing the command (i.e. <code>set_option</code> commands in Lean).</p>"},{"location":"api/interface/#lean_interact.interface.CommandOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Command","title":"Command","text":"<p>               Bases: <code>BaseREPLQuery</code>, <code>CommandOptions</code></p> <p>Command to be executed in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.Command.cmd","title":"cmd  <code>instance-attribute</code>","text":"<pre><code>cmd: str\n</code></pre> <p>The command to be executed.</p>"},{"location":"api/interface/#lean_interact.interface.Command.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: int | None = None\n</code></pre> <p>The environment to be used. If <code>env = None</code>, starts a new session (in which you can use <code>import</code>). If <code>env</code> is set, the command is executed in the given environment.</p>"},{"location":"api/interface/#lean_interact.interface.Command.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Command.all_tactics","title":"all_tactics  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>all_tactics: bool | None = None\n</code></pre> <p>If true, return all tactics used in the command with their associated information.</p>"},{"location":"api/interface/#lean_interact.interface.Command.declarations","title":"declarations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>declarations: bool | None = None\n</code></pre> <p>If true, return detailed information about declarations in the command.</p>"},{"location":"api/interface/#lean_interact.interface.Command.root_goals","title":"root_goals  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>root_goals: bool | None = None\n</code></pre> <p>If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.</p>"},{"location":"api/interface/#lean_interact.interface.Command.infotree","title":"infotree  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>infotree: InfoTreeOptions | str | None = None\n</code></pre> <p>Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.</p>"},{"location":"api/interface/#lean_interact.interface.Command.incrementality","title":"incrementality  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>incrementality: bool | None = None\n</code></pre> <p>If true, enable incremental optimization for the command.</p>"},{"location":"api/interface/#lean_interact.interface.Command.set_options","title":"set_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_options: Options | None = None\n</code></pre> <p>Options to be set before executing the command (i.e. <code>set_option</code> commands in Lean).</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand","title":"FileCommand","text":"<p>               Bases: <code>BaseREPLQuery</code>, <code>CommandOptions</code></p> <p>Command for file operations in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: str\n</code></pre> <p>The path of the file to be operated on.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: int | None = None\n</code></pre> <p>The environment to be used. If <code>env = None</code>, starts a new session (in which you can use <code>import</code>). If <code>env</code> is set, the command is executed in the given environment.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.FileCommand.all_tactics","title":"all_tactics  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>all_tactics: bool | None = None\n</code></pre> <p>If true, return all tactics used in the command with their associated information.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.declarations","title":"declarations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>declarations: bool | None = None\n</code></pre> <p>If true, return detailed information about declarations in the command.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.root_goals","title":"root_goals  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>root_goals: bool | None = None\n</code></pre> <p>If true, return root goals, i.e. initial goals of all declarations in the command, even if they already have a proof.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.infotree","title":"infotree  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>infotree: InfoTreeOptions | str | None = None\n</code></pre> <p>Return syntax information. Should be \"full\", \"tactics\", \"original\", or \"substantive\". Anything else is ignored.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.incrementality","title":"incrementality  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>incrementality: bool | None = None\n</code></pre> <p>If true, enable incremental optimization for the command.</p>"},{"location":"api/interface/#lean_interact.interface.FileCommand.set_options","title":"set_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_options: Options | None = None\n</code></pre> <p>Options to be set before executing the command (i.e. <code>set_option</code> commands in Lean).</p>"},{"location":"api/interface/#lean_interact.interface.ProofStep","title":"ProofStep","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Proof step in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStep.proof_state","title":"proof_state  <code>instance-attribute</code>","text":"<pre><code>proof_state: int\n</code></pre> <p>The proof state to start from.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStep.tactic","title":"tactic  <code>instance-attribute</code>","text":"<pre><code>tactic: str\n</code></pre> <p>The tactic to be applied.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStep.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.PickleEnvironment","title":"PickleEnvironment","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Environment for pickling in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.PickleEnvironment.env","title":"env  <code>instance-attribute</code>","text":"<pre><code>env: int\n</code></pre> <p>The environment to be pickled.</p>"},{"location":"api/interface/#lean_interact.interface.PickleEnvironment.pickle_to","title":"pickle_to  <code>instance-attribute</code>","text":"<pre><code>pickle_to: str\n</code></pre> <p>The path to save the pickle file.</p>"},{"location":"api/interface/#lean_interact.interface.PickleEnvironment.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.UnpickleEnvironment","title":"UnpickleEnvironment","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Environment for unpickling in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.UnpickleEnvironment.unpickle_env_from","title":"unpickle_env_from  <code>instance-attribute</code>","text":"<pre><code>unpickle_env_from: str\n</code></pre> <p>The path to the pickle file.</p>"},{"location":"api/interface/#lean_interact.interface.UnpickleEnvironment.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.PickleProofState","title":"PickleProofState","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Proof state for pickling in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.PickleProofState.proof_state","title":"proof_state  <code>instance-attribute</code>","text":"<pre><code>proof_state: int\n</code></pre> <p>The proof state to be pickled.</p>"},{"location":"api/interface/#lean_interact.interface.PickleProofState.pickle_to","title":"pickle_to  <code>instance-attribute</code>","text":"<pre><code>pickle_to: str\n</code></pre> <p>The path to save the pickle file.</p>"},{"location":"api/interface/#lean_interact.interface.PickleProofState.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.UnpickleProofState","title":"UnpickleProofState","text":"<p>               Bases: <code>BaseREPLQuery</code></p> <p>Environment for unpickling in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.UnpickleProofState.unpickle_proof_state_from","title":"unpickle_proof_state_from  <code>instance-attribute</code>","text":"<pre><code>unpickle_proof_state_from: str\n</code></pre> <p>The path to the pickle file containing the proof state to be unpickled.</p>"},{"location":"api/interface/#lean_interact.interface.UnpickleProofState.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: int | None = None\n</code></pre> <p>The environment to be used as a context for unpickling.</p>"},{"location":"api/interface/#lean_interact.interface.UnpickleProofState.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandResponse","title":"CommandResponse","text":"<pre><code>CommandResponse(**data)\n</code></pre> <p>               Bases: <code>BaseREPLResponse</code></p> <p>Response to a command in the REPL.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def __init__(self, **data):\n    if self.__class__ == BaseREPLResponse:\n        raise TypeError(\"BaseResponse cannot be instantiated directly\")\n    super().__init__(**data)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.env","title":"env  <code>instance-attribute</code>","text":"<pre><code>env: int\n</code></pre> <p>The new environment state after running the code in the command.</p>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.tactics","title":"tactics  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tactics: list[Tactic] = Field(default_factory=list)\n</code></pre> <p>List of tactics in the code. Returned only if <code>all_tactics</code> is true.</p>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.declarations","title":"declarations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>declarations: list[DeclarationInfo] = Field(\n    default_factory=list\n)\n</code></pre> <p>List of declarations in the code. Returned only if <code>declarations</code> is true.</p>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.infotree","title":"infotree  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>infotree: list[InfoTree] | None = None\n</code></pre> <p>The infotree of the code. Returned only if <code>infotree</code> is true.</p>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.messages","title":"messages  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>messages: list[Message] = Field(default_factory=list)\n</code></pre> <p>List of messages in the response.</p>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.sorries","title":"sorries  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sorries: list[Sorry] = Field(default_factory=list)\n</code></pre> <p>List of sorries found in the submitted code.</p>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.get_errors","title":"get_errors","text":"<pre><code>get_errors() -&gt; list[Message]\n</code></pre> <p>Return all error messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def get_errors(self) -&gt; list[Message]:\n    \"\"\"Return all error messages\"\"\"\n    return [msg for msg in self.messages if msg.severity == \"error\"]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.get_warnings","title":"get_warnings","text":"<pre><code>get_warnings() -&gt; list[Message]\n</code></pre> <p>Return all warning messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def get_warnings(self) -&gt; list[Message]:\n    \"\"\"Return all warning messages\"\"\"\n    return [msg for msg in self.messages if msg.severity == \"warning\"]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.has_errors","title":"has_errors","text":"<pre><code>has_errors() -&gt; bool\n</code></pre> <p>Check if response contains any error messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def has_errors(self) -&gt; bool:\n    \"\"\"Check if response contains any error messages\"\"\"\n    return any(msg.severity == \"error\" for msg in self.messages)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandResponse.lean_code_is_valid","title":"lean_code_is_valid","text":"<pre><code>lean_code_is_valid(\n    start_pos: Pos | None = None,\n    end_pos: Pos | None = None,\n    allow_sorry: bool = True,\n) -&gt; bool\n</code></pre> <p>Check if the submitted code is valid Lean code.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def lean_code_is_valid(\n    self,\n    start_pos: Pos | None = None,\n    end_pos: Pos | None = None,\n    allow_sorry: bool = True,\n) -&gt; bool:\n    \"\"\"Check if the submitted code is valid Lean code.\"\"\"\n    # check only the messages intersecting the code\n    errors = [\n        message\n        for message in self.messages\n        if message_intersects_code(message, start_pos, end_pos) and message.severity == \"error\"\n    ]\n    sorries = [message for message in self.sorries if message_intersects_code(message, start_pos, end_pos)] + [\n        message\n        for message in self.messages\n        if message_intersects_code(message, start_pos, end_pos) and message.data == \"declaration uses 'sorry'\"\n    ]\n    return not errors and (allow_sorry or not sorries)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse","title":"ProofStepResponse","text":"<pre><code>ProofStepResponse(**data)\n</code></pre> <p>               Bases: <code>BaseREPLResponse</code></p> <p>Response to a proof step in the REPL.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def __init__(self, **data):\n    if self.__class__ == BaseREPLResponse:\n        raise TypeError(\"BaseResponse cannot be instantiated directly\")\n    super().__init__(**data)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.proof_status","title":"proof_status  <code>instance-attribute</code>","text":"<pre><code>proof_status: str\n</code></pre> <p>The proof status of the whole proof. Possible values: <code>Completed</code>, <code>Incomplete</code>, <code>Error</code>. It may contain additional information, e.g. <code>Incomplete: contains sorry</code>.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.proof_state","title":"proof_state  <code>instance-attribute</code>","text":"<pre><code>proof_state: int\n</code></pre> <p>The proof state after the proof step.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.goals","title":"goals  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>goals: list[str] = Field(default_factory=list)\n</code></pre> <p>List of goals after the proof step.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.traces","title":"traces  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>traces: list[str] = Field(default_factory=list)\n</code></pre> <p>List of traces in the proof step.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.messages","title":"messages  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>messages: list[Message] = Field(default_factory=list)\n</code></pre> <p>List of messages in the response.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.sorries","title":"sorries  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sorries: list[Sorry] = Field(default_factory=list)\n</code></pre> <p>List of sorries found in the submitted code.</p>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.get_errors","title":"get_errors","text":"<pre><code>get_errors() -&gt; list[Message]\n</code></pre> <p>Return all error messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def get_errors(self) -&gt; list[Message]:\n    \"\"\"Return all error messages\"\"\"\n    return [msg for msg in self.messages if msg.severity == \"error\"]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.get_warnings","title":"get_warnings","text":"<pre><code>get_warnings() -&gt; list[Message]\n</code></pre> <p>Return all warning messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def get_warnings(self) -&gt; list[Message]:\n    \"\"\"Return all warning messages\"\"\"\n    return [msg for msg in self.messages if msg.severity == \"warning\"]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.has_errors","title":"has_errors","text":"<pre><code>has_errors() -&gt; bool\n</code></pre> <p>Check if response contains any error messages</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def has_errors(self) -&gt; bool:\n    \"\"\"Check if response contains any error messages\"\"\"\n    return any(msg.severity == \"error\" for msg in self.messages)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ProofStepResponse.lean_code_is_valid","title":"lean_code_is_valid","text":"<pre><code>lean_code_is_valid(\n    start_pos: Pos | None = None,\n    end_pos: Pos | None = None,\n    allow_sorry: bool = True,\n) -&gt; bool\n</code></pre> <p>Check if the submitted code is valid Lean code.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def lean_code_is_valid(\n    self,\n    start_pos: Pos | None = None,\n    end_pos: Pos | None = None,\n    allow_sorry: bool = True,\n) -&gt; bool:\n    \"\"\"Check if the submitted code is valid Lean code.\"\"\"\n    # check only the messages intersecting the code\n    errors = [\n        message\n        for message in self.messages\n        if message_intersects_code(message, start_pos, end_pos) and message.severity == \"error\"\n    ]\n    sorries = [message for message in self.sorries if message_intersects_code(message, start_pos, end_pos)] + [\n        message\n        for message in self.messages\n        if message_intersects_code(message, start_pos, end_pos) and message.data == \"declaration uses 'sorry'\"\n    ]\n    return not errors and (allow_sorry or not sorries)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.LeanError","title":"LeanError","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Represents an error in the Lean REPL.</p>"},{"location":"api/interface/#lean_interact.interface.LeanError.message","title":"message  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>message: str = ''\n</code></pre> <p>The error message.</p>"},{"location":"api/interface/#lean_interact.interface.LeanError.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Message","title":"Message","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Message in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.Message.start_pos","title":"start_pos  <code>instance-attribute</code>","text":"<pre><code>start_pos: Pos\n</code></pre> <p>The starting position of the message.</p>"},{"location":"api/interface/#lean_interact.interface.Message.end_pos","title":"end_pos  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_pos: Pos | None = None\n</code></pre> <p>The ending position of the message.</p>"},{"location":"api/interface/#lean_interact.interface.Message.severity","title":"severity  <code>instance-attribute</code>","text":"<pre><code>severity: Literal['error', 'warning', 'info', 'trace']\n</code></pre> <p>The severity of the message. Possible values: <code>error</code>, <code>warning</code>, <code>info</code>, <code>trace</code>.</p>"},{"location":"api/interface/#lean_interact.interface.Message.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: str\n</code></pre> <p>The data associated with the message.</p>"},{"location":"api/interface/#lean_interact.interface.Message.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Pos","title":"Pos","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Position in the Lean code.</p>"},{"location":"api/interface/#lean_interact.interface.Pos.line","title":"line  <code>instance-attribute</code>","text":"<pre><code>line: int\n</code></pre> <p>The line number of the position.</p>"},{"location":"api/interface/#lean_interact.interface.Pos.column","title":"column  <code>instance-attribute</code>","text":"<pre><code>column: int\n</code></pre> <p>The column number of the position.</p>"},{"location":"api/interface/#lean_interact.interface.Pos.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Range","title":"Range","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Range of a Syntax object.</p>"},{"location":"api/interface/#lean_interact.interface.Range.synthetic","title":"synthetic  <code>instance-attribute</code>","text":"<pre><code>synthetic: bool\n</code></pre> <p>Whether the syntax is synthetic or not.</p>"},{"location":"api/interface/#lean_interact.interface.Range.start","title":"start  <code>instance-attribute</code>","text":"<pre><code>start: Pos\n</code></pre> <p>The starting position of the syntax.</p>"},{"location":"api/interface/#lean_interact.interface.Range.finish","title":"finish  <code>instance-attribute</code>","text":"<pre><code>finish: Pos\n</code></pre> <p>The ending position of the syntax.</p>"},{"location":"api/interface/#lean_interact.interface.Range.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Sorry","title":"Sorry","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Sorry message in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.Sorry.start_pos","title":"start_pos  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_pos: Pos | None = None\n</code></pre> <p>The starting position of the sorry message.</p>"},{"location":"api/interface/#lean_interact.interface.Sorry.end_pos","title":"end_pos  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_pos: Pos | None = None\n</code></pre> <p>The ending position of the sorry message.</p>"},{"location":"api/interface/#lean_interact.interface.Sorry.goal","title":"goal  <code>instance-attribute</code>","text":"<pre><code>goal: str\n</code></pre> <p>The proof goal at the sorry location.</p>"},{"location":"api/interface/#lean_interact.interface.Sorry.proof_state","title":"proof_state  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>proof_state: int | None = None\n</code></pre> <p>The proof state associated to the sorry.</p>"},{"location":"api/interface/#lean_interact.interface.Sorry.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.Tactic","title":"Tactic","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Tactic in the REPL.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.start_pos","title":"start_pos  <code>instance-attribute</code>","text":"<pre><code>start_pos: Pos\n</code></pre> <p>The starting position of the tactic.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.end_pos","title":"end_pos  <code>instance-attribute</code>","text":"<pre><code>end_pos: Pos\n</code></pre> <p>The ending position of the tactic.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.goals","title":"goals  <code>instance-attribute</code>","text":"<pre><code>goals: str\n</code></pre> <p>The goals associated with the tactic.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.tactic","title":"tactic  <code>instance-attribute</code>","text":"<pre><code>tactic: str\n</code></pre> <p>The applied tactic.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.proof_state","title":"proof_state  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>proof_state: int | None = None\n</code></pre> <p>The proof state associated with the tactic.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.used_constants","title":"used_constants  <code>instance-attribute</code>","text":"<pre><code>used_constants: list[str]\n</code></pre> <p>The constants used in the tactic.</p>"},{"location":"api/interface/#lean_interact.interface.Tactic.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree","title":"InfoTree","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>An InfoTree representation of the Lean code.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTree.node","title":"node  <code>instance-attribute</code>","text":"<pre><code>node: Node\n</code></pre> <p>The root node of the InfoTree, which can be a TacticNode, CommandNode, TermNode, or None.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTree.kind","title":"kind  <code>instance-attribute</code>","text":"<pre><code>kind: Literal[\n    \"TacticInfo\",\n    \"TermInfo\",\n    \"PartialTermInfo\",\n    \"CommandInfo\",\n    \"MacroExpansionInfo\",\n    \"OptionInfo\",\n    \"FieldInfo\",\n    \"CompletionInfo\",\n    \"UserWidgetInfo\",\n    \"CustomInfo\",\n    \"FVarAliasInfo\",\n    \"FieldRedeclInfo\",\n    \"ChoiceInfo\",\n    \"DelabTermInfo\",\n]\n</code></pre> <p>The kind of the InfoTree.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTree.children","title":"children  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>children: list[Self] = Field(default_factory=list)\n</code></pre> <p>Children of the InfoTree, which are also InfoTrees.</p>"},{"location":"api/interface/#lean_interact.interface.InfoTree.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.dfs_walk","title":"dfs_walk","text":"<pre><code>dfs_walk() -&gt; Generator[Self, None, None]\n</code></pre> <p>Walk the InfoTree using Depth-First-Search.</p> <p>Returns:</p> Type Description <code>None</code> <p>Yields the subsequent InfoTree.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def dfs_walk(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Walk the InfoTree using Depth-First-Search.\n\n    Returns:\n        Yields the subsequent InfoTree.\n    \"\"\"\n    # Had to do this iteratively, because recursively is slow and exceeds recursion depth\n    stack = deque([self])\n\n    while stack:\n        first = stack.popleft()\n        yield first\n        stack.extendleft(first.children)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.leaves","title":"leaves","text":"<pre><code>leaves() -&gt; Generator[Self, None, None]\n</code></pre> <p>Get the InfoTree leaves of the Depth-First-Search</p> <p>Returns:</p> Type Description <code>None</code> <p>Yield the leaves of the InfoTree.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def leaves(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Get the InfoTree leaves of the Depth-First-Search\n\n    Returns:\n        Yield the leaves of the InfoTree.\n    \"\"\"\n    for tree in self.dfs_walk():\n        if not tree.children:\n            yield tree\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.commands","title":"commands","text":"<pre><code>commands() -&gt; Generator[Self, None, None]\n</code></pre> <p>Get all InfoTrees that represent commands</p> <p>Returns:</p> Type Description <code>None</code> <p>Yields the command nodes of the InfoTree.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def commands(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Get all InfoTrees that represent commands\n\n    Returns:\n        Yields the command nodes of the InfoTree.\n    \"\"\"\n    for tree in self.dfs_walk():\n        if tree.kind != \"CommandInfo\":\n            continue\n        assert isinstance(tree.node, CommandNode)\n        yield tree\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.variables","title":"variables","text":"<pre><code>variables() -&gt; Generator[Self, None, None]\n</code></pre> <p>Get children corresponding to variable expressions.</p> <p>Returns:</p> Type Description <code>None</code> <p>Yields the variable nodes of the InfoTree.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def variables(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Get children corresponding to variable expressions.\n\n    Returns:\n        Yields the variable nodes of the InfoTree.\n    \"\"\"\n    for tree in self.commands():\n        if tree.node.elaborator != \"Lean.Elab.Command.elabVariable\":  # type: ignore\n            continue\n        yield tree\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.theorems","title":"theorems","text":"<pre><code>theorems() -&gt; Generator[Self, None, None]\n</code></pre> <p>Get children corresponding to theorems (including lemmas).</p> <p>Returns:</p> Type Description <code>None</code> <p>Yields the theorems of the InfoTree.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def theorems(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Get children corresponding to theorems (including lemmas).\n\n    Returns:\n         Yields the theorems of the InfoTree.\n    \"\"\"\n    for tree in self.commands():\n        if tree.node.stx.kind != \"Lean.Parser.Command.declaration\":  # type: ignore\n            continue\n        if tree.node.stx.arg_kinds[-1] != \"Lean.Parser.Command.theorem\":  # type: ignore\n            continue\n        yield tree\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.docs","title":"docs","text":"<pre><code>docs() -&gt; Generator[Self, None, None]\n</code></pre> <p>Get children corresponding to DocStrings.</p> <p>Returns:</p> Type Description <code>None</code> <p>Yields the InfoTree nodes representing Docstrings.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def docs(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Get children corresponding to DocStrings.\n\n    Returns:\n         Yields the InfoTree nodes representing Docstrings.\n    \"\"\"\n    for tree in self.commands():\n        if tree.node.elaborator != \"Lean.Elab.Command.elabModuleDoc\":  # type: ignore\n            continue\n        yield tree\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.namespaces","title":"namespaces","text":"<pre><code>namespaces() -&gt; Generator[Self, None, None]\n</code></pre> <p>Get children corresponding to namespaces.</p> <p>Returns:</p> Type Description <code>None</code> <p>Yields the InfoTree nodes for namespaces.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def namespaces(self) -&gt; Generator[Self, None, None]:\n    \"\"\"\n    Get children corresponding to namespaces.\n\n    Returns:\n         Yields the InfoTree nodes for namespaces.\n    \"\"\"\n    for tree in self.commands():\n        if tree.node.elaborator != \"Lean.Elab.Command.elabNamespace\":  # type: ignore\n            continue\n        yield tree\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.pp_up_to","title":"pp_up_to","text":"<pre><code>pp_up_to(end_pos: Pos) -&gt; str\n</code></pre> <p>Get the pretty-printed string of the InfoTree up to a given position.</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def pp_up_to(self, end_pos: Pos) -&gt; str:\n    \"\"\"\n    Get the pretty-printed string of the InfoTree up to a given position.\n    \"\"\"\n    if self.node is None:\n        raise ValueError(\"InfoTree node is None, cannot pretty-print!\")\n    if end_pos &gt; self.node.stx.range.finish or end_pos &lt; self.node.stx.range.start:\n        raise ValueError(\"end_pos has to be in bounds!\")\n    if self.node.stx.pp is None:\n        raise ValueError(\"InfoTree node has no pretty-printed string!\")\n    lines = self.node.stx.pp.splitlines(keepends=True)\n    result = []\n    for line_idx in range(end_pos.line + 1 - self.node.stx.range.start.line):\n        line = lines[line_idx]\n        if line_idx == end_pos.line - self.node.stx.range.start.line:\n            line = line[: end_pos.column]\n        result.append(line)\n    return \"\".join(result)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.InfoTree.theorem_for_sorry","title":"theorem_for_sorry","text":"<pre><code>theorem_for_sorry(sorry: Sorry) -&gt; Self | None\n</code></pre> <p>Get the theorem InfoTree for a given sorry, if found in this tree.</p> <p>Parameters:</p> Name Type Description Default <code>sorry</code> <code>Sorry</code> <p>The sorry to search a theorem for</p> required <p>Returns:</p> Type Description <code>Self | None</code> <p>The found InfoTree, if found, else None</p> Source code in <code>src/lean_interact/interface.py</code> <pre><code>def theorem_for_sorry(self, sorry: Sorry) -&gt; Self | None:\n    \"\"\"\n    Get the theorem InfoTree for a given sorry, if found in this tree.\n\n    Args:\n        sorry: The sorry to search a theorem for\n\n    Returns:\n        The found InfoTree, if found, else None\n    \"\"\"\n    found = None\n    for tree in self.theorems():\n        thm_range = tree.node.stx.range  # type: ignore\n        # Sorry inside\n        if sorry.start_pos is None or sorry.end_pos is None:\n            continue\n        if sorry.start_pos &lt; thm_range.start or sorry.end_pos &gt; thm_range.finish:\n            continue\n        assert found is None\n        found = tree\n    return found\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.TacticNode","title":"TacticNode","text":"<p>               Bases: <code>BaseNode</code></p> <p>A tactic node of the InfoTree.</p>"},{"location":"api/interface/#lean_interact.interface.TacticNode.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str | None\n</code></pre> <p>The name of the tactic, if available.</p>"},{"location":"api/interface/#lean_interact.interface.TacticNode.goals_before","title":"goals_before  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>goals_before: list[str] = Field(\n    default_factory=list, alias=\"goalsBefore\"\n)\n</code></pre> <p>Goals before tactic application.</p>"},{"location":"api/interface/#lean_interact.interface.TacticNode.goals_after","title":"goals_after  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>goals_after: list[str] = Field(\n    default_factory=list, alias=\"goalsAfter\"\n)\n</code></pre> <p>Goals after tactic application.</p>"},{"location":"api/interface/#lean_interact.interface.TacticNode.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.TacticNode.stx","title":"stx  <code>instance-attribute</code>","text":"<pre><code>stx: Syntax\n</code></pre> <p>The syntax object of the node.</p>"},{"location":"api/interface/#lean_interact.interface.CommandNode","title":"CommandNode","text":"<p>               Bases: <code>BaseNode</code></p> <p>A command node of the InfoTree.</p>"},{"location":"api/interface/#lean_interact.interface.CommandNode.elaborator","title":"elaborator  <code>instance-attribute</code>","text":"<pre><code>elaborator: str\n</code></pre> <p>The elaborator used to elaborate the command.</p>"},{"location":"api/interface/#lean_interact.interface.CommandNode.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.CommandNode.stx","title":"stx  <code>instance-attribute</code>","text":"<pre><code>stx: Syntax\n</code></pre> <p>The syntax object of the node.</p>"},{"location":"api/interface/#lean_interact.interface.TermNode","title":"TermNode","text":"<p>               Bases: <code>BaseNode</code></p> <p>A term node of the InfoTree.</p>"},{"location":"api/interface/#lean_interact.interface.TermNode.is_binder","title":"is_binder  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_binder: bool = Field(alias='isBinder')\n</code></pre> <p>Whether the node is a binder or not.</p>"},{"location":"api/interface/#lean_interact.interface.TermNode.expr","title":"expr  <code>instance-attribute</code>","text":"<pre><code>expr: str\n</code></pre> <p>The expression string of the term node.</p>"},{"location":"api/interface/#lean_interact.interface.TermNode.expected_type","title":"expected_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expected_type: str | None = Field(\n    default=None, alias=\"expectedType\"\n)\n</code></pre> <p>The expected type of the term node, if available.</p>"},{"location":"api/interface/#lean_interact.interface.TermNode.elaborator","title":"elaborator  <code>instance-attribute</code>","text":"<pre><code>elaborator: str | None\n</code></pre> <p>The elaborator used for the term node, if available.</p>"},{"location":"api/interface/#lean_interact.interface.TermNode.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.TermNode.stx","title":"stx  <code>instance-attribute</code>","text":"<pre><code>stx: Syntax\n</code></pre> <p>The syntax object of the node.</p>"},{"location":"api/interface/#lean_interact.interface.Syntax","title":"Syntax","text":"<p>               Bases: <code>REPLBaseModel</code></p> <p>Lean Syntax object.</p>"},{"location":"api/interface/#lean_interact.interface.Syntax.pp","title":"pp  <code>instance-attribute</code>","text":"<pre><code>pp: str | None\n</code></pre> <p>The pretty-printed string of the syntax.</p>"},{"location":"api/interface/#lean_interact.interface.Syntax.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre> <p>The range of the syntax.</p>"},{"location":"api/interface/#lean_interact.interface.Syntax.kind","title":"kind  <code>instance-attribute</code>","text":"<pre><code>kind: str\n</code></pre> <p>The kind of the syntax..</p>"},{"location":"api/interface/#lean_interact.interface.Syntax.arg_kinds","title":"arg_kinds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>arg_kinds: list[str] = Field(\n    default_factory=list, alias=\"argKinds\"\n)\n</code></pre> <p>The kinds of the arguments of the syntax.</p>"},{"location":"api/interface/#lean_interact.interface.Syntax.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DocString","title":"DocString","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DocString.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DocString.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DocString.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers","title":"DeclModifiers","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.doc_string","title":"doc_string  <code>instance-attribute</code>","text":"<pre><code>doc_string: DocString | None\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.visibility","title":"visibility  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>visibility: Literal[\n    \"regular\", \"private\", \"protected\", \"public\"\n] = \"regular\"\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.compute_kind","title":"compute_kind  <code>instance-attribute</code>","text":"<pre><code>compute_kind: Literal['regular', 'meta', 'noncomputable']\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.rec_kind","title":"rec_kind  <code>instance-attribute</code>","text":"<pre><code>rec_kind: Literal['default', 'partial', 'nonrec']\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.is_protected","title":"is_protected  <code>instance-attribute</code>","text":"<pre><code>is_protected: bool\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.is_unsafe","title":"is_unsafe  <code>instance-attribute</code>","text":"<pre><code>is_unsafe: bool\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.attributes","title":"attributes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>attributes: list[str] = Field(default_factory=list)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclModifiers.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclSignature","title":"DeclSignature","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DeclSignature.pp","title":"pp  <code>instance-attribute</code>","text":"<pre><code>pp: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclSignature.constants","title":"constants  <code>instance-attribute</code>","text":"<pre><code>constants: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclSignature.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclSignature.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BinderView","title":"BinderView","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.BinderView.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BinderView.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BinderView.binderInfo","title":"binderInfo  <code>instance-attribute</code>","text":"<pre><code>binderInfo: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.BinderView.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclBinders","title":"DeclBinders","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DeclBinders.pp","title":"pp  <code>instance-attribute</code>","text":"<pre><code>pp: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclBinders.groups","title":"groups  <code>instance-attribute</code>","text":"<pre><code>groups: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclBinders.map","title":"map  <code>instance-attribute</code>","text":"<pre><code>map: list[BinderView]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclBinders.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclBinders.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclType","title":"DeclType","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DeclType.pp","title":"pp  <code>instance-attribute</code>","text":"<pre><code>pp: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclType.constants","title":"constants  <code>instance-attribute</code>","text":"<pre><code>constants: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclType.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclType.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclValue","title":"DeclValue","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DeclValue.pp","title":"pp  <code>instance-attribute</code>","text":"<pre><code>pp: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclValue.constants","title":"constants  <code>instance-attribute</code>","text":"<pre><code>constants: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclValue.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclValue.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.OpenDecl","title":"OpenDecl","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.OpenDecl.simple","title":"simple  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>simple: dict[str, str | list[str]] | None = None\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.OpenDecl.rename","title":"rename  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rename: dict[str, str] | None = None\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.OpenDecl.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo","title":"ScopeInfo","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.var_decls","title":"var_decls  <code>instance-attribute</code>","text":"<pre><code>var_decls: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.include_vars","title":"include_vars  <code>instance-attribute</code>","text":"<pre><code>include_vars: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.omit_vars","title":"omit_vars  <code>instance-attribute</code>","text":"<pre><code>omit_vars: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.level_names","title":"level_names  <code>instance-attribute</code>","text":"<pre><code>level_names: list[str]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.curr_namespace","title":"curr_namespace  <code>instance-attribute</code>","text":"<pre><code>curr_namespace: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.open_decl","title":"open_decl  <code>instance-attribute</code>","text":"<pre><code>open_decl: list[OpenDecl]\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.ScopeInfo.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo","title":"DeclarationInfo","text":"<p>               Bases: <code>REPLBaseModel</code></p>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.pp","title":"pp  <code>instance-attribute</code>","text":"<pre><code>pp: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Range\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.scope","title":"scope  <code>instance-attribute</code>","text":"<pre><code>scope: ScopeInfo\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.full_name","title":"full_name  <code>instance-attribute</code>","text":"<pre><code>full_name: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.kind","title":"kind  <code>instance-attribute</code>","text":"<pre><code>kind: str\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.modifiers","title":"modifiers  <code>instance-attribute</code>","text":"<pre><code>modifiers: DeclModifiers\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.signature","title":"signature  <code>instance-attribute</code>","text":"<pre><code>signature: DeclSignature\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.binders","title":"binders  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>binders: DeclBinders | None = None\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: DeclType | None = None\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: DeclValue | None = None\n</code></pre>"},{"location":"api/interface/#lean_interact.interface.DeclarationInfo.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, extra=\"allow\", populate_by_name=True\n)\n</code></pre>"},{"location":"api/project/","title":"Projects","text":""},{"location":"api/project/#lean_interact.project","title":"Projects","text":"<p>Module: <code>lean_interact.project</code></p> <p>This module provides classes for managing Lean projects, including local directories and git repositories. It supports automatic building and dependency management using <code>lake</code>, and can be used to create temporary projects with specific configurations. It is useful for setting up Lean environments for development, testing, or running benchmarks without manual setup.</p>"},{"location":"api/project/#lean_interact.project.LocalProject","title":"LocalProject  <code>dataclass</code>","text":"<pre><code>LocalProject(\n    *,\n    directory: str | PathLike,\n    lake_path: str | PathLike = \"lake\",\n    auto_build: bool = True,\n)\n</code></pre> <p>               Bases: <code>BaseProject</code></p> <p>Configuration for using an existing local Lean project directory.</p> <p>Examples:</p> <pre><code># Use an existing local project\nproject = LocalProject(\n    directory=\"/path/to/my/lean/project\",\n    auto_build=True  # Build the project automatically\n)\n\nconfig = LeanREPLConfig(project=project)\n</code></pre>"},{"location":"api/project/#lean_interact.project.LocalProject.directory","title":"directory  <code>instance-attribute</code>","text":"<pre><code>directory: str | PathLike\n</code></pre> <p>Path to the local Lean project directory.</p>"},{"location":"api/project/#lean_interact.project.LocalProject.lake_path","title":"lake_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lake_path: str | PathLike = 'lake'\n</code></pre> <p>The path to the lake executable. Default is \"lake\", which assumes it is in the system PATH.</p>"},{"location":"api/project/#lean_interact.project.LocalProject.auto_build","title":"auto_build  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>auto_build: bool = True\n</code></pre> <p>Whether to automatically build the project after instantiation.</p>"},{"location":"api/project/#lean_interact.project.LocalProject.get_directory","title":"get_directory","text":"<pre><code>get_directory() -&gt; str\n</code></pre> <p>Get the directory of the Lean project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_directory(self) -&gt; str:\n    \"\"\"Get the directory of the Lean project.\"\"\"\n    if self.directory is None:\n        raise ValueError(\"`directory` must be set\")\n    return str(Path(self.directory).resolve())\n</code></pre>"},{"location":"api/project/#lean_interact.project.LocalProject.get_lean_version","title":"get_lean_version","text":"<pre><code>get_lean_version() -&gt; str\n</code></pre> <p>The Lean version used by this project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_lean_version(self) -&gt; str:\n    \"\"\"The Lean version used by this project.\"\"\"\n    version = get_project_lean_version(Path(self.get_directory()))\n    if version is None:\n        raise ValueError(\"Unable to determine Lean version\")\n    return version\n</code></pre>"},{"location":"api/project/#lean_interact.project.LocalProject.build","title":"build","text":"<pre><code>build(\n    verbose: bool = True,\n    update: bool = False,\n    _lock: bool = True,\n) -&gt; None\n</code></pre> <p>Build the Lean project using lake. Args:     verbose: Whether to print building information to the console.     update: Whether to run <code>lake update</code> before building.     _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def build(self, verbose: bool = True, update: bool = False, _lock: bool = True) -&gt; None:\n    \"\"\"Build the Lean project using lake.\n    Args:\n        verbose: Whether to print building information to the console.\n        update: Whether to run `lake update` before building.\n        _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).\n    \"\"\"\n    directory = Path(self.get_directory())\n    check_lake(self.lake_path, verbose=verbose)\n\n    def _do_build():\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n        try:\n            # Run lake update if requested\n            if update:\n                subprocess.run(\n                    [str(self.lake_path), \"update\"], cwd=directory, check=True, stdout=stdout, stderr=stderr\n                )\n\n            # Try to get cache first (non-fatal if it fails)\n            cache_result = subprocess.run(\n                [str(self.lake_path), \"exe\", \"cache\", \"get\"],\n                cwd=directory,\n                check=False,\n                stdout=stdout,\n                stderr=stderr,\n            )\n            if cache_result.returncode != 0 and verbose:\n                logger.info(\n                    \"Getting 'error: unknown executable cache' is expected if the project doesn't depend on Mathlib\"\n                )\n\n            # Build the project (this must succeed)\n            subprocess.run([str(self.lake_path), \"build\"], cwd=directory, check=True, stdout=stdout, stderr=stderr)\n            logger.debug(\"Successfully built project at %s\", directory)\n\n        except subprocess.CalledProcessError as e:\n            logger.error(\"Failed to build the project: %s\", e)\n            raise\n\n    if _lock:\n        with FileLock(f\"{directory}.lock\"):\n            _do_build()\n    else:\n        _do_build()\n</code></pre>"},{"location":"api/project/#lean_interact.project.GitProject","title":"GitProject  <code>dataclass</code>","text":"<pre><code>GitProject(\n    *,\n    directory: str | PathLike | None = None,\n    lake_path: str | PathLike = \"lake\",\n    auto_build: bool = True,\n    url: str,\n    rev: str | None = None,\n    force_pull: bool = False,\n)\n</code></pre> <p>               Bases: <code>BaseProject</code></p> <p>Configuration for using an online git repository containing a Lean project.</p> <p>Examples:</p> <pre><code># Clone and use a Git repository\nproject = GitProject(\n    url=\"https://github.com/user/lean-project\",\n    rev=\"main\",  # Optional: specific branch/tag/commit\n    directory=\"/custom/cache/dir\",  # Optional: custom directory\n    force_pull=False  # Optional: force update on each use\n)\n\nconfig = LeanREPLConfig(project=project)\n</code></pre>"},{"location":"api/project/#lean_interact.project.GitProject.url","title":"url  <code>instance-attribute</code>","text":"<pre><code>url: str\n</code></pre> <p>The git URL of the repository to clone.</p>"},{"location":"api/project/#lean_interact.project.GitProject.directory","title":"directory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>directory: str | PathLike | None = field(default=None)\n</code></pre> <p>The directory where the git project will be cloned. If None, a unique path inside the default LeanInteract cache directory will be used.</p>"},{"location":"api/project/#lean_interact.project.GitProject.rev","title":"rev  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rev: str | None = None\n</code></pre> <p>The specific git revision (tag, branch, or commit hash) to checkout. If None, uses the default branch.</p>"},{"location":"api/project/#lean_interact.project.GitProject.force_pull","title":"force_pull  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_pull: bool = False\n</code></pre> <p>Whether to force pull the latest changes from the remote repository, overwriting local changes.</p>"},{"location":"api/project/#lean_interact.project.GitProject.lake_path","title":"lake_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lake_path: str | PathLike = 'lake'\n</code></pre> <p>The path to the lake executable. Default is \"lake\", which assumes it is in the system PATH.</p>"},{"location":"api/project/#lean_interact.project.GitProject.auto_build","title":"auto_build  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>auto_build: bool = True\n</code></pre> <p>Whether to automatically build the project after instantiation.</p>"},{"location":"api/project/#lean_interact.project.GitProject.get_directory","title":"get_directory","text":"<pre><code>get_directory() -&gt; str\n</code></pre> <p>Get the directory of the Lean project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_directory(self) -&gt; str:\n    \"\"\"Get the directory of the Lean project.\"\"\"\n    if self.directory is None:\n        raise ValueError(\"`directory` must be set\")\n    return str(Path(self.directory).resolve())\n</code></pre>"},{"location":"api/project/#lean_interact.project.GitProject.get_lean_version","title":"get_lean_version","text":"<pre><code>get_lean_version() -&gt; str\n</code></pre> <p>The Lean version used by this project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_lean_version(self) -&gt; str:\n    \"\"\"The Lean version used by this project.\"\"\"\n    version = get_project_lean_version(Path(self.get_directory()))\n    if version is None:\n        raise ValueError(\"Unable to determine Lean version\")\n    return version\n</code></pre>"},{"location":"api/project/#lean_interact.project.GitProject.build","title":"build","text":"<pre><code>build(\n    verbose: bool = True,\n    update: bool = False,\n    _lock: bool = True,\n) -&gt; None\n</code></pre> <p>Build the Lean project using lake. Args:     verbose: Whether to print building information to the console.     update: Whether to run <code>lake update</code> before building.     _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def build(self, verbose: bool = True, update: bool = False, _lock: bool = True) -&gt; None:\n    \"\"\"Build the Lean project using lake.\n    Args:\n        verbose: Whether to print building information to the console.\n        update: Whether to run `lake update` before building.\n        _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).\n    \"\"\"\n    directory = Path(self.get_directory())\n    check_lake(self.lake_path, verbose=verbose)\n\n    def _do_build():\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n        try:\n            # Run lake update if requested\n            if update:\n                subprocess.run(\n                    [str(self.lake_path), \"update\"], cwd=directory, check=True, stdout=stdout, stderr=stderr\n                )\n\n            # Try to get cache first (non-fatal if it fails)\n            cache_result = subprocess.run(\n                [str(self.lake_path), \"exe\", \"cache\", \"get\"],\n                cwd=directory,\n                check=False,\n                stdout=stdout,\n                stderr=stderr,\n            )\n            if cache_result.returncode != 0 and verbose:\n                logger.info(\n                    \"Getting 'error: unknown executable cache' is expected if the project doesn't depend on Mathlib\"\n                )\n\n            # Build the project (this must succeed)\n            subprocess.run([str(self.lake_path), \"build\"], cwd=directory, check=True, stdout=stdout, stderr=stderr)\n            logger.debug(\"Successfully built project at %s\", directory)\n\n        except subprocess.CalledProcessError as e:\n            logger.error(\"Failed to build the project: %s\", e)\n            raise\n\n    if _lock:\n        with FileLock(f\"{directory}.lock\"):\n            _do_build()\n    else:\n        _do_build()\n</code></pre>"},{"location":"api/project/#lean_interact.project.TemporaryProject","title":"TemporaryProject  <code>dataclass</code>","text":"<pre><code>TemporaryProject(\n    *,\n    directory: str | PathLike | None = None,\n    lake_path: str | PathLike = \"lake\",\n    auto_build: bool = True,\n    lean_version: str,\n    verbose: bool = True,\n    content: str,\n    lakefile_type: Literal[\"lean\", \"toml\"] = \"lean\",\n)\n</code></pre> <p>               Bases: <code>BaseTempProject</code></p> <p>Configuration for creating a temporary Lean project with custom lakefile content.</p> <p>Examples:</p> <pre><code># Create a temporary project with custom lakefile\nproject = TemporaryProject(\n    lean_version=\"v4.19.0\",\n    content=\"\"\"\nimport Lake\nopen Lake DSL\n\npackage \"my_temp_project\" where\nversion := v!\"0.1.0\"\n\nrequire mathlib from git\n\"https://github.com/leanprover-community/mathlib4.git\" @ \"v4.19.0\"\n\"\"\",\n    lakefile_type=\"lean\"  # or \"toml\"\n)\n\nconfig = LeanREPLConfig(project=project)\n</code></pre>"},{"location":"api/project/#lean_interact.project.TemporaryProject.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre> <p>The content to write to the lakefile (either lakefile.lean or lakefile.toml format).</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.lakefile_type","title":"lakefile_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lakefile_type: Literal['lean', 'toml'] = 'lean'\n</code></pre> <p>The type of lakefile to create. Either 'lean' for lakefile.lean or 'toml' for lakefile.toml.</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.directory","title":"directory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>directory: str | PathLike | None = field(default=None)\n</code></pre> <p>The directory where temporary Lean projects will be cached. If None, a unique path inside the default LeanInteract cache directory will be used.</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.lake_path","title":"lake_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lake_path: str | PathLike = 'lake'\n</code></pre> <p>The path to the lake executable. Default is \"lake\", which assumes it is in the system PATH.</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.auto_build","title":"auto_build  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>auto_build: bool = True\n</code></pre> <p>Whether to automatically build the project after instantiation.</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.lean_version","title":"lean_version  <code>instance-attribute</code>","text":"<pre><code>lean_version: str\n</code></pre> <p>The Lean version to use for this project.</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.verbose","title":"verbose  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>verbose: bool = True\n</code></pre> <p>Whether to print additional information during the setup process.</p>"},{"location":"api/project/#lean_interact.project.TemporaryProject.get_directory","title":"get_directory","text":"<pre><code>get_directory() -&gt; str\n</code></pre> <p>Get the directory of the Lean project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_directory(self) -&gt; str:\n    \"\"\"Get the directory of the Lean project.\"\"\"\n    if self.directory is None:\n        raise ValueError(\"`directory` must be set\")\n    return str(Path(self.directory).resolve())\n</code></pre>"},{"location":"api/project/#lean_interact.project.TemporaryProject.get_lean_version","title":"get_lean_version","text":"<pre><code>get_lean_version() -&gt; str\n</code></pre> <p>The Lean version used by this project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_lean_version(self) -&gt; str:\n    \"\"\"The Lean version used by this project.\"\"\"\n    version = get_project_lean_version(Path(self.get_directory()))\n    if version is None:\n        raise ValueError(\"Unable to determine Lean version\")\n    return version\n</code></pre>"},{"location":"api/project/#lean_interact.project.TemporaryProject.build","title":"build","text":"<pre><code>build(\n    verbose: bool = True,\n    update: bool = False,\n    _lock: bool = True,\n) -&gt; None\n</code></pre> <p>Build the Lean project using lake. Args:     verbose: Whether to print building information to the console.     update: Whether to run <code>lake update</code> before building.     _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def build(self, verbose: bool = True, update: bool = False, _lock: bool = True) -&gt; None:\n    \"\"\"Build the Lean project using lake.\n    Args:\n        verbose: Whether to print building information to the console.\n        update: Whether to run `lake update` before building.\n        _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).\n    \"\"\"\n    directory = Path(self.get_directory())\n    check_lake(self.lake_path, verbose=verbose)\n\n    def _do_build():\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n        try:\n            # Run lake update if requested\n            if update:\n                subprocess.run(\n                    [str(self.lake_path), \"update\"], cwd=directory, check=True, stdout=stdout, stderr=stderr\n                )\n\n            # Try to get cache first (non-fatal if it fails)\n            cache_result = subprocess.run(\n                [str(self.lake_path), \"exe\", \"cache\", \"get\"],\n                cwd=directory,\n                check=False,\n                stdout=stdout,\n                stderr=stderr,\n            )\n            if cache_result.returncode != 0 and verbose:\n                logger.info(\n                    \"Getting 'error: unknown executable cache' is expected if the project doesn't depend on Mathlib\"\n                )\n\n            # Build the project (this must succeed)\n            subprocess.run([str(self.lake_path), \"build\"], cwd=directory, check=True, stdout=stdout, stderr=stderr)\n            logger.debug(\"Successfully built project at %s\", directory)\n\n        except subprocess.CalledProcessError as e:\n            logger.error(\"Failed to build the project: %s\", e)\n            raise\n\n    if _lock:\n        with FileLock(f\"{directory}.lock\"):\n            _do_build()\n    else:\n        _do_build()\n</code></pre>"},{"location":"api/project/#lean_interact.project.TempRequireProject","title":"TempRequireProject  <code>dataclass</code>","text":"<pre><code>TempRequireProject(\n    *,\n    directory: str | PathLike | None = None,\n    lake_path: str | PathLike = \"lake\",\n    auto_build: bool = True,\n    lean_version: str,\n    verbose: bool = True,\n    require: Literal[\"mathlib\"]\n    | LeanRequire\n    | list[LeanRequire | Literal[\"mathlib\"]],\n)\n</code></pre> <p>               Bases: <code>BaseTempProject</code></p> <p>Configuration for setting up a temporary project with specific dependencies.</p> <p>As Mathlib is a common dependency, you can just set <code>require=\"mathlib\"</code> and a compatible version of mathlib will be used. This feature has been developed mostly to be able to run benchmarks using Mathlib as a dependency (such as ProofNet# or MiniF2F) without having to manually set up a Lean project.</p> <p>Examples:</p> <pre><code># Create a temporary project with Mathlib\nproject = TempRequireProject(\n    lean_version=\"v4.19.0\",\n    require=\"mathlib\"  # Shortcut for Mathlib\n)\n\n# Or with custom dependencies\nproject = TempRequireProject(\n    lean_version=\"v4.19.0\",\n    require=[\n        LeanRequire(\"mathlib\", \"https://github.com/leanprover-community/mathlib4.git\", \"v4.19.0\"),\n        LeanRequire(\"my_lib\", \"https://github.com/user/my-lib.git\", \"v1.0.0\")\n    ]\n)\n\nconfig = LeanREPLConfig(project=project)\n</code></pre>"},{"location":"api/project/#lean_interact.project.TempRequireProject.require","title":"require  <code>instance-attribute</code>","text":"<pre><code>require: (\n    Literal[\"mathlib\"]\n    | LeanRequire\n    | list[LeanRequire | Literal[\"mathlib\"]]\n)\n</code></pre> <p>The dependencies to include in the project. Can be:</p> <ul> <li>\"mathlib\" for automatic Mathlib dependency matching the Lean version</li> <li>A single LeanRequire object for a custom dependency</li> <li>A list of dependencies (mix of \"mathlib\" and LeanRequire objects)</li> </ul>"},{"location":"api/project/#lean_interact.project.TempRequireProject.directory","title":"directory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>directory: str | PathLike | None = field(default=None)\n</code></pre> <p>The directory where temporary Lean projects will be cached. If None, a unique path inside the default LeanInteract cache directory will be used.</p>"},{"location":"api/project/#lean_interact.project.TempRequireProject.lake_path","title":"lake_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lake_path: str | PathLike = 'lake'\n</code></pre> <p>The path to the lake executable. Default is \"lake\", which assumes it is in the system PATH.</p>"},{"location":"api/project/#lean_interact.project.TempRequireProject.auto_build","title":"auto_build  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>auto_build: bool = True\n</code></pre> <p>Whether to automatically build the project after instantiation.</p>"},{"location":"api/project/#lean_interact.project.TempRequireProject.lean_version","title":"lean_version  <code>instance-attribute</code>","text":"<pre><code>lean_version: str\n</code></pre> <p>The Lean version to use for this project.</p>"},{"location":"api/project/#lean_interact.project.TempRequireProject.verbose","title":"verbose  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>verbose: bool = True\n</code></pre> <p>Whether to print additional information during the setup process.</p>"},{"location":"api/project/#lean_interact.project.TempRequireProject.get_directory","title":"get_directory","text":"<pre><code>get_directory() -&gt; str\n</code></pre> <p>Get the directory of the Lean project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_directory(self) -&gt; str:\n    \"\"\"Get the directory of the Lean project.\"\"\"\n    if self.directory is None:\n        raise ValueError(\"`directory` must be set\")\n    return str(Path(self.directory).resolve())\n</code></pre>"},{"location":"api/project/#lean_interact.project.TempRequireProject.get_lean_version","title":"get_lean_version","text":"<pre><code>get_lean_version() -&gt; str\n</code></pre> <p>The Lean version used by this project.</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def get_lean_version(self) -&gt; str:\n    \"\"\"The Lean version used by this project.\"\"\"\n    version = get_project_lean_version(Path(self.get_directory()))\n    if version is None:\n        raise ValueError(\"Unable to determine Lean version\")\n    return version\n</code></pre>"},{"location":"api/project/#lean_interact.project.TempRequireProject.build","title":"build","text":"<pre><code>build(\n    verbose: bool = True,\n    update: bool = False,\n    _lock: bool = True,\n) -&gt; None\n</code></pre> <p>Build the Lean project using lake. Args:     verbose: Whether to print building information to the console.     update: Whether to run <code>lake update</code> before building.     _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).</p> Source code in <code>src/lean_interact/project.py</code> <pre><code>def build(self, verbose: bool = True, update: bool = False, _lock: bool = True) -&gt; None:\n    \"\"\"Build the Lean project using lake.\n    Args:\n        verbose: Whether to print building information to the console.\n        update: Whether to run `lake update` before building.\n        _lock: (internal parameter) Whether to acquire a file lock (should be False if already locked by caller).\n    \"\"\"\n    directory = Path(self.get_directory())\n    check_lake(self.lake_path, verbose=verbose)\n\n    def _do_build():\n        stdout = None if verbose else subprocess.DEVNULL\n        stderr = None if verbose else subprocess.DEVNULL\n        try:\n            # Run lake update if requested\n            if update:\n                subprocess.run(\n                    [str(self.lake_path), \"update\"], cwd=directory, check=True, stdout=stdout, stderr=stderr\n                )\n\n            # Try to get cache first (non-fatal if it fails)\n            cache_result = subprocess.run(\n                [str(self.lake_path), \"exe\", \"cache\", \"get\"],\n                cwd=directory,\n                check=False,\n                stdout=stdout,\n                stderr=stderr,\n            )\n            if cache_result.returncode != 0 and verbose:\n                logger.info(\n                    \"Getting 'error: unknown executable cache' is expected if the project doesn't depend on Mathlib\"\n                )\n\n            # Build the project (this must succeed)\n            subprocess.run([str(self.lake_path), \"build\"], cwd=directory, check=True, stdout=stdout, stderr=stderr)\n            logger.debug(\"Successfully built project at %s\", directory)\n\n        except subprocess.CalledProcessError as e:\n            logger.error(\"Failed to build the project: %s\", e)\n            raise\n\n    if _lock:\n        with FileLock(f\"{directory}.lock\"):\n            _do_build()\n    else:\n        _do_build()\n</code></pre>"},{"location":"api/project/#lean_interact.project.LeanRequire","title":"LeanRequire  <code>dataclass</code>","text":"<pre><code>LeanRequire(name: str, git: str, rev: str | None = None)\n</code></pre> <p>Lean project dependency specification for <code>lakefile.lean</code> files.</p>"},{"location":"api/project/#lean_interact.project.LeanRequire.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the dependency package.</p>"},{"location":"api/project/#lean_interact.project.LeanRequire.git","title":"git  <code>instance-attribute</code>","text":"<pre><code>git: str\n</code></pre> <p>The git URL of the dependency repository.</p>"},{"location":"api/project/#lean_interact.project.LeanRequire.rev","title":"rev  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rev: str | None = None\n</code></pre> <p>The specific git revision (tag, branch, or commit hash) to use. If None, uses the default branch.</p>"},{"location":"api/server/","title":"Lean Server","text":""},{"location":"api/server/#lean_interact.server","title":"Lean Servers","text":"<p>Module: <code>lean_interact.server</code></p> <p>This module provides the <code>LeanServer</code> and <code>AutoLeanServer</code> classes, which are used to interact with the Lean REPL (Read-Eval-Print Loop). The <code>LeanServer</code> class is a simple wrapper around the Lean REPL, while the <code>AutoLeanServer</code> class adds automatic memory management and session caching features.</p>"},{"location":"api/server/#lean_interact.server.LeanServer","title":"LeanServer","text":"<pre><code>LeanServer(config: LeanREPLConfig)\n</code></pre> <p>This class is a Python wrapper for the Lean REPL. Please refer to the         documentation for usage examples.</p> Warning <p>Instantiate a single config before starting multiprocessing. Then instantiate one <code>LeanServer</code> per process by passing the config instance to the constructor. This will ensure that the REPL is already set up for your specific environment and avoid concurrency conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LeanREPLConfig</code> <p>The configuration for the Lean server.</p> required Source code in <code>src/lean_interact/server.py</code> <pre><code>def __init__(self, config: LeanREPLConfig):\n    \"\"\"\n    This class is a Python wrapper for the Lean REPL. Please refer to the \\\n    [documentation](https://augustepoiroux.github.io/LeanInteract/stable/user-guide/basic-usage/) for usage examples.\n\n    Warning:\n        Instantiate a single config before starting multiprocessing. Then instantiate one `LeanServer`\n        per process by passing the config instance to the constructor. This will ensure that the REPL is already set up\n        for your specific environment and avoid concurrency conflicts.\n\n    Args:\n        config: The configuration for the Lean server.\n    \"\"\"\n    self.config = config\n    assert self.config.is_setup(), \"The Lean environment has not been set up properly.\"\n    self._proc = None\n    self._lock = threading.Lock()\n    self.start()\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config: LeanREPLConfig = config\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.lean_version","title":"lean_version  <code>property</code>","text":"<pre><code>lean_version: str | None\n</code></pre> <p>Get the Lean version used by the Lean REPL server.</p>"},{"location":"api/server/#lean_interact.server.LeanServer.start","title":"start","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start the Lean REPL server process. This is called automatically in the constructor.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the Lean REPL server process. This is called automatically in the constructor.\"\"\"\n\n    self._proc = subprocess.Popen(\n        [\n            str(self.config.lake_path),\n            \"env\",\n            str(os.path.join(self.config._cache_repl_dir, \".lake\", \"build\", \"bin\", \"repl\")),\n        ],\n        cwd=self.config.working_dir,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        encoding=\"utf-8\",\n        text=True,\n        bufsize=1,\n        start_new_session=True,\n        preexec_fn=None\n        if platform.system() != \"Linux\"\n        else lambda: _limit_memory(self.config.memory_hard_limit_mb),\n    )\n    if not self.is_alive():\n        stdout, stderr = self.get_stdout_stderr()\n        raise ChildProcessError(f\"The Lean server could not be started:\\nstdout: {stdout}\\nstderr: {stderr}\")\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.get_stdout_stderr","title":"get_stdout_stderr","text":"<pre><code>get_stdout_stderr() -&gt; tuple[str, str]\n</code></pre> <p>Get the stdout and stderr output from the Lean REPL.</p> <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>A tuple containing the stdout and stderr output.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def get_stdout_stderr(self) -&gt; tuple[str, str]:\n    \"\"\"Get the stdout and stderr output from the Lean REPL.\n\n    Returns:\n        A tuple containing the stdout and stderr output.\n    \"\"\"\n    stdout = self._proc.stdout.read() if self._proc and self._proc.stdout else \"\"\n    stderr = self._proc.stderr.read() if self._proc and self._proc.stderr else \"\"\n    return stdout, stderr\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.is_alive","title":"is_alive","text":"<pre><code>is_alive() -&gt; bool\n</code></pre> <p>Check if the Lean REPL server process is running.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def is_alive(self) -&gt; bool:\n    \"\"\"Check if the Lean REPL server process is running.\"\"\"\n    return self._proc is not None and self._proc.poll() is None\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.kill","title":"kill","text":"<pre><code>kill() -&gt; None\n</code></pre> <p>Kill the Lean REPL server process and its children.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def kill(self) -&gt; None:\n    \"\"\"Kill the Lean REPL server process and its children.\"\"\"\n    if self._proc:\n        try:\n            proc = psutil.Process(self._proc.pid)\n            # Terminate the process tree\n            children = proc.children(recursive=True)\n            for child in children:\n                try:\n                    child.terminate()\n                except Exception:\n                    pass\n            proc.terminate()\n            _, alive = psutil.wait_procs([proc] + children, timeout=1)\n            for p in alive:\n                try:\n                    p.kill()\n                except Exception:\n                    pass\n        except Exception:\n            pass\n        finally:\n            try:\n                self._proc.wait(timeout=1)  # Ensure the process is properly reaped\n            except Exception:\n                pass\n        if self._proc.stdin:\n            self._proc.stdin.close()\n        if self._proc.stdout:\n            self._proc.stdout.close()\n        if self._proc.stderr:\n            self._proc.stderr.close()\n        self._proc = None\n    gc.collect()\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.restart","title":"restart","text":"<pre><code>restart() -&gt; None\n</code></pre> <p>Restart the Lean REPL server.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def restart(self) -&gt; None:\n    \"\"\"Restart the Lean REPL server.\"\"\"\n    self.kill()\n    self.start()\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.get_memory_usage","title":"get_memory_usage","text":"<pre><code>get_memory_usage() -&gt; float\n</code></pre> <p>Get the memory usage of the Lean REPL server process in MB.</p> <p>Returns:</p> Type Description <code>float</code> <p>Memory usage in MB.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def get_memory_usage(self) -&gt; float:\n    \"\"\"\n    Get the memory usage of the Lean REPL server process in MB.\n\n    Returns:\n        Memory usage in MB.\n    \"\"\"\n    if self._proc is None:\n        return 0.0\n    try:\n        proc = psutil.Process(self._proc.pid)\n        return get_total_memory_usage(proc) / (1024**2)  # Convert bytes to MB\n    except psutil.NoSuchProcess:\n        return 0.0\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.run_dict","title":"run_dict","text":"<pre><code>run_dict(\n    request: dict,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n) -&gt; dict\n</code></pre> <p>Run a Lean REPL dictionary request and return the Lean server output as a dictionary.</p> Info <p>When working with custom REPL implementations that might have incompatible interfaces with LeanInteract's standard commands, you can use the <code>run_dict</code> method to communicate directly with the REPL using the raw JSON protocol. This method bypasses the command-specific parsing and validation, allowing you to work with custom REPL interfaces.</p> <p>Examples:</p> <pre><code># Using run_dict to send a raw command to the REPL\nresult = server.run_dict({\"cmd\": \"your Lean code here\"})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>dict</code> <p>The Lean REPL request to execute. Must be a dictionary.</p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information during the verification process.</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <p>Returns:</p> Type Description <code>dict</code> <p>The output of the Lean server as a dictionary.</p> <p>Raises:</p> Type Description <code>TimeoutError</code> <p>If the Lean server does not respond within the specified timeout.</p> <code>ConnectionAbortedError</code> <p>If the Lean server closes unexpectedly.</p> <code>ChildProcessError</code> <p>If the Lean server is not running.</p> <code>JsonDecodeError</code> <p>If the Lean server output is not valid JSON.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run_dict(self, request: dict, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT) -&gt; dict:\n    \"\"\"\n    Run a Lean REPL dictionary request and return the Lean server output as a dictionary.\n\n    Info:\n        When working with custom REPL implementations that might have incompatible interfaces with\n        LeanInteract's standard commands, you can use the `run_dict` method to communicate directly\n        with the REPL using the raw JSON protocol. This method bypasses the command-specific parsing\n        and validation, allowing you to work with custom REPL interfaces.\n\n    Examples:\n        ```python\n        # Using run_dict to send a raw command to the REPL\n        result = server.run_dict({\"cmd\": \"your Lean code here\"})\n        ```\n\n    Args:\n        request: The Lean REPL request to execute. Must be a dictionary.\n        verbose: Whether to print additional information during the verification process.\n        timeout: The timeout for the request in seconds\n\n    Returns:\n        The output of the Lean server as a dictionary.\n\n    Raises:\n        TimeoutError: If the Lean server does not respond within the specified timeout.\n        ConnectionAbortedError: If the Lean server closes unexpectedly.\n        ChildProcessError: If the Lean server is not running.\n        JsonDecodeError: If the Lean server output is not valid JSON.\n    \"\"\"\n    if not self.is_alive():\n        stdout, stderr = self.get_stdout_stderr()\n        raise ChildProcessError(\n            f\"The Lean server is not running.\\n{'-' * 50}\\nstdout:\\n{stdout}\\n{'-' * 50}\\nstderr:\\n{stderr}\\n{'-' * 50}\"\n        )\n\n    json_query = json.dumps(request, ensure_ascii=False)\n    try:\n        raw_output = self._execute_cmd_in_repl(json_query, verbose, timeout)\n    except TimeoutError as e:\n        self.kill()\n        raise TimeoutError(f\"The Lean server did not respond in time ({timeout=}) and is now killed.\") from e\n    except BrokenPipeError as e:\n        stdout, stderr = self.get_stdout_stderr()\n        self.kill()\n        raise ConnectionAbortedError(\n            f\"The Lean server closed unexpectedly.\"\n            f\"\\n{'-' * 50}\\nstdout:\\n{stdout}\\n{'-' * 50}\\nstderr:\\n{stderr}\\n{'-' * 50}\"\n            f\"\\nIf stdout and stderr are empty or obscure, here is a list of possible reasons (not exhaustive):\\n\"\n            \"- Not enough memory and/or compute available\\n\"\n            \"- The cached Lean REPL is corrupted. In this case, clear the cache using the `clear-lean-cache` command.\\n\"\n            \"- An uncaught exception in the Lean REPL\"\n        ) from e\n\n    return self._parse_repl_output(raw_output, verbose)\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.run","title":"run","text":"<pre><code>run(\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    **kwargs,\n) -&gt; BaseREPLResponse | LeanError\n</code></pre> <p>Run a Lean REPL request.</p> Note <p>Thread-safe: Uses a <code>threading.Lock</code> to ensure only one operation runs at a time.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BaseREPLQuery</code> <p>The Lean REPL request to execute. Must be one of the following types: <code>Command</code>, <code>FileCommand</code>, <code>ProofStep</code>, <code>PickleEnvironment</code>, <code>PickleProofState</code>, <code>UnpickleEnvironment</code>, or <code>UnpickleProofState</code></p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <p>Returns:</p> Type Description <code>BaseREPLResponse | LeanError</code> <p>Depending on the request type, the response will be one of the following: <code>CommandResponse</code>, <code>ProofStepResponse</code>, or <code>LeanError</code></p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run(\n    self, request: BaseREPLQuery, *, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT, **kwargs\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Run a Lean REPL request.\n\n    Note:\n        **Thread-safe:** Uses a `threading.Lock` to ensure only one operation runs at a time.\n\n    Args:\n        request: The Lean REPL request to execute. Must be one of the following types:\n            `Command`, `FileCommand`, `ProofStep`, `PickleEnvironment`, `PickleProofState`,\n            `UnpickleEnvironment`, or `UnpickleProofState`\n        verbose: Whether to print additional information\n        timeout: The timeout for the request in seconds\n\n    Returns:\n        Depending on the request type, the response will be one of the following:\n            `CommandResponse`, `ProofStepResponse`, or `LeanError`\n    \"\"\"\n    request = self._augment_request(request)\n    request_dict = request.model_dump(exclude_none=True, by_alias=True)\n    result_dict = self.run_dict(request=request_dict, verbose=verbose, timeout=timeout, **kwargs)\n\n    if set(result_dict.keys()) == {\"message\"}:\n        return LeanError.model_validate(result_dict)\n\n    if isinstance(request, (Command, FileCommand, PickleEnvironment, UnpickleEnvironment)):\n        return CommandResponse.model_validate(result_dict)\n    elif isinstance(request, (ProofStep, PickleProofState, UnpickleProofState)):\n        return ProofStepResponse.model_validate(result_dict)\n    else:\n        return BaseREPLResponse.model_validate(result_dict)\n</code></pre>"},{"location":"api/server/#lean_interact.server.LeanServer.async_run","title":"async_run  <code>async</code>","text":"<pre><code>async_run(\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    **kwargs,\n) -&gt; BaseREPLResponse | LeanError\n</code></pre> <p>Asynchronous version of <code>run()</code>. Runs the blocking <code>run()</code> in a thread pool.</p> Note <p>Thread-safe: Uses a <code>threading.Lock</code> to ensure only one operation runs at a time.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BaseREPLQuery</code> <p>The Lean REPL request to execute. Must be one of the following types: <code>Command</code>, <code>FileCommand</code>, <code>ProofStep</code>, <code>PickleEnvironment</code>, <code>PickleProofState</code>, <code>UnpickleEnvironment</code>, or <code>UnpickleProofState</code></p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <p>Returns:</p> Type Description <code>BaseREPLResponse | LeanError</code> <p>Depending on the request type, the response will be one of the following: <code>CommandResponse</code>, <code>ProofStepResponse</code>, or <code>LeanError</code></p> Source code in <code>src/lean_interact/server.py</code> <pre><code>async def async_run(\n    self, request: BaseREPLQuery, *, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT, **kwargs\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Asynchronous version of `run()`. Runs the blocking `run()` in a thread pool.\n\n    Note:\n        **Thread-safe:** Uses a `threading.Lock` to ensure only one operation runs at a time.\n\n    Args:\n        request: The Lean REPL request to execute. Must be one of the following types:\n            `Command`, `FileCommand`, `ProofStep`, `PickleEnvironment`, `PickleProofState`,\n            `UnpickleEnvironment`, or `UnpickleProofState`\n        verbose: Whether to print additional information\n        timeout: The timeout for the request in seconds\n\n    Returns:\n        Depending on the request type, the response will be one of the following:\n            `CommandResponse`, `ProofStepResponse`, or `LeanError`\n    \"\"\"\n    return await asyncio.to_thread(self.run, request, verbose=verbose, timeout=timeout, **kwargs)  # type: ignore\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer","title":"AutoLeanServer","text":"<pre><code>AutoLeanServer(\n    config: LeanREPLConfig,\n    max_total_memory: float = 0.8,\n    max_process_memory: float | None = 0.8,\n    max_restart_attempts: int = 5,\n    session_cache: BaseSessionCache | None = None,\n)\n</code></pre> <p>               Bases: <code>LeanServer</code></p> <p>This class is a Python wrapper for the Lean REPL. <code>AutoLeanServer</code> differs from <code>LeanServer</code> by automatically         restarting when it runs out of memory to clear Lean environment states.         It also automatically recovers from timeouts.         An exponential backoff strategy is used to restart the server, making this class slightly more friendly for multiprocessing than <code>LeanServer</code> when multiple instances are competing for resources.         Please refer to the documentation for usage examples.</p> Note <p>A session cache is implemented to keep user-selected environment / proof states across these automatic restarts.             Use the <code>add_to_session_cache</code> parameter in the different class methods to add the command to             the session cache. <code>AutoLeanServer</code> works best when only a few states are cached simultaneously.             You can use <code>remove_from_session_cache</code> and <code>clear_session_cache</code> to clear the session cache.             Cached state indices are negative integers starting from -1 to not conflict with the positive integers used by the Lean REPL.</p> Note <p>The session cache is specific to each <code>AutoLeanServer</code> instance and is cleared when the instance is deleted.             If you want truly persistent states, you can use the <code>pickle</code> and <code>unpickle</code> methods to save and load states to disk.</p> Warning <p>Instantiate a single config before starting multiprocessing. Then instantiate one <code>LeanServer</code> per process by passing the config instance to the constructor. This will ensure that the REPL is already set up for your specific environment and avoid concurrency conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LeanREPLConfig</code> <p>The configuration for the Lean server.</p> required <code>max_total_memory</code> <code>float</code> <p>The maximum proportion of system-wide memory usage (across all processes) before triggering a Lean server restart. This is a soft limit ranging from 0.0 to 1.0, with default 0.8 (80%). When system memory exceeds this threshold, the server restarts to free memory. Particularly useful in multiprocessing environments to prevent simultaneous crashes.</p> <code>0.8</code> <code>max_process_memory</code> <code>float | None</code> <p>The maximum proportion of the memory hard limit (set in <code>LeanREPLConfig.memory_hard_limit_mb</code>) that the Lean server process can use before restarting. This soft limit ranges from 0.0 to 1.0, with default 0.8 (80%). Only applied if a hard limit is configured in <code>LeanREPLConfig</code>.</p> <code>0.8</code> <code>max_restart_attempts</code> <code>int</code> <p>The maximum number of consecutive restart attempts allowed before raising a <code>MemoryError</code> exception. Default is 5. The server uses exponential backoff between restart attempts.</p> <code>5</code> <code>session_cache</code> <code>BaseSessionCache | None</code> <p>Optional session cache implementation. Defaults to <code>ReplaySessionCache()</code>. Use <code>PickleSessionCache</code> if you explicitly need on-disk artifacts.</p> <code>None</code> Source code in <code>src/lean_interact/server.py</code> <pre><code>def __init__(\n    self,\n    config: LeanREPLConfig,\n    max_total_memory: float = 0.8,\n    max_process_memory: float | None = 0.8,\n    max_restart_attempts: int = 5,\n    session_cache: BaseSessionCache | None = None,\n):\n    \"\"\"\n    This class is a Python wrapper for the Lean REPL. `AutoLeanServer` differs from `LeanServer` by automatically \\\n    restarting when it runs out of memory to clear Lean environment states. \\\n    It also automatically recovers from timeouts. \\\n    An exponential backoff strategy is used to restart the server, making this class slightly more friendly for multiprocessing\n    than `LeanServer` when multiple instances are competing for resources. \\\n    Please refer to the [documentation](https://augustepoiroux.github.io/LeanInteract/stable/user-guide/basic-usage/) for usage examples.\n\n    Note:\n        A session cache is implemented to keep user-selected environment / proof states across these automatic restarts. \\\n        Use the `add_to_session_cache` parameter in the different class methods to add the command to \\\n        the session cache. `AutoLeanServer` works best when only a few states are cached simultaneously. \\\n        You can use `remove_from_session_cache` and `clear_session_cache` to clear the session cache. \\\n        Cached state indices are negative integers starting from -1 to not conflict with the positive integers used by the Lean REPL.\n\n    Note:\n        The session cache is specific to each `AutoLeanServer` instance and is cleared when the instance is deleted. \\\n        If you want truly persistent states, you can use the `pickle` and `unpickle` methods to save and load states to disk.\n\n    Warning:\n        Instantiate a single config before starting multiprocessing. Then instantiate one `LeanServer`\n        per process by passing the config instance to the constructor. This will ensure that the REPL is already set up\n        for your specific environment and avoid concurrency conflicts.\n\n    Args:\n        config: The configuration for the Lean server.\n        max_total_memory: The maximum proportion of system-wide memory usage (across all processes) before triggering a Lean server restart. This is a soft limit ranging from 0.0 to 1.0, with default 0.8 (80%). When system memory exceeds this threshold, the server restarts to free memory. Particularly useful in multiprocessing environments to prevent simultaneous crashes.\n        max_process_memory: The maximum proportion of the memory hard limit (set in `LeanREPLConfig.memory_hard_limit_mb`) that the Lean server process can use before restarting. This soft limit ranges from 0.0 to 1.0, with default 0.8 (80%). Only applied if a hard limit is configured in `LeanREPLConfig`.\n        max_restart_attempts: The maximum number of consecutive restart attempts allowed before raising a `MemoryError` exception. Default is 5. The server uses exponential backoff between restart attempts.\n        session_cache: Optional session cache implementation. Defaults to `ReplaySessionCache()`.\n            Use `PickleSessionCache` if you explicitly need on-disk artifacts.\n    \"\"\"\n    if session_cache is None:\n        session_cache = ReplaySessionCache()\n    self._session_cache: BaseSessionCache = session_cache\n    self._max_total_memory = max_total_memory\n    self._max_process_memory = max_process_memory\n    self._max_restart_attempts = max_restart_attempts\n    super().__init__(config=config)\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config: LeanREPLConfig = config\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.lean_version","title":"lean_version  <code>property</code>","text":"<pre><code>lean_version: str | None\n</code></pre> <p>Get the Lean version used by the Lean REPL server.</p>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.restart","title":"restart","text":"<pre><code>restart(verbose: bool = False) -&gt; None\n</code></pre> <p>Restart the Lean REPL server and reload the session cache.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Whether to print additional information during the restart process.</p> <code>False</code> Source code in <code>src/lean_interact/server.py</code> <pre><code>def restart(self, verbose: bool = False) -&gt; None:\n    \"\"\"\n    Restart the Lean REPL server and reload the session cache.\n\n    Args:\n        verbose: Whether to print additional information during the restart process.\n    \"\"\"\n    super().restart()\n    self._session_cache.reload(self, timeout_per_state=DEFAULT_TIMEOUT, verbose=verbose)\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.remove_from_session_cache","title":"remove_from_session_cache","text":"<pre><code>remove_from_session_cache(session_state_id: int) -&gt; None\n</code></pre> <p>Remove an environment from the session cache.</p> <p>Parameters:</p> Name Type Description Default <code>session_state_id</code> <code>int</code> <p>The session state id to remove.</p> required Source code in <code>src/lean_interact/server.py</code> <pre><code>def remove_from_session_cache(self, session_state_id: int) -&gt; None:\n    \"\"\"\n    Remove an environment from the session cache.\n\n    Args:\n        session_state_id: The session state id to remove.\n    \"\"\"\n    self._session_cache.remove(session_state_id)\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.clear_session_cache","title":"clear_session_cache","text":"<pre><code>clear_session_cache(force: bool = False) -&gt; None\n</code></pre> <p>Clear the session cache.</p> <p>Parameters:</p> Name Type Description Default <code>force</code> <code>bool</code> <p>Whether to directly clear the session cache.                 <code>force=False</code> will only clear the session cache the next time the server runs out of memory while                 still allowing you to add new content in the session cache in the meantime.</p> <code>False</code> Source code in <code>src/lean_interact/server.py</code> <pre><code>def clear_session_cache(self, force: bool = False) -&gt; None:\n    \"\"\"\n    Clear the session cache.\n\n    Args:\n        force: Whether to directly clear the session cache. \\\n            `force=False` will only clear the session cache the next time the server runs out of memory while \\\n            still allowing you to add new content in the session cache in the meantime.\n    \"\"\"\n    self._session_cache.clear()\n    if force:\n        self.restart()\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.run_dict","title":"run_dict","text":"<pre><code>run_dict(\n    request: dict,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n) -&gt; dict\n</code></pre> Warning <p>This method is not available with automated memory management. Please use <code>run</code>, or use <code>run_dict</code> from the <code>LeanServer</code> class.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method is not available with automated memory management. Please use <code>run</code>, or use <code>run_dict</code> from the <code>LeanServer</code> class.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run_dict(self, request: dict, verbose: bool = False, timeout: float | None = DEFAULT_TIMEOUT) -&gt; dict:\n    \"\"\"\n    Warning:\n        This method is not available with automated memory management. Please use `run`, or use `run_dict` from the `LeanServer` class.\n\n    Raises:\n        NotImplementedError: This method is not available with automated memory management.\n            Please use `run`, or use `run_dict` from the `LeanServer` class.\n    \"\"\"\n    raise NotImplementedError(\n        \"This method is not available with automated memory management. Please use `run`, or use `run_dict` from the `LeanServer` class.\"\n    )\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.run","title":"run","text":"<pre><code>run(\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; BaseREPLResponse | LeanError\n</code></pre> <p>Run a Lean REPL request with optional session caching.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BaseREPLQuery</code> <p>The Lean REPL request to execute. Must be one of the following types: <code>Command</code>, <code>File</code>, <code>ProofStep</code>, <code>PickleEnvironment</code>, <code>PickleProofState</code>, <code>UnpickleEnvironment</code>, or <code>UnpickleProofState</code></p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <p>Returns:</p> Type Description <code>BaseREPLResponse | LeanError</code> <p>Depending on the request type, the response will be one of the following: <code>CommandResponse</code>, <code>ProofStepResponse</code>, or <code>LeanError</code></p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def run(\n    self,\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Run a Lean REPL request with optional session caching.\n\n    Args:\n        request: The Lean REPL request to execute. Must be one of the following types:\n            `Command`, `File`, `ProofStep`, `PickleEnvironment`, `PickleProofState`,\n            `UnpickleEnvironment`, or `UnpickleProofState`\n        verbose: Whether to print additional information\n        timeout: The timeout for the request in seconds\n\n    Returns:\n        Depending on the request type, the response will be one of the following:\n            `CommandResponse`, `ProofStepResponse`, or `LeanError`\n    \"\"\"\n    request = self._augment_request(request)\n    request_dict = request.model_dump(exclude_none=True, by_alias=True)\n    result_dict = self._run_dict_backoff(request=request_dict, verbose=verbose, timeout=timeout)\n\n    if set(result_dict.keys()) == {\"message\"} or result_dict == {}:\n        response = LeanError.model_validate(result_dict)\n    elif isinstance(request, (Command, FileCommand, PickleEnvironment, UnpickleEnvironment)):\n        response = CommandResponse.model_validate(result_dict)\n        if add_to_session_cache:\n            new_env_id = self._session_cache.add(self, request, response, verbose=verbose)\n            response = response.model_copy(update={\"env\": new_env_id})\n    elif isinstance(request, (ProofStep, PickleProofState, UnpickleProofState)):\n        response = ProofStepResponse.model_validate(result_dict)\n        if add_to_session_cache:\n            new_proof_state_id = self._session_cache.add(self, request, response, verbose=verbose)\n            response = response.model_copy(update={\"proofState\": new_proof_state_id})\n    else:\n        response = BaseREPLResponse.model_validate(result_dict)\n\n    return response\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.async_run","title":"async_run  <code>async</code>","text":"<pre><code>async_run(\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; BaseREPLResponse | LeanError\n</code></pre> <p>Asynchronous version of <code>run()</code> for AutoLeanServer. Runs the blocking <code>run()</code> in a thread pool.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BaseREPLQuery</code> <p>The Lean REPL request to execute. Must be one of the following types: <code>Command</code>, <code>FileCommand</code>, <code>ProofStep</code>, <code>PickleEnvironment</code>, <code>PickleProofState</code>, <code>UnpickleEnvironment</code>, or <code>UnpickleProofState</code></p> required <code>verbose</code> <code>bool</code> <p>Whether to print additional information</p> <code>False</code> <code>timeout</code> <code>float | None</code> <p>The timeout for the request in seconds</p> <code>DEFAULT_TIMEOUT</code> <code>add_to_session_cache</code> <code>bool</code> <p>Whether to add the command to the session cache.                 If <code>True</code>, the command will be added to the session cache and the response will be updated with the new environment or proof state id.</p> <code>False</code> <p>Returns:</p> Type Description <code>BaseREPLResponse | LeanError</code> <p>Depending on the request type, the response will be one of the following: <code>CommandResponse</code>, <code>ProofStepResponse</code>, or <code>LeanError</code></p> Source code in <code>src/lean_interact/server.py</code> <pre><code>async def async_run(\n    self,\n    request: BaseREPLQuery,\n    *,\n    verbose: bool = False,\n    timeout: float | None = DEFAULT_TIMEOUT,\n    add_to_session_cache: bool = False,\n) -&gt; BaseREPLResponse | LeanError:\n    \"\"\"\n    Asynchronous version of `run()` for AutoLeanServer. Runs the blocking `run()` in a thread pool.\n\n    Args:\n        request: The Lean REPL request to execute. Must be one of the following types:\n            `Command`, `FileCommand`, `ProofStep`, `PickleEnvironment`, `PickleProofState`,\n            `UnpickleEnvironment`, or `UnpickleProofState`\n        verbose: Whether to print additional information\n        timeout: The timeout for the request in seconds\n        add_to_session_cache: Whether to add the command to the session cache. \\\n            If `True`, the command will be added to the session cache and the response will be updated with the new environment or proof state id.\n\n    Returns:\n        Depending on the request type, the response will be one of the following:\n            `CommandResponse`, `ProofStepResponse`, or `LeanError`\n    \"\"\"\n    return await asyncio.to_thread(\n        self.run,\n        request,  # type: ignore\n        verbose=verbose,\n        timeout=timeout,\n        add_to_session_cache=add_to_session_cache,\n    )\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.start","title":"start","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start the Lean REPL server process. This is called automatically in the constructor.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the Lean REPL server process. This is called automatically in the constructor.\"\"\"\n\n    self._proc = subprocess.Popen(\n        [\n            str(self.config.lake_path),\n            \"env\",\n            str(os.path.join(self.config._cache_repl_dir, \".lake\", \"build\", \"bin\", \"repl\")),\n        ],\n        cwd=self.config.working_dir,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        encoding=\"utf-8\",\n        text=True,\n        bufsize=1,\n        start_new_session=True,\n        preexec_fn=None\n        if platform.system() != \"Linux\"\n        else lambda: _limit_memory(self.config.memory_hard_limit_mb),\n    )\n    if not self.is_alive():\n        stdout, stderr = self.get_stdout_stderr()\n        raise ChildProcessError(f\"The Lean server could not be started:\\nstdout: {stdout}\\nstderr: {stderr}\")\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.get_stdout_stderr","title":"get_stdout_stderr","text":"<pre><code>get_stdout_stderr() -&gt; tuple[str, str]\n</code></pre> <p>Get the stdout and stderr output from the Lean REPL.</p> <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>A tuple containing the stdout and stderr output.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def get_stdout_stderr(self) -&gt; tuple[str, str]:\n    \"\"\"Get the stdout and stderr output from the Lean REPL.\n\n    Returns:\n        A tuple containing the stdout and stderr output.\n    \"\"\"\n    stdout = self._proc.stdout.read() if self._proc and self._proc.stdout else \"\"\n    stderr = self._proc.stderr.read() if self._proc and self._proc.stderr else \"\"\n    return stdout, stderr\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.is_alive","title":"is_alive","text":"<pre><code>is_alive() -&gt; bool\n</code></pre> <p>Check if the Lean REPL server process is running.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def is_alive(self) -&gt; bool:\n    \"\"\"Check if the Lean REPL server process is running.\"\"\"\n    return self._proc is not None and self._proc.poll() is None\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.kill","title":"kill","text":"<pre><code>kill() -&gt; None\n</code></pre> <p>Kill the Lean REPL server process and its children.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def kill(self) -&gt; None:\n    \"\"\"Kill the Lean REPL server process and its children.\"\"\"\n    if self._proc:\n        try:\n            proc = psutil.Process(self._proc.pid)\n            # Terminate the process tree\n            children = proc.children(recursive=True)\n            for child in children:\n                try:\n                    child.terminate()\n                except Exception:\n                    pass\n            proc.terminate()\n            _, alive = psutil.wait_procs([proc] + children, timeout=1)\n            for p in alive:\n                try:\n                    p.kill()\n                except Exception:\n                    pass\n        except Exception:\n            pass\n        finally:\n            try:\n                self._proc.wait(timeout=1)  # Ensure the process is properly reaped\n            except Exception:\n                pass\n        if self._proc.stdin:\n            self._proc.stdin.close()\n        if self._proc.stdout:\n            self._proc.stdout.close()\n        if self._proc.stderr:\n            self._proc.stderr.close()\n        self._proc = None\n    gc.collect()\n</code></pre>"},{"location":"api/server/#lean_interact.server.AutoLeanServer.get_memory_usage","title":"get_memory_usage","text":"<pre><code>get_memory_usage() -&gt; float\n</code></pre> <p>Get the memory usage of the Lean REPL server process in MB.</p> <p>Returns:</p> Type Description <code>float</code> <p>Memory usage in MB.</p> Source code in <code>src/lean_interact/server.py</code> <pre><code>def get_memory_usage(self) -&gt; float:\n    \"\"\"\n    Get the memory usage of the Lean REPL server process in MB.\n\n    Returns:\n        Memory usage in MB.\n    \"\"\"\n    if self._proc is None:\n        return 0.0\n    try:\n        proc = psutil.Process(self._proc.pid)\n        return get_total_memory_usage(proc) / (1024**2)  # Convert bytes to MB\n    except psutil.NoSuchProcess:\n        return 0.0\n</code></pre>"},{"location":"api/server/#notes-on-performance-features","title":"Notes on performance features","text":"<p>LeanInteract automatically augments <code>Command</code> and <code>FileCommand</code> requests to speed up elaboration and processing of files:</p> <ul> <li>Incremental elaboration is enabled by default</li> <li>Parallel elaboration is enabled via <code>set_option Elab.async true</code> by default when supported (Lean &gt;= v4.19.0)</li> </ul> <p>You can disable these behaviors in <code>LeanREPLConfig</code> by setting <code>enable_incremental_optimization=False</code> and/or <code>enable_parallel_elaboration=False</code>.</p>"},{"location":"api/sessioncache/","title":"Session Cache API","text":""},{"location":"api/sessioncache/#lean_interact.sessioncache","title":"Session Cache","text":"<p>Module: <code>lean_interact.sessioncache</code></p> <p>This module implements the session cache classes responsible for storing and retrieving Lean proof states and environments. Session cache is used internally by the <code>AutoLeanServer</code> class. It enables efficient resumption of proofs and environments after server restarts, timeouts, and automated recover from crashes. Additionally, <code>ReplaySessionCache</code> and <code>PickleSessionCache</code> are thread-safe and can be used to share session states between multiple <code>AutoLeanServer</code> instances within the same process. While by default <code>AutoLeanServer</code> instantiates a fresh <code>ReplaySessionCache</code> instance, you can also use a custom one. It can be useful to implement more advanced caching strategies, shareable cache across processes / compute nodes, ...</p> <p>Examples:</p> <pre><code>from lean_interact.sessioncache import PickleSessionCache, ReplaySessionCache\nfrom lean_interact.server import AutoLeanServer\n\n# Create a session cache\nreplay_cache = ReplaySessionCache()\npickle_cache = PickleSessionCache(working_dir=\"./cache\")\n\n# Create Lean servers with a given cache\nserver = AutoLeanServer(config=..., session_cache=replay_cache)\nlegacy = AutoLeanServer(config=..., session_cache=pickle_cache)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache","title":"ReplaySessionCache","text":"<pre><code>ReplaySessionCache(lazy: bool = True)\n</code></pre> <p>               Bases: <code>BaseSessionCache</code></p> <p>Automatically replays cached Lean commands to restore proof states and environments when needed.</p> <p>Parameters:</p> Name Type Description Default <code>lazy</code> <code>bool</code> <p>When <code>True</code> (default) cached states are re-materialized on demand the next time they are requested. When <code>False</code>, <code>reload()</code> eagerly replays every cached command for the target <code>LeanServer</code>, which can reduce latency after restarts at the cost of upfront work.</p> <code>True</code> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def __init__(self, lazy: bool = True):\n    super().__init__()\n    self._cache: dict[int, ReplaySessionState] = {}\n    self._state_counter = 0\n    self._lazy = lazy\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.add","title":"add","text":"<pre><code>add(\n    lean_server: LeanServer,\n    request: BaseREPLQuery,\n    response: BaseREPLResponse,\n    verbose: bool = False,\n) -&gt; int\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def add(\n    self,\n    lean_server: \"LeanServer\",\n    request: BaseREPLQuery,\n    response: BaseREPLResponse,\n    verbose: bool = False,\n) -&gt; int:\n    if isinstance(response, ProofStepResponse):\n        repl_id = response.proof_state\n        is_proof_state = True\n    elif isinstance(response, CommandResponse):\n        repl_id = response.env\n        is_proof_state = False\n    else:\n        raise NotImplementedError(\n            f\"Cannot store the session state for unsupported response of type {type(response).__name__}.\"\n        )\n\n    request_copy = request.model_copy(deep=True)\n    with self._lock:\n        self._state_counter -= 1\n        session_id = self._state_counter\n        self._cache[session_id] = ReplaySessionState(\n            session_id=session_id,\n            is_proof_state=is_proof_state,\n            request=request_copy,\n        )\n    self._set_state_repl_id(self._cache[session_id], lean_server, repl_id)\n    return session_id\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.remove","title":"remove","text":"<pre><code>remove(\n    session_state_id: int, verbose: bool = False\n) -&gt; None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def remove(self, session_state_id: int, verbose: bool = False) -&gt; None:\n    with self._lock:\n        self._cache.pop(session_state_id, None)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.reload","title":"reload","text":"<pre><code>reload(\n    lean_server: LeanServer,\n    timeout_per_state: int | float | None,\n    verbose: bool = False,\n) -&gt; None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def reload(\n    self,\n    lean_server: \"LeanServer\",\n    timeout_per_state: int | float | None,\n    verbose: bool = False,\n) -&gt; None:\n    with self._lock:\n        states = list(self._cache.values())\n    for state in states:\n        self._set_state_repl_id(state, lean_server, None)\n        if not self._lazy:\n            self._materialize_state(\n                lean_server,\n                state,\n                timeout=timeout_per_state,\n                verbose=verbose,\n            )\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.is_empty","title":"is_empty","text":"<pre><code>is_empty() -&gt; bool\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    with self._lock:\n        return len(self._cache) == 0\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.clear","title":"clear","text":"<pre><code>clear(verbose: bool = False) -&gt; None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def clear(self, verbose: bool = False) -&gt; None:\n    with self._lock:\n        self._cache.clear()\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.keys","title":"keys","text":"<pre><code>keys() -&gt; list[int]\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def keys(self) -&gt; list[int]:\n    with self._lock:\n        return list(self._cache.keys())\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionCache.get_repl_id","title":"get_repl_id","text":"<pre><code>get_repl_id(\n    session_state_id: int, lean_server: LeanServer\n) -&gt; int | None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def get_repl_id(self, session_state_id: int, lean_server: \"LeanServer\") -&gt; int | None:\n    state = self.__getitem__(session_state_id)\n    repl_id = self._get_state_repl_id(state, lean_server)\n    if repl_id is None:\n        self._materialize_state(lean_server, state)\n        repl_id = self._get_state_repl_id(state, lean_server)\n    return repl_id\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache","title":"PickleSessionCache","text":"<pre><code>PickleSessionCache(working_dir: str | PathLike)\n</code></pre> <p>               Bases: <code>BaseSessionCache</code></p> <p>A session cache based on the local file storage and the REPL pickle feature.</p> Warning <p>Pickled Lean states are not fully reliable yet and are not always reloaded correctly. Prefer <code>ReplaySessionCache</code> unless you explicitly need serialized states on disk.</p> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def __init__(self, working_dir: str | PathLike):\n    super().__init__()\n    self._cache: dict[int, PickleSessionState] = {}\n    self._state_counter = 0\n    self._working_dir = Path(working_dir)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.add","title":"add","text":"<pre><code>add(\n    lean_server: LeanServer,\n    request: BaseREPLQuery,\n    response: BaseREPLResponse,\n    verbose: bool = False,\n) -&gt; int\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def add(\n    self, lean_server: \"LeanServer\", request: BaseREPLQuery, response: BaseREPLResponse, verbose: bool = False\n) -&gt; int:\n    with self._lock:\n        self._state_counter -= 1\n        session_id = self._state_counter\n    process_id = os.getpid()  # use process id to avoid conflicts in multiprocessing\n    hash_key = f\"request_{type(request).__name__}_{id(request)}\"\n    pickle_file = (\n        self._working_dir / \"session_cache\" / f\"{hashlib.sha256(hash_key.encode()).hexdigest()}_{process_id}.olean\"\n    )\n    pickle_file.parent.mkdir(parents=True, exist_ok=True)\n    if isinstance(response, ProofStepResponse):\n        repl_id = response.proof_state\n        is_proof_state = True\n        request = PickleProofState(proof_state=response.proof_state, pickle_to=str(pickle_file))\n    elif isinstance(response, CommandResponse):\n        repl_id = response.env\n        is_proof_state = False\n        request = PickleEnvironment(env=response.env, pickle_to=str(pickle_file))\n    else:\n        raise NotImplementedError(\n            f\"Cannot pickle the session state for unsupported request of type {type(request).__name__}.\"\n        )\n\n    # Use file lock when accessing the pickle file to prevent cache invalidation\n    # from concurrent access\n    with FileLock(f\"{pickle_file}.lock\", timeout=60):\n        response_pickle = lean_server.run(request, verbose=verbose)\n        if isinstance(response_pickle, LeanError):\n            raise ValueError(\n                f\"Could not store the result in the session cache. The Lean server returned an error: {response_pickle.message}\"\n            )\n\n        with self._lock:\n            self._cache[session_id] = PickleSessionState(\n                session_id=session_id,\n                pickle_file=str(pickle_file),\n                is_proof_state=is_proof_state,\n            )\n        self._set_state_repl_id(self._cache[session_id], lean_server, repl_id)\n    return session_id\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.remove","title":"remove","text":"<pre><code>remove(\n    session_state_id: int, verbose: bool = False\n) -&gt; None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def remove(self, session_state_id: int, verbose: bool = False) -&gt; None:\n    with self._lock:\n        state_cache = self._cache.pop(session_state_id, None)\n    if state_cache is not None:\n        pickle_file = state_cache.pickle_file\n        with FileLock(f\"{pickle_file}.lock\", timeout=60):\n            if os.path.exists(pickle_file):\n                os.remove(pickle_file)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.reload","title":"reload","text":"<pre><code>reload(\n    lean_server: LeanServer,\n    timeout_per_state: int | float | None,\n    verbose: bool = False,\n) -&gt; None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def reload(self, lean_server: \"LeanServer\", timeout_per_state: int | float | None, verbose: bool = False) -&gt; None:\n    with self._lock:\n        state_snapshot = list(self._cache.values())\n    for state_data in state_snapshot:\n        # Use file lock when accessing the pickle file to prevent cache invalidation\n        # from multiple concurrent processes\n        with FileLock(\n            f\"{state_data.pickle_file}.lock\", timeout=float(timeout_per_state) if timeout_per_state else -1\n        ):\n            if state_data.is_proof_state:\n                cmd = UnpickleProofState(\n                    unpickle_proof_state_from=state_data.pickle_file,\n                    env=self._get_state_repl_id(state_data, lean_server),\n                )\n            else:\n                cmd = UnpickleEnvironment(unpickle_env_from=state_data.pickle_file)\n            result = lean_server.run(\n                cmd,\n                verbose=verbose,\n                timeout=timeout_per_state,\n            )\n            if isinstance(result, LeanError):\n                raise ValueError(\n                    f\"Could not reload the session cache. The Lean server returned an error: {result.message}\"\n                )\n            elif isinstance(result, CommandResponse):\n                self._set_state_repl_id(state_data, lean_server, result.env)\n            elif isinstance(result, ProofStepResponse):\n                self._set_state_repl_id(state_data, lean_server, result.proof_state)\n            else:\n                raise ValueError(\n                    f\"Could not reload the session cache. The Lean server returned an unexpected response: {result}\"\n                )\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.is_empty","title":"is_empty","text":"<pre><code>is_empty() -&gt; bool\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    with self._lock:\n        return len(self._cache) == 0\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.clear","title":"clear","text":"<pre><code>clear(verbose: bool = False) -&gt; None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def clear(self, verbose: bool = False) -&gt; None:\n    with self._lock:\n        state_snapshot = list(self._cache.values())\n    for state_data in state_snapshot:\n        self.remove(session_state_id=state_data.session_id, verbose=verbose)\n    with self._lock:\n        assert not self._cache, f\"Cache is not empty after clearing: {self._cache}\"\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.keys","title":"keys","text":"<pre><code>keys() -&gt; list[int]\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def keys(self) -&gt; list[int]:\n    with self._lock:\n        return list(self._cache.keys())\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionCache.get_repl_id","title":"get_repl_id","text":"<pre><code>get_repl_id(\n    session_state_id: int, lean_server: LeanServer\n) -&gt; int | None\n</code></pre> Source code in <code>src/lean_interact/sessioncache.py</code> <pre><code>def get_repl_id(self, session_state_id: int, lean_server: \"LeanServer\") -&gt; int | None:\n    state = self.__getitem__(session_state_id)\n    return self._get_state_repl_id(state, lean_server)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.SessionState","title":"SessionState  <code>dataclass</code>","text":"<pre><code>SessionState(\n    *,\n    session_id: int,\n    is_proof_state: bool,\n    repl_ids: dict[str, int | None] = dict(),\n)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.SessionState.session_id","title":"session_id  <code>instance-attribute</code>","text":"<pre><code>session_id: int\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.SessionState.is_proof_state","title":"is_proof_state  <code>instance-attribute</code>","text":"<pre><code>is_proof_state: bool\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.SessionState.repl_ids","title":"repl_ids  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repl_ids: dict[str, int | None] = field(\n    default_factory=dict\n)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionState","title":"ReplaySessionState  <code>dataclass</code>","text":"<pre><code>ReplaySessionState(\n    *,\n    session_id: int,\n    is_proof_state: bool,\n    repl_ids: dict[str, int | None] = dict(),\n    request: BaseREPLQuery,\n    _materializing_servers: set[str] = set(),\n)\n</code></pre> <p>               Bases: <code>SessionState</code></p>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionState.request","title":"request  <code>instance-attribute</code>","text":"<pre><code>request: BaseREPLQuery\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionState.session_id","title":"session_id  <code>instance-attribute</code>","text":"<pre><code>session_id: int\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionState.is_proof_state","title":"is_proof_state  <code>instance-attribute</code>","text":"<pre><code>is_proof_state: bool\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.ReplaySessionState.repl_ids","title":"repl_ids  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repl_ids: dict[str, int | None] = field(\n    default_factory=dict\n)\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionState","title":"PickleSessionState  <code>dataclass</code>","text":"<pre><code>PickleSessionState(\n    *,\n    session_id: int,\n    is_proof_state: bool,\n    repl_ids: dict[str, int | None] = dict(),\n    pickle_file: str,\n)\n</code></pre> <p>               Bases: <code>SessionState</code></p>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionState.pickle_file","title":"pickle_file  <code>instance-attribute</code>","text":"<pre><code>pickle_file: str\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionState.session_id","title":"session_id  <code>instance-attribute</code>","text":"<pre><code>session_id: int\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionState.is_proof_state","title":"is_proof_state  <code>instance-attribute</code>","text":"<pre><code>is_proof_state: bool\n</code></pre>"},{"location":"api/sessioncache/#lean_interact.sessioncache.PickleSessionState.repl_ids","title":"repl_ids  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repl_ids: dict[str, int | None] = field(\n    default_factory=dict\n)\n</code></pre>"},{"location":"api/utils/","title":"Utilities","text":"<p>This page documents the utility functions and classes used in LeanInteract.</p>"},{"location":"api/utils/#installation-and-cache-management","title":"Installation and Cache Management","text":""},{"location":"api/utils/#lean_interact.utils.install_lean","title":"install_lean","text":"<pre><code>install_lean()\n</code></pre> <p>Install Lean 4 version manager (elan) in a cross-platform compatible way. Uses platform-specific methods for Windows, macOS, and Linux.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def install_lean():\n    \"\"\"\n    Install Lean 4 version manager (elan) in a cross-platform compatible way.\n    Uses platform-specific methods for Windows, macOS, and Linux.\n    \"\"\"\n    try:\n        os_name = platform.system()\n        logger.info(\"Detected operating system: %s\", os_name)\n\n        if os_name == \"Windows\":\n            # Check long path support on Windows before installing Lean\n            check_windows_long_paths()\n\n            # Windows installation - use PowerShell with proper error handling\n            logger.info(\"Installing elan for Windows...\")\n\n            # Download the PowerShell script\n            dl_cmd = \"curl -O --location https://raw.githubusercontent.com/leanprover/elan/master/elan-init.ps1\"\n            subprocess.run(dl_cmd, shell=True, check=True)\n\n            ps_cmd = \"powershell -ExecutionPolicy Bypass -Command \\\"&amp; './elan-init.ps1' -NoPrompt $true -DefaultToolchain stable\\\"\"\n            subprocess.run(ps_cmd, shell=True, check=True)\n\n            cleanup_cmd = \"del elan-init.ps1\"\n            subprocess.run(cleanup_cmd, shell=True, check=True)\n\n            logger.info(\n                \"Elan has been installed. You may need to restart your terminal for the PATH changes to take effect.\"\n            )\n\n        else:  # Unix-like systems\n            if os_name in [\"Linux\", \"Darwin\"]:\n                command = \"curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh -s -- -y --default-toolchain stable\"\n            else:\n                raise RuntimeError(\n                    f\"Unsupported operating system: {os_name}. Please install elan manually: \"\n                    \"https://leanprover-community.github.io/get_started.html\"\n                )\n\n            subprocess.run(command, shell=True, check=True)\n\n            # Add to PATH in common shell config files\n            user_home = Path.home()\n            shell_configs = [\".bashrc\", \".zshrc\", \".bash_profile\", \".profile\"]\n            for config_name in shell_configs:\n                config_path = user_home / config_name\n                if config_path.exists():\n                    try:\n                        with open(config_path, \"a\", encoding=\"utf-8\") as file:\n                            file.write('\\nexport PATH=\"$HOME/.elan/bin:$PATH\"\\n')\n                        logger.info(\"Added elan to PATH in %s\", config_path)\n                    except Exception as e:\n                        logger.warning(\"Could not modify %s: %s\", config_path, e)\n\n            logger.info(\"Please restart your terminal or run 'source ~/.profile' to update your PATH\")\n\n        logger.info(\"Lean installation completed successfully.\")\n\n    except subprocess.CalledProcessError as e:\n        logger.warning(\n            \"An error occurred during Lean installation: %s\\n\"\n            \"Please check https://leanprover-community.github.io/get_started.html for more information.\",\n            e,\n        )\n        raise e\n    except Exception as e:\n        logger.warning(\n            \"Unexpected error during Lean installation: %s\\nPlease try installing manually: https://leanprover-community.github.io/get_started.html\",\n            e,\n        )\n        raise e\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache()\n</code></pre> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def clear_cache():\n    shutil.rmtree(DEFAULT_CACHE_DIR, ignore_errors=True)\n</code></pre>"},{"location":"api/utils/#project-utilities","title":"Project Utilities","text":""},{"location":"api/utils/#lean_interact.utils.get_project_lean_version","title":"get_project_lean_version","text":"<pre><code>get_project_lean_version(\n    project_dir: str | PathLike,\n) -&gt; str | None\n</code></pre> <p>Get the Lean version used in a project.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def get_project_lean_version(project_dir: str | PathLike) -&gt; str | None:\n    \"\"\"\n    Get the Lean version used in a project.\n    \"\"\"\n    project_dir = Path(project_dir)\n    toolchain_file = project_dir / \"lean-toolchain\"\n    if toolchain_file.is_file():\n        with open(toolchain_file, \"r\", encoding=\"utf-8\") as f:\n            content = f.read().strip()\n            try:\n                return parse_lean_version(content)\n            except ValueError:\n                return None\n    return None\n</code></pre>"},{"location":"api/utils/#windows-path-utilities","title":"Windows Path Utilities","text":""},{"location":"api/utils/#lean_interact.utils.check_windows_long_paths","title":"check_windows_long_paths","text":"<pre><code>check_windows_long_paths()\n</code></pre> <p>Check if long paths are enabled if running on Windows.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def check_windows_long_paths():\n    \"\"\"Check if long paths are enabled if running on Windows.\"\"\"\n    if platform.system() != \"Windows\":\n        return\n\n    # Try to check if long paths are enabled via registry key\n    try:\n        import winreg\n\n        key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, r\"SYSTEM\\CurrentControlSet\\Control\\FileSystem\")  # type: ignore\n        value, _ = winreg.QueryValueEx(key, \"LongPathsEnabled\")  # type: ignore\n        if value == 1:\n            logger.info(\"Windows long paths already enabled\")\n        else:\n            logger.info(\"For optimal use on Windows, enable long paths by running this command as administrator:\")\n            logger.info(\n                'New-ItemProperty -Path \"HKLM:\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\FileSystem\" -Name LongPathsEnabled -Value 1 -PropertyType DWord -Force'\n            )\n    except Exception as e:\n        logger.warning(f\"Could not check Windows long path setting: {e}\")\n\n    # Check if git core.longpaths is already configured\n    result = subprocess.run(\n        [\"git\", \"config\", \"--get\", \"core.longpaths\"],\n        check=False,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n    )\n\n    if result.returncode == 0 and result.stdout.strip() == \"true\":\n        logger.info(\"Git already configured for long paths\")\n    else:\n        logger.info(\"For optimal use on Windows, configure git for long paths by running:\")\n        logger.info(\"git config --global core.longpaths true\")\n</code></pre>"},{"location":"api/utils/#memory-management","title":"Memory Management","text":""},{"location":"api/utils/#lean_interact.utils.get_total_memory_usage","title":"get_total_memory_usage","text":"<pre><code>get_total_memory_usage(proc: Process)\n</code></pre> <p>Get total resident memory usage of a process and its children (in bytes).</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def get_total_memory_usage(proc: psutil.Process):\n    \"\"\"Get total resident memory usage of a process and its children (in bytes).\"\"\"\n    try:\n        return proc.memory_info().rss + sum(child.memory_info().rss for child in proc.children(recursive=True))\n    except psutil.NoSuchProcess:\n        return 0\n</code></pre>"},{"location":"api/utils/#code-processing-utilities","title":"Code Processing Utilities","text":""},{"location":"api/utils/#lean_interact.utils.indent_code","title":"indent_code","text":"<pre><code>indent_code(code: str, nb_spaces: int = 2) -&gt; str\n</code></pre> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def indent_code(code: str, nb_spaces: int = 2) -&gt; str:\n    return \"\\n\".join(\" \" * nb_spaces + line for line in code.split(\"\\n\"))\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.compress_newlines","title":"compress_newlines","text":"<pre><code>compress_newlines(lean_code: str)\n</code></pre> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def compress_newlines(lean_code: str):\n    # compress lines containing only whitespaces\n    lean_code = re.sub(r\"^\\s+$\", \"\", lean_code, flags=re.MULTILINE)\n    # Compress multiple consecutive newlines\n    lean_code = re.sub(r\"\\n\\n+\", \"\\n\\n\", lean_code)\n    lean_code = lean_code.lstrip()\n    if lean_code.endswith(\"\\n\"):\n        lean_code = lean_code.rstrip() + \"\\n\"\n    return lean_code\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.lean_comments_ranges","title":"lean_comments_ranges","text":"<pre><code>lean_comments_ranges(\n    lean_code: str,\n    multiline_comment_suffix: str = \"\",\n    remove_single_line_comments: bool = True,\n) -&gt; list[tuple[int, int]]\n</code></pre> <p>Extract the ranges of Lean comments from a Lean code snippet.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def lean_comments_ranges(\n    lean_code: str, multiline_comment_suffix: str = \"\", remove_single_line_comments: bool = True\n) -&gt; list[tuple[int, int]]:\n    \"\"\"Extract the ranges of Lean comments from a Lean code snippet.\"\"\"\n    # multiline comments\n    open_comment_indices = [m.start() for m in re.finditer(r\"/-\" + multiline_comment_suffix, lean_code)]\n    close_comment_indices = [\n        m.start() + len(multiline_comment_suffix) + 2 for m in re.finditer(multiline_comment_suffix + r\"-/\", lean_code)\n    ]\n\n    if len(open_comment_indices) == len(close_comment_indices) + 1:\n        # the last comment has probably not been closed due to partial code\n        close_comment_indices.append(len(lean_code))\n\n    elif len(open_comment_indices) + 1 == len(close_comment_indices):\n        # the first comment has probably been opened before the code snippet\n        open_comment_indices.insert(0, 0)\n\n    elif len(open_comment_indices) != len(close_comment_indices):\n        raise ValueError(\"Mismatched open and close comment indices.\")\n\n    # trick to handle nested comments in a simple way\n    multiline_comment_ranges = list(zip(open_comment_indices, close_comment_indices))\n\n    if remove_single_line_comments:\n        # single line comments\n        single_line_comment_ranges = [\n            (m.start(), lean_code.find(\"\\n\", m.start())) for m in re.finditer(r\"--\", lean_code)\n        ]\n        multiline_comment_ranges += single_line_comment_ranges\n\n    # merge potential overlapping ranges\n    comment_ranges = sorted(multiline_comment_ranges, key=lambda x: x[0])\n    merged_comment_ranges: list[tuple[int, int]] = []\n    for start, end in comment_ranges:\n        if merged_comment_ranges and start &lt;= merged_comment_ranges[-1][1]:\n            merged_comment_ranges[-1] = (merged_comment_ranges[-1][0], max(merged_comment_ranges[-1][1], end))\n        else:\n            merged_comment_ranges.append((start, end))\n\n    return merged_comment_ranges\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.remove_lean_comments","title":"remove_lean_comments","text":"<pre><code>remove_lean_comments(lean_code: str) -&gt; str | None\n</code></pre> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def remove_lean_comments(lean_code: str) -&gt; str | None:\n    try:\n        comment_ranges = lean_comments_ranges(lean_code)\n\n        new_lean_code = \"\"\n        prev_start = 0\n        for start, end in comment_ranges:\n            new_lean_code += lean_code[prev_start:start]\n            prev_start = end\n\n        new_lean_code += lean_code[prev_start:]\n        return new_lean_code\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.split_implementation","title":"split_implementation","text":"<pre><code>split_implementation(declaration: str, start: int = 0)\n</code></pre> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def split_implementation(declaration: str, start: int = 0):\n    # for a theorem, an implementation is the proof\n    if \":=\" in declaration:\n        # we have to be careful here as \":=\" can be used inside the declaration itself\n        indices = set([m.start() for m in re.finditer(r\":=\", declaration)])\n\n        # we remove the ones related to \"let\", \"haveI\", ... declarations\n        for keyword in [\"let\", \"haveI\"]:\n            regex = rf\"{keyword}\\s+\\S*?\\s*(:=)\"\n            decl_indices = set([m.start(1) for m in re.finditer(regex, declaration)])\n            indices = indices - decl_indices\n\n        # implementation using pcre2 blows up the memory, and it turns out it is faster to use a python loop\n        counters = {\"(\": 0, \"{\": 0, \"[\": 0}\n        closing = {\")\": \"(\", \"}\": \"{\", \"]\": \"[\"}\n        for i, c in enumerate(declaration[start:]):\n            if c in counters:\n                counters[c] += 1\n            elif c in [\")\", \"}\", \"]\"]:\n                counters[closing[c]] -= 1\n            if all([v == 0 for v in counters.values()]) and (i + start) in indices:\n                return i + start\n    return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.split_conclusion","title":"split_conclusion","text":"<pre><code>split_conclusion(\n    declaration: str, start: int = 0\n) -&gt; int | None\n</code></pre> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def split_conclusion(declaration: str, start: int = 0) -&gt; int | None:\n    counters = {\"(\": 0, \"{\": 0, \"[\": 0}\n    closing = {\")\": \"(\", \"}\": \"{\", \"]\": \"[\"}\n    for i, c in enumerate(declaration[start:]):\n        if c in counters:\n            counters[c] += 1\n        elif c in [\")\", \"}\", \"]\"]:\n            counters[closing[c]] -= 1\n        if all([v == 0 for v in counters.values()]) and c == \":\":\n            return i + start\n    return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.clean_theorem_string","title":"clean_theorem_string","text":"<pre><code>clean_theorem_string(\n    theorem_string: str,\n    new_theorem_name: str = \"dummy\",\n    add_sorry: bool = True,\n) -&gt; str | None\n</code></pre> <p>Clean a theorem string by removing the proof, comments, and updating the theorem name. This method assumes that no other declarations are present in the theorem string.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def clean_theorem_string(theorem_string: str, new_theorem_name: str = \"dummy\", add_sorry: bool = True) -&gt; str | None:\n    \"\"\"Clean a theorem string by removing the proof, comments, and updating the theorem name.\n    This method assumes that no other declarations are present in the theorem string.\"\"\"\n    try:\n        # clean the theorem string\n        clean_formal = remove_lean_comments(theorem_string)\n        if clean_formal is None:\n            raise ValueError(\"Comment removal failed.\")\n        clean_formal = clean_formal.strip()\n\n        # we remove the first part of the string until the first \"theorem\" or \"lemma\" keyword\n        theorem_decl_keywords = \"|\".join([\"theorem\", \"lemma\", \"example\"])\n        re_match = re.search(rf\"\\b{theorem_decl_keywords}\\s\", clean_formal)\n        if re_match is None:\n            raise ValueError(\"Theorem declaration keyword not found.\")\n        idx_theorem = re_match.start()\n        clean_formal = clean_formal[idx_theorem:]\n\n        # if a proof is provided we remove it\n        idx_implement = split_implementation(clean_formal)\n        if idx_implement is not None:\n            clean_formal = clean_formal[:idx_implement].strip()\n\n        # remove \"theorem\" and the theorem name\n        if clean_formal.strip().startswith(\"example\"):\n            clean_formal = re.sub(r\"^[^\\s]+\", \"\", clean_formal).strip()\n        else:\n            clean_formal = re.sub(r\"^[^\\s]+\", \"\", clean_formal).strip()\n            clean_formal = re.sub(r\"^[^\\s:({\\[]+\", \"\", clean_formal).strip()\n        clean_formal = f\"theorem {new_theorem_name} \" + clean_formal\n        if add_sorry:\n            clean_formal += \" := by sorry\"\n        return clean_formal\n    except Exception:\n        return None\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.extract_last_theorem","title":"extract_last_theorem","text":"<pre><code>extract_last_theorem(lean_code: str) -&gt; int\n</code></pre> <p>Extract the last theorem from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def extract_last_theorem(lean_code: str) -&gt; int:\n    \"\"\"Extract the last theorem from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.\"\"\"\n    comments_ranges = lean_comments_ranges(lean_code)\n\n    # find last theorem by looking for `theorem` keyword surrounded by whitespaces, or by being at the beginning of the string\n    theorem_decl_keywords = [\"theorem\", \"lemma\", \"example\"]\n    theorem_indices = []\n    for keyword in theorem_decl_keywords:\n        theorem_indices += [m.start() for m in re.finditer(rf\"\\b{keyword}\\s\", lean_code)]\n\n    # remove matches that are inside comments\n    theorem_indices = [idx for idx in theorem_indices if not any(start &lt;= idx &lt;= end for start, end in comments_ranges)]\n\n    if not theorem_indices:\n        raise ValueError(f\"No theorem found in the provided Lean code:\\n{lean_code}\")\n\n    return theorem_indices[-1]\n</code></pre>"},{"location":"api/utils/#lean_interact.utils.clean_last_theorem_string","title":"clean_last_theorem_string","text":"<pre><code>clean_last_theorem_string(\n    lean_code: str,\n    new_theorem_name: str = \"dummy\",\n    add_sorry: bool = False,\n) -&gt; str\n</code></pre> <p>Clean the last theorem string from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.</p> Source code in <code>src/lean_interact/utils.py</code> <pre><code>def clean_last_theorem_string(lean_code: str, new_theorem_name: str = \"dummy\", add_sorry: bool = False) -&gt; str:\n    \"\"\"Clean the last theorem string from a Lean code snippet. It assumes that the Lean code snippet ends with a theorem.\"\"\"\n    idx_last_theorem = extract_last_theorem(lean_code)\n    clean_thm = clean_theorem_string(lean_code[idx_last_theorem:], new_theorem_name, add_sorry=add_sorry)\n    if clean_thm is not None:\n        return lean_code[:idx_last_theorem] + clean_thm\n\n    raise ValueError(f\"Theorem extraction failed for the following Lean code:\\n{lean_code}\")\n</code></pre>"},{"location":"user-guide/basic-usage/","title":"Basic Usage","text":"<p>This guide covers the fundamental operations and command types in LeanInteract.</p>"},{"location":"user-guide/basic-usage/#basic-command-execution","title":"Basic Command Execution","text":"<p>The most common operation in LeanInteract is executing Lean code directly using the <code>Command</code> class:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Setup\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Run a simple theorem\nprint(server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\")))\n</code></pre> <pre><code>CommandResponse(env=0)\n</code></pre> <p>The response contains:</p> <ul> <li>Messages returned by Lean if any (errors, information, etc.)</li> <li>An environment state (<code>env</code>) that can be used for subsequent commands.</li> </ul>"},{"location":"user-guide/basic-usage/#working-with-environment-states","title":"Working with Environment States","text":"<p>Each command execution creates a new environment state. You can use this state in subsequent commands:</p> <pre><code># First command creates environment state\nresponse1 = server.run(Command(cmd=\"def x := 5\"))\n\n# Use environment state 0 for the next command\nprint(server.run(Command(cmd=\"#check x\", env=response1.env)))\n</code></pre> <pre><code>CommandResponse(env=2, messages=[Message(start_pos=Pos(column=0, line=1), data='x : Nat', end_pos=Pos(column=6, line=1), severity='info')])\n</code></pre>"},{"location":"user-guide/basic-usage/#processing-lean-files","title":"Processing Lean Files","text":"<p>You can process entire Lean files using the <code>FileCommand</code> class:</p> <pre><code>from lean_interact import FileCommand\n\n# Process a Lean file\nresponse = server.run(FileCommand(path=\"myfile.lean\"))\n\n# With options to get more information about goals\nresponse = server.run(FileCommand(path=\"myfile.lean\", root_goals=True))\n</code></pre>"},{"location":"user-guide/basic-usage/#available-options","title":"Available Options","text":"<p>Both <code>Command</code> and <code>FileCommand</code> support several options:</p> <ul> <li><code>all_tactics</code>: Get information about tactics used</li> <li><code>declarations</code>: Extract fine-grained information about declarations in the code</li> <li><code>root_goals</code>: Get information about goals in theorems and definitions</li> <li><code>infotree</code>: Get Lean infotree containing various informations from the Lean syntax tree</li> <li><code>incrementality</code>: Enable or disable incremental elaboration for this specific command.</li> <li><code>set_options</code>: Set Lean options for this command (see Set Options)</li> <li><code>env</code>: The environment from a previous command to be used as context. If <code>env = None</code>, starts from scratch.</li> </ul> <p>Example with options:</p> <pre><code>response = server.run(Command(\n    cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := by simp\",\n    all_tactics=True\n))\nprint(response.tactics)  # Shows tactics used\n</code></pre> <pre><code>[Tactic(start_pos=Pos(column=43, line=1), used_constants=['instOfNatNat', 'imp_self._simp_1', 'Nat', 'of_eq_true', 'OfNat.ofNat', 'Eq'], tactic='simp', proof_state=0, goals='n : Nat\\n\u22a2 n = 5 \u2192 n = 5', end_pos=Pos(column=47, line=1))]\n</code></pre>"},{"location":"user-guide/basic-usage/#working-with-sorries","title":"Working with Sorries","text":"<p>When Lean code contains <code>sorry</code> (incomplete proofs), LeanInteract returns information about these <code>sorry</code>:</p> <pre><code>response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nprint(response.sorries[0])\n</code></pre> <pre><code>Sorry(proof_state=1, start_pos=Pos(column=40, line=1), end_pos=Pos(column=45, line=1), goal='n : Nat\\n\u22a2 n = 5 \u2192 n = 5')\n</code></pre> <p>This response will include a list of <code>Sorry</code> objects, each containing:</p> <ul> <li>Position in the code</li> <li>Goal to be proven</li> <li>Proof state ID (can be used with <code>ProofStep</code> commands)</li> </ul>"},{"location":"user-guide/basic-usage/#error-handling","title":"Error Handling","text":"<pre><code>from lean_interact.interface import LeanError\n\ntry:\n    response = server.run(Command(cmd=\"invalid Lean code\"))\n    if isinstance(response, LeanError):\n        print(\"Command failed with fatal error(s):\", response.message)\n    else:\n        print(\"Command succeeded:\", response) # but the content may contain errors !!\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n</code></pre> <pre><code>Command succeeded: CommandResponse(env=5, messages=[Message(start_pos=Pos(column=0, line=1), data='unexpected identifier; expected command', end_pos=Pos(column=7, line=1), severity='error')])\n</code></pre>"},{"location":"user-guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about tactic mode for step-by-step proof interaction</li> <li>Configure custom Lean environments</li> <li>Explore the API Reference for more command options</li> </ul>"},{"location":"user-guide/custom-lean-configuration/","title":"Custom Lean Configuration","text":"<p>LeanInteract provides flexible ways to configure the Lean environment to suit different use cases. This guide covers the various configuration options available.</p>"},{"location":"user-guide/custom-lean-configuration/#specifying-lean-versions","title":"Specifying Lean Versions","text":"<p>You can specify which version of Lean 4 you want to use when no project is specified:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer\n\n# Use a specific Lean version\nconfig = LeanREPLConfig(lean_version=\"v4.8.0\")\nserver = LeanServer(config)\n</code></pre>"},{"location":"user-guide/custom-lean-configuration/#working-with-existing-projects","title":"Working with Existing Projects","text":"<p>Note</p> <p>When using a project through the <code>project</code> attribute, the Lean version is automatically inferred from the project. You cannot specify both <code>lean_version</code> and <code>project</code> parameters.</p>"},{"location":"user-guide/custom-lean-configuration/#local-lean-projects","title":"Local Lean Projects","text":"<p>To work with a local Lean project, create a <code>LocalProject</code> instance:</p> <pre><code>from lean_interact import LeanREPLConfig, LocalProject, LeanServer\n\n# Configure with a local project\nproject = LocalProject(\n    directory=\"path/to/your/project\",\n    auto_build=True  # Automatically build the project (default is True)\n)\nconfig = LeanREPLConfig(project=project)\nserver = LeanServer(config)\n</code></pre> <p>Important</p> <p>Ensure the project can be successfully built with <code>lake build</code> before using it with LeanInteract.</p> <p>Tip</p> <p>Setting <code>auto_build=False</code> will skip building the project, which can be useful if you've already built it.</p>"},{"location":"user-guide/custom-lean-configuration/#git-based-projects","title":"Git-Based Projects","text":"<p>You can work with projects hosted on Git repositories:</p> <pre><code>from lean_interact import LeanREPLConfig, GitProject, LeanServer\n\n# Configure with a Git-hosted project\nproject = GitProject(\n    url=\"https://github.com/yangky11/lean4-example\",\n    rev=\"main\",  # Optional: specific branch, tag, or commit\n    directory=\"/custom/cache/path\",  # Optional: custom directory where the project will be cloned\n    force_pull=False  # Optional: force update from remote. Useful in case you already have the project cloned and the branch has been updated.\n)\nconfig = LeanREPLConfig(project=project)\nserver = LeanServer(config)\n</code></pre> <p>The <code>GitProject</code> will automatically:</p> <ul> <li>Clone the repository if it doesn't exist (including submodules if present)</li> <li>Update to the specified revision</li> <li>Build the project with <code>lake build</code></li> </ul> <p>Tip</p> <p>Use the <code>directory</code> parameter to control where projects are cached</p>"},{"location":"user-guide/custom-lean-configuration/#working-with-temporary-projects","title":"Working with Temporary Projects","text":"<p>LeanInteract allows you to create temporary projects with dependencies for quick experimentation and automated reproducible setups.</p>"},{"location":"user-guide/custom-lean-configuration/#simple-temporary-projects-with-dependencies","title":"Simple Temporary Projects with Dependencies","text":"<p>To create a temporary project with dependencies:</p> <pre><code>from lean_interact import LeanREPLConfig, TempRequireProject, LeanRequire\n\n# Create a temporary project with Mathlib as a dependency\nproject = TempRequireProject(\n    lean_version=\"v4.8.0\",\n    require=[\n        LeanRequire(\n            name=\"mathlib\",\n            git=\"https://github.com/leanprover-community/mathlib4.git\",\n            rev=\"v4.8.0\"\n        )\n    ]\n)\nconfig = LeanREPLConfig(project=project)\n</code></pre> <p>For the common case of requiring Mathlib, there's a shortcut:</p> <pre><code>project = TempRequireProject(lean_version=\"v4.8.0\", require=\"mathlib\")\nconfig = LeanREPLConfig(project=project)\n</code></pre>"},{"location":"user-guide/custom-lean-configuration/#fine-grained-temporary-projects","title":"Fine-Grained Temporary Projects","text":"<p>For more control over the temporary project, you can specify the complete lakefile content:</p> <pre><code>from lean_interact import LeanREPLConfig, TemporaryProject\n\nproject = TemporaryProject(\n    lean_version=\"v4.18.0\",\n    content=\"\"\"\nimport Lake\nopen Lake DSL\n\npackage \"dummy\" where\n  version := v!\"0.1.0\"\n\n@[default_target]\nlean_exe \"dummy\" where\n  root := `Main\n\nrequire mathlib from git\n  \"https://github.com/leanprover-community/mathlib4.git\" @ \"v4.18.0\"\n\"\"\",\n    lakefile_type=\"lean\"  # or \"toml\"\n)\nconfig = LeanREPLConfig(project=project)\n</code></pre> <p>This approach gives you full control over the Lake configuration. Alternatively, you can define the lakefile content using the TOML format by setting <code>lakefile_type=\"toml\"</code>.</p>"},{"location":"user-guide/custom-lean-configuration/#using-custom-repl-revisions","title":"Using Custom REPL Revisions","text":"<p>LeanInteract uses the Lean REPL from a git repository to interact with Lean. By default, it uses a specific version of the REPL from the default forked repository (<code>https://github.com/augustepoiroux/repl</code>) which manages compatibility with Lean versions. However, you can customize this by specifying a different REPL revision or repository:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer\n\n# Use a specific REPL revision\nconfig = LeanREPLConfig(\n    repl_rev=\"v4.21.0-rc3\",\n    repl_git=\"https://github.com/leanprover-community/repl\"\n)\nserver = LeanServer(config)\n</code></pre> <p>When you specify a <code>repl_rev</code>, LeanInteract will try to:</p> <ol> <li>Find a tagged revision with the format <code>{repl_rev}_lean-toolchain-{lean_version}</code></li> <li>If such tag doesn't exist, fall back to using the specified <code>repl_rev</code> directly</li> <li>If <code>lean_version</code> is not specified, it will use the latest available Lean version compatible with the REPL</li> </ol> <p>This approach allows for better matching between REPL versions and Lean versions, ensuring compatibility.</p> <p>Warning</p> <p>Custom/older REPL implementations may have interfaces that are incompatible with LeanInteract's current commands. If you encounter issues, consider using the <code>run_dict</code> method from <code>LeanServer</code> to communicate directly with the REPL:</p> <pre><code>result = server.run_dict({\"cmd\": \"your_command_here\"})\n</code></pre> <p>Note</p> <p>The <code>repl_rev</code> and <code>repl_git</code> parameters are ignored if you specify <code>local_repl_path</code>.</p>"},{"location":"user-guide/custom-lean-configuration/#using-a-local-repl-installation","title":"Using a Local REPL Installation","text":"<p>If you are developing the Lean REPL or have a custom version, you can use your local copy instead of downloading from a git repository:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer\n\nconfig = LeanREPLConfig(local_repl_path=\"path/to/your/local/repl\", build_repl=True)\nserver = LeanServer(config)\n</code></pre> <p>Note</p> <p>When using <code>local_repl_path</code>, any specified <code>repl_rev</code>, and <code>repl_git</code> parameters are ignored as the local REPL is used directly.</p> <p>Note</p> <p>Make sure you are using a compatible Lean version between your local REPL and the project you will interact with.</p>"},{"location":"user-guide/data-extraction/","title":"Data Extraction: Declarations, Tactics, and InfoTrees","text":"<p>LeanInteract makes it easy to extract rich data from elaboration, including declarations, tactics, and detailed InfoTrees.</p>"},{"location":"user-guide/data-extraction/#declarations","title":"Declarations","text":"<p>Set <code>declarations=True</code> to retrieve a list of <code>DeclarationInfo</code> for each declaration introduced in your Lean code. Full details about the fields in <code>DeclarationInfo</code> can be found in the API reference.</p> <pre><code>from lean_interact import LeanServer, LeanREPLConfig, Command\nfrom lean_interact.interface import CommandResponse\n\ncode = \"\"\"\ntheorem ex (n : Nat) : n = 5 \u2192 n = 5 := by\n  intro h; exact h\n\"\"\"\n\nserver = LeanServer(LeanREPLConfig())\nres = server.run(Command(cmd=code, declarations=True))\nassert isinstance(res, CommandResponse)\nfor d in res.declarations:\n    print(f\"Full name: `{d.full_name}`\")\n    print(f\"Kind: `{d.kind}`\")\n    print(f\"Signature: `{d.signature}`\")\n    print(f\"Value: `{d.value}`\")\n    print(f\"Binders: `{d.binders}`\")\n</code></pre> <pre><code>Full name: `ex`\nKind: `theorem`\nSignature: `DeclSignature(constants=['n', 'Nat'], range=Range(start=Pos(column=11, line=2), finish=Pos(column=36, line=2), synthetic=False), pp='(n : Nat) : n = 5 \u2192 n = 5')`\nValue: `DeclValue(constants=['h'], range=Range(start=Pos(column=37, line=2), finish=Pos(column=18, line=3), synthetic=False), pp=':= by\\n  intro h; exact h')`\nBinders: `DeclBinders(map=[BinderView(id='n', type='Nat', binderInfo='default')], groups=['(n : Nat)'], range=Range(start=Pos(column=11, line=2), finish=Pos(column=20, line=2), synthetic=False), pp='(n : Nat)')`\n</code></pre> <p>For files:</p> <pre><code>from lean_interact import FileCommand\nres = server.run(FileCommand(path=\"myfile.lean\", declarations=True))\n</code></pre> <p>Tip: See <code>examples/extract_mathlib_decls.py</code> for a scalable, per-file parallel extractor over Mathlib.</p>"},{"location":"user-guide/data-extraction/#tactics","title":"Tactics","text":"<p>Use <code>all_tactics=True</code> to collect tactic applications with their goals and used constants.</p> <pre><code>resp = server.run(Command(cmd=code, all_tactics=True))\nfor t in resp.tactics:\n    print(t.tactic, \"::: used:\", t.used_constants)\n</code></pre> <pre><code>intro h ::: used: ['instOfNatNat', 'Nat', 'OfNat.ofNat', 'Eq']\nexact h ::: used: []\n</code></pre>"},{"location":"user-guide/data-extraction/#infotrees","title":"InfoTrees","text":"<p>Request <code>infotree</code> to obtain structured elaboration information. Accepted values include <code>\"full\"</code>, <code>\"tactics\"</code>, <code>\"original\"</code>, and <code>\"substantive\"</code>. See InfoTreeOptions for details.</p> <pre><code>from lean_interact.interface import InfoTree, InfoTreeOptions\n\nres = server.run(Command(cmd=code, infotree=InfoTreeOptions.full))\ntrees: list[InfoTree] = res.infotree or []\n\n# Example: iterate over all command-level nodes and print their kind\nfor tree in trees:\n    for cmd_node in tree.commands():\n        print(cmd_node.kind, cmd_node.node.stx)\n</code></pre> <pre><code>CommandInfo Syntax(arg_kinds=['Lean.Parser.Command.declModifiers', 'Lean.Parser.Command.theorem'], range=Range(start=Pos(column=0, line=2), finish=Pos(column=18, line=3), synthetic=False), pp='theorem ex (n : Nat) : n = 5 \u2192 n = 5 := by intro h; exact h', kind='Lean.Parser.Command.declaration')\nCommandInfo Syntax(arg_kinds=['\u00ab\u00bb'], range=Range(start=Pos(column=0, line=4), finish=Pos(column=0, line=4), synthetic=False), pp='', kind='Lean.Parser.Command.eoi')\n</code></pre>"},{"location":"user-guide/data-extraction/#root-goals-and-messages","title":"Root goals and messages","text":"<p>You can also ask for <code>root_goals=True</code> to retrieve initial goals for declarations (even if already proved).</p> <pre><code>print(server.run(Command(cmd=code, root_goals=True)))\n</code></pre> <pre><code>CommandResponse(env=3, sorries=[Sorry(proof_state=2, start_pos=Pos(column=40, line=2), end_pos=Pos(column=40, line=2), goal='n : Nat\\n\u22a2 n = 5 \u2192 n = 5')])\n</code></pre>"},{"location":"user-guide/examples/","title":"Examples","text":"<p>This page provides practical examples of using LeanInteract in different scenarios. You can find a few full example scripts in the <code>examples</code> directory of the repository.</p>"},{"location":"user-guide/examples/#basic-theorem-proving","title":"Basic Theorem Proving","text":"<p>This example demonstrates how to define a simple theorem with a partial proof in Lean using LeanInteract:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Initialize configuration and server\nconfig = LeanREPLConfig()\nserver = LeanServer(config)\n\n# Define a simple theorem\nprint(server.run(Command(cmd=\"\"\"\ntheorem add_comm (a b : Nat) : a + b = b + a := by\n  induction a with\n  | zero =&gt; simp\n  | succ a ih =&gt; sorry\n\"\"\")))\n</code></pre> <pre><code>CommandResponse(env=0, sorries=[Sorry(proof_state=0, start_pos=Pos(column=17, line=5), end_pos=Pos(column=22, line=5), goal='case succ\\nb a : Nat\\nih : a + b = b + a\\n\u22a2 a + 1 + b = b + (a + 1)')], messages=[Message(start_pos=Pos(column=8, line=2), data=\"declaration uses 'sorry'\", end_pos=Pos(column=16, line=2), severity='warning')])\n</code></pre>"},{"location":"user-guide/examples/#working-with-mathlib","title":"Working with Mathlib","text":"<p>This example shows how to use Mathlib to work with more advanced mathematical concepts:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command, TempRequireProject\n\n# Create configuration with Mathlib\nconfig = LeanREPLConfig(project=TempRequireProject(lean_version=\"v4.19.0\", require=\"mathlib\"))\nserver = LeanServer(config)\n\n# Define a theorem using Mathlib's real numbers\nprint(server.run(Command(cmd=\"\"\"\nimport Mathlib\n\ntheorem irrational_plus_rational \n  (x : \u211d) (y : \u211a) : Irrational x \u2192 Irrational (x + y) := by\n  intro h\n  simp\n  assumption\n\"\"\")))\n</code></pre> <pre><code>CommandResponse(env=0, messages=[Message(start_pos=Pos(column=0, line=4), data='Goals accomplished!', end_pos=Pos(column=12, line=8), severity='info')])\n</code></pre>"},{"location":"user-guide/examples/#using-custom-repl-versions","title":"Using Custom REPL Versions","text":"<p>This example demonstrates how to use a specific REPL version from a custom repository:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Use a specific REPL version from the official Lean repository\nconfig = LeanREPLConfig(\n    repl_rev=\"v4.21.0-rc3\", \n    repl_git=\"https://github.com/leanprover-community/repl\"\n)\nserver = LeanServer(config)\n\n# Check the Lean version\nresponse = server.run(Command(cmd=\"#eval Lean.versionString\"))\nprint(response.messages[0].data)  # Output: \"4.21.0-rc3\"\n\n# If you encounter interface compatibility issues with custom REPLs,\n# you can use run_dict to communicate directly with the REPL:\nresult = server.run_dict({\"cmd\": \"#eval Lean.versionString\"})\nprint(result)  # Example raw output from the REPL\n</code></pre> <pre><code>\"4.21.0-rc3\"\n{'messages': [{'severity': 'info', 'pos': {'line': 1, 'column': 0}, 'endPos': {'line': 1, 'column': 5}, 'data': '\"4.21.0-rc3\"'}], 'env': 1}\n</code></pre>"},{"location":"user-guide/examples/#real-world-examples","title":"Real-World Examples","text":"<p>For more comprehensive examples, check out the following scripts in the examples directory:</p> <ol> <li> <p>parallelization.py    Shows how to parallelize calls to LeanInteract for faster processing.</p> </li> <li> <p>proof_generation_and_autoformalization.py    Shows how to use models like DeepSeek-Prover-V1.5 and Goedel-Prover on MiniF2F and ProofNet# benchmarks.</p> </li> <li> <p>beq_plus.py    Demonstrates how to run the autoformalization BEq+ metric on the ProofNetVerif benchmark.</p> </li> <li> <p>type_check.py    Shows how to optimize type checking using environment states.</p> </li> </ol>"},{"location":"user-guide/getting-started/","title":"Getting Started with LeanInteract","text":""},{"location":"user-guide/getting-started/#overview","title":"Overview","text":"<p>LeanInteract provides a Python interface to the Lean 4 theorem prover via the Lean REPL (Read-Evaluate-Print Loop). It enables you to:</p> <ul> <li>Execute Lean code from Python</li> <li>Process Lean files</li> <li>Interact with proofs step by step</li> </ul>"},{"location":"user-guide/getting-started/#quick-example","title":"Quick Example","text":"<pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Create a Lean REPL configuration\nconfig = LeanREPLConfig(verbose=True)\n\n# Start a Lean server with the configuration\nserver = LeanServer(config)\n\n# Execute a simple theorem\nresponse = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\n\n# Print the response\nprint(response)\n</code></pre> <pre><code>CommandResponse(env=0)\n</code></pre> <p>This will:</p> <ol> <li>Initialize a Lean REPL configuration: downloads and initializes the Lean environment</li> <li>Start a Lean server</li> <li>Execute a simple Lean theorem</li> <li>Return a response containing the Lean environment state and any messages</li> </ol>"},{"location":"user-guide/getting-started/#core-components","title":"Core Components","text":""},{"location":"user-guide/getting-started/#leanreplconfig","title":"LeanREPLConfig","text":"<p><code>LeanREPLConfig</code> sets up the Lean environment:</p> <pre><code>config = LeanREPLConfig(\n    lean_version=\"v4.19.0\",  # Specify Lean version (optional, default is latest)\n    verbose=True,            # Print detailed logs\n)\n</code></pre>"},{"location":"user-guide/getting-started/#leanserver","title":"LeanServer","text":"<p><code>LeanServer</code> manages communication with the Lean REPL:</p> <pre><code>server = LeanServer(config)\n</code></pre> <p>A more robust alternative is <code>AutoLeanServer</code>, which automatically recovers from (some) crashes:</p> <pre><code>from lean_interact import AutoLeanServer\nauto_server = AutoLeanServer(config)\n</code></pre>"},{"location":"user-guide/getting-started/#commands","title":"Commands","text":"<p>LeanInteract provides several types of commands:</p> <ul> <li><code>Command</code>: Execute Lean code directly</li> <li><code>FileCommand</code>: Process Lean files</li> <li><code>ProofStep</code>: Work with proofs step by step using tactics</li> </ul> <p>Basic command execution:</p> <pre><code>server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := id\"))\n</code></pre>"},{"location":"user-guide/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about basic usage patterns</li> <li>Explore tactic mode for step-by-step proof interaction</li> <li>Configure custom Lean environments</li> </ul> <p>Or check out the API Reference for detailed information on all available classes and methods.</p>"},{"location":"user-guide/installation/","title":"Installation","text":""},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing LeanInteract, ensure you have the following prerequisites:</p> <ul> <li>Python 3.10 or newer</li> <li>Git (for Lean installation)</li> <li>Lean 4 (optional - LeanInteract can install it for you)</li> </ul> <p>We recommend using Linux or macOS for the best experience, but LeanInteract also supports Windows.</p>"},{"location":"user-guide/installation/#installation-steps","title":"Installation Steps","text":""},{"location":"user-guide/installation/#1-install-the-package","title":"1. Install the Package","text":"<p>You can install LeanInteract directly from PyPI:</p> <pre><code>pip install lean-interact\n</code></pre>"},{"location":"user-guide/installation/#2-install-lean-4-if-not-already-installed","title":"2. Install Lean 4 (if not already installed)","text":"<p>LeanInteract provides a convenient command to install Lean 4 along with its official Elan version manager:</p> <pre><code>install-lean\n</code></pre> <p>This command will install Elan, which manages Lean versions.</p> <p>Elan Version</p> <p>Your Elan version should be at least 4.0.0.</p>"},{"location":"user-guide/installation/#verifying-installation","title":"Verifying Installation","text":"<p>You can verify that LeanInteract is properly installed by running a simple Python script:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\n# Create a configuration\nconfig = LeanREPLConfig(verbose=True)\n\n# Initialize the server\nserver = LeanServer(config)\n\n# Execute a simple Lean command\nresponse = server.run(Command(cmd=\"#eval 2 + 2\"))\nprint(response)\n</code></pre> <pre><code>CommandResponse(env=0, messages=[Message(start_pos=Pos(column=0, line=1), data='4', end_pos=Pos(column=5, line=1), severity='info')])\n</code></pre> <p>If everything is set up correctly, the script should output a successful response.</p> <p>Note</p> <p>The first time you run LeanInteract, it might take some time as it downloads the requested Lean version and builds Lean REPL. Subsequent runs will be significantly faster due to caching.</p>"},{"location":"user-guide/installation/#system-specific-notes","title":"System-Specific Notes","text":""},{"location":"user-guide/installation/#windows","title":"Windows","text":"<p>On Windows, you might encounter path length limitations. If you get an error related to path length, you can enable long paths in Windows 10 and later versions by running the following command in an administrator PowerShell:</p> <pre><code>New-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" -Name LongPathsEnabled -Value 1 -PropertyType DWord -Force\ngit config --system core.longpaths true\n</code></pre> <p>For more information, refer to the Microsoft documentation.</p>"},{"location":"user-guide/installation/#docker","title":"Docker","text":"<p>If you're using LeanInteract in a Docker container, make sure to include Git in your container and have sufficient memory allocated, especially if you're working with Mathlib.</p>"},{"location":"user-guide/installation/#uninstallation","title":"Uninstallation","text":"<p>If you need to clear the LeanInteract cache (for troubleshooting or disk space reasons), you can use:</p> <pre><code>clear-lean-cache\n</code></pre> <p>To completely uninstall:</p> <pre><code>pip uninstall lean-interact\n</code></pre>"},{"location":"user-guide/performance/","title":"Performance &amp; Parallelization","text":"<p>LeanInteract provides three complementary performance layers that can be combined:</p> <ol> <li>Within-command speedups (inside a single Lean request)<ul> <li>Incremental elaboration: reuse previous elaboration results instead of starting from scratch.</li> <li>Parallel elaboration: use <code>Elab.async</code> so Lean elaborates independent parts in parallel.</li> </ul> </li> <li>Across-command speedups (multiple commands / tasks)<ul> <li>External parallelization: run several Lean servers in parallel, typically via <code>AutoLeanServer</code>.</li> </ul> </li> </ol> <p>All three can be enabled together for maximum throughput: fast single commands (incremental + parallel elaboration) and high aggregate throughput across many commands (external parallelization). By default, incremental elaboration and parallel elaboration are enabled in <code>LeanREPLConfig</code>. External parallelization can be implemented in various ways, thus no default is provided.</p>"},{"location":"user-guide/performance/#incremental-elaboration","title":"Incremental Elaboration","text":"<p>Incremental elaboration is a free performance boost that reduces latency and memory by automatically reusing elaboration results from prior commands executed on the same <code>LeanServer</code>.</p>"},{"location":"user-guide/performance/#how-it-works","title":"How it works","text":"<p>In Lean, incremental elaboration allows reusing the elaboration state of a prior command when elaborating a new command that shares a common prefix. For example, if you have already elaborated:</p> <pre><code>import Mathlib\ndef foo : Nat := 42\n</code></pre> <p>and now want to elaborate:</p> <pre><code>import Mathlib\ndef bar : Nat := 56\n</code></pre> <p>then Lean can reuse the elaboration state after <code>import Mathlib</code> from the first command instead of starting from scratch, effectively loading Mathlib only once.</p> <p>Incremental elaboration therefore automatically finds the best incremental state from the previous command to reuse for the new command. For VS Code users, this corresponds to how Lean4's built-in language server reuses elaboration states when editing files (vertical orange loading bar in the gutter).</p> <p>LeanInteract generalizes this mechanism further by extending the search for the best incremental state to reuse to all prior commands in the history, not just the most recent one. The optimal incremental state is found using a Trie-based data structure, which in practice has no noticeable overhead in both memory and CPU usage.</p>"},{"location":"user-guide/performance/#properties","title":"Properties","text":"<ul> <li>Write commands in any order without manually worrying about managing command states.</li> <li>The Trie-based history lookup ensures that the best reuse point is found efficiently, independent of the number of prior commands.</li> <li>In the worst case, memory and CPU usage will be similar to non-incremental elaboration (if no reuse is possible).</li> <li>Particularly useful when checking batches of file edits or multiple similar commands.</li> </ul>"},{"location":"user-guide/performance/#how-to-use-it","title":"How to use it","text":"<ul> <li>Create your <code>LeanREPLConfig</code> with default settings (or ensure <code>enable_incremental_optimization=True</code>).</li> <li>Simply send commands to the same <code>LeanServer</code> instance as usual, incremental elaboration will be automatically applied.</li> <li>Recommendation: Instead of splitting your code into small chunks like in a REPL, you should send full commands or file contents. LeanInteract will find the best reuse points automatically.</li> </ul>"},{"location":"user-guide/performance/#example","title":"Example","text":"<p>Below is a small script that measures the elapsed time of two \"heavy\" commands, but the second command benefits from incremental reuse:</p> <pre><code>import time\nfrom lean_interact import LeanREPLConfig, LeanServer, Command\n\nserver = LeanServer(LeanREPLConfig())\n\nt1 = time.perf_counter()\nprint(server.run(Command(cmd=\"\"\"\ndef fib : Nat \u2192 Nat\n  | 0 =&gt; 0\n  | 1 =&gt; 1\n  | n + 2 =&gt; fib (n + 1) + fib n\n#eval fib 35\n\ntheorem foo : n = n := by rfl\n#check foo\n\"\"\")))\nprint(f\"First run:  {time.perf_counter() - t1:.3f}s\")\n\nt2 = time.perf_counter()\nprint(server.run(Command(cmd=\"\"\"\ndef fib : Nat \u2192 Nat\n  | 0 =&gt; 0\n  | 1 =&gt; 1\n  | n + 2 =&gt; fib (n + 1) + fib n\n#eval fib 35\n\ntheorem foo2 : n = n+0 := by rfl\n#check foo2\n\"\"\")))\nprint(f\"Second run: {time.perf_counter() - t2:.3f}s\")\n</code></pre> <pre><code>CommandResponse(env=0, messages=[Message(start_pos=Pos(column=0, line=6), data='9227465', end_pos=Pos(column=5, line=6), severity='info'), Message(start_pos=Pos(column=0, line=9), data='foo.{u_1} {\u03b1\u271d : Sort u_1} {n : \u03b1\u271d} : n = n', end_pos=Pos(column=6, line=9), severity='info')])\nFirst run:  8.114s\nCommandResponse(env=1, messages=[Message(start_pos=Pos(column=0, line=6), data='9227465', end_pos=Pos(column=5, line=6), severity='info'), Message(start_pos=Pos(column=0, line=9), data='foo2 {n : Nat} : n = n + 0', end_pos=Pos(column=6, line=9), severity='info')])\nSecond run: 0.007s\n</code></pre> <p>Warning</p> <p>Imports are cached in incremental mode, meaning that if the content of one of your imported file has changed, it will not be taken into account unless you restart the server.</p> <p>You can disable this feature by setting <code>enable_incremental_optimization=False</code> in <code>LeanREPLConfig</code>.</p>"},{"location":"user-guide/performance/#parallel-elaboration","title":"Parallel Elaboration","text":"<p>When supported (Lean &gt;= v4.19.0), Lean can elaborate different parts of a command/file in parallel. LeanInteract auto-enables this by adding <code>set_option Elab.async true</code> to each request. You can disable it if needed by setting <code>enable_parallel_elaboration=False</code> in <code>LeanREPLConfig</code>.</p> <p>Note</p> <p>Only available for Lean &gt;= v4.19.0</p>"},{"location":"user-guide/performance/#parallelization-guide-multiple-commands","title":"Parallelization Guide (multiple commands)","text":"<p>LeanInteract is designed with parallelization in mind, allowing you to leverage multiple CPU cores for parallel theorem proving and verification tasks.</p> <p>This section focuses on external parallelization: running multiple Lean servers (usually via <code>AutoLeanServer</code>) in parallel threads, processes or workers. This is complementary to the within-command optimizations above and can be combined with them.</p> <p>We recommend using <code>AutoLeanServer</code>. It is specifically designed for parallel environments with automated restart on fatal Lean errors, timeouts, and when memory limits are reached. On automated restarts, only commands run with <code>add_to_session_cache=True</code> (attribute of the <code>AutoLeanServer.run</code> method) will be preserved.</p> <p><code>AutoLeanServer</code> is still experimental, feedback and issues are welcome.</p>"},{"location":"user-guide/performance/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Always pre-instantiate <code>LeanREPLConfig</code> before parallelization</li> <li>One lean server per process/thread</li> <li>Use <code>AutoLeanServer</code></li> <li>Configure memory limits to prevent system overload</li> <li>Set appropriate timeouts for long-running operations</li> <li>Use session caching to keep context between requests</li> <li>Consider using <code>maxtasksperchild</code> to limit memory accumulation</li> </ol>"},{"location":"user-guide/performance/#quick-start","title":"Quick Start","text":"<pre><code>from multiprocessing import Pool\nfrom lean_interact import AutoLeanServer, Command, LeanREPLConfig\nfrom lean_interact.interface import LeanError\n\ndef worker(config: LeanREPLConfig, task_id: int):\n    \"\"\"Worker function that runs in each process\"\"\"\n    server = AutoLeanServer(config)\n    result = server.run(Command(cmd=f\"#eval {task_id} * {task_id}\"))\n    return f\"Task {task_id}: {result.messages[0].data if not isinstance(result, LeanError) else 'Error'}\"\n\n# Pre-instantiate config before parallelization (downloads/initializes resources)\nconfig = LeanREPLConfig(verbose=True)\nwith Pool() as p:\n    print(p.starmap(worker, [(config, i) for i in range(5)]))\n</code></pre> <p>For more examples, check the examples directory.</p>"},{"location":"user-guide/performance/#core-principles","title":"Core Principles","text":""},{"location":"user-guide/performance/#1-pre-instantiate-configuration","title":"1. Pre-instantiate Configuration","text":"<p>Always create your <code>LeanREPLConfig</code> instance before starting parallelization:</p> <pre><code>from lean_interact import LeanREPLConfig, AutoLeanServer\nimport multiprocessing as mp\n\n# \u2705 CORRECT: Config created in main process\nconfig = LeanREPLConfig()  # Pre-setup in main process\n\ndef worker(cfg):\n    server = AutoLeanServer(cfg)  # Use pre-configured config\n    # ... your work here\n    pass\n\nctx = mp.get_context(\"spawn\")\nwith ctx.Pool() as pool:\n    pool.map(worker, [config] * 4)\n\n# \u274c INCORRECT: Config created in each process\ndef worker():\n    config = LeanREPLConfig()\n    server = AutoLeanServer(config)\n    # ... your work here\n    pass\n\nctx = mp.get_context(\"spawn\")\nwith ctx.Pool() as pool:\n    pool.map(worker, range(4))\n</code></pre>"},{"location":"user-guide/performance/#2-one-server-per-processthread","title":"2. One Server Per Process/Thread","text":"<p>Each process or thread should have its own <code>LeanServer</code> or <code>AutoLeanServer</code> instance.</p> <pre><code>def worker(config, task_data):\n    # Each process gets its own server\n    server = AutoLeanServer(config)\n\n    for task in task_data:\n        result = server.run(task)\n        # Handle result\n\n    return results\n</code></pre>"},{"location":"user-guide/performance/#thread-safety","title":"Thread Safety","text":"<p>Within a single process, <code>LeanServer</code> and <code>AutoLeanServer</code> are thread-safe thanks to internal locking. All concurrent requests are processed sequentially. Across processes, servers are not shareable: each process must create its own instance.</p> <p>Similarly, <code>ReplaySessionCache</code> is thread-safe within a process, meaning multiple <code>AutoLeanServer</code> in different threads can safely share the same cache instance. However, across processes, each must have its own cache instance.</p>"},{"location":"user-guide/performance/#memory-management","title":"Memory Management","text":"<pre><code>from lean_interact import AutoLeanServer, LeanREPLConfig\n\n# Configure memory limits for multi-process safety\nconfig = LeanREPLConfig(memory_hard_limit_mb=8192)  # 8GB per server, works on Linux only\n\nserver = AutoLeanServer(\n    config,\n    max_total_memory=0.8,      # Restart when system uses &gt;80% memory\n    max_process_memory=0.8,    # Restart when process uses &gt;80% of memory limit\n    max_restart_attempts=5     # Allow up to 5 restart attempts per command\n)\n</code></pre>"},{"location":"user-guide/performance/#memory-configuration-options","title":"Memory Configuration Options","text":"<ul> <li><code>max_total_memory</code>: System-wide memory threshold (0.0-1.0)</li> <li><code>max_process_memory</code>: Per-process memory threshold (0.0-1.0)</li> <li><code>memory_hard_limit_mb</code>: Hard memory limit in MB (Linux only)</li> <li><code>max_restart_attempts</code>: Maximum consecutive restart attempts</li> </ul>"},{"location":"user-guide/set-options/","title":"Set Lean Options from Python (<code>set_option</code>)","text":"<p>You can pass Lean options per request using the <code>setOptions</code> field on <code>Command</code> and <code>FileCommand</code>. This mirrors Lean\u2019s <code>set_option</code> commands and lets you customize elaboration or pretty-printing on a per-request basis.</p>"},{"location":"user-guide/set-options/#shape","title":"Shape","text":"<ul> <li><code>setOptions</code> is a list of pairs <code>(Name, DataValue)</code></li> <li><code>Name</code> is a list of components, e.g. <code>[\"pp\", \"unicode\"]</code></li> <li><code>DataValue</code> can be <code>bool | int | str | Name</code></li> </ul> <p>Example:</p> <pre><code>from lean_interact import Command, LeanServer, LeanREPLConfig\n\nserver = LeanServer(LeanREPLConfig())\nprint(server.run(Command(\n    cmd=\"variable (n : Nat)\\n#check n+0=n\",\n    setOptions=[([\"pp\", \"raw\"], True)],\n)))\n</code></pre> <pre><code>CommandResponse(env=0, messages=[Message(start_pos=Pos(column=0, line=2), data='Eq.{1} Nat (HAdd.hAdd.{0, 0, 0} Nat Nat Nat (instHAdd.{0} Nat instAddNat) _uniq.4 (OfNat.ofNat.{0} Nat 0 (instOfNatNat 0))) _uniq.4 : Prop', end_pos=Pos(column=6, line=2), severity='info')])\n</code></pre> <p>LeanInteract will also merge your <code>setOptions</code> with its own defaults when enabled (e.g., it may add <code>([\"Elab\",\"async\"], True)</code> to enable parallel elaboration). Your explicitly provided options are appended and forwarded with the request.</p> <p>Note</p> <p>Options apply only to the single request you send; pass them again for subsequent calls</p>"},{"location":"user-guide/tactic-mode/","title":"Tactic Mode","text":"<p>Tactic mode in LeanInteract allows you to work with Lean's proof tactics step-by-step, providing an interactive way to develop and explore proofs.</p> <p>Experimental Feature</p> <p>The tactic mode feature is experimental may not work as expected in all situations. Some valid proofs might be incorrectly rejected.</p>"},{"location":"user-guide/tactic-mode/#getting-started-with-tactics","title":"Getting Started with Tactics","text":"<p>Using tactics in LeanInteract involves two main steps:</p> <ol> <li>Creating a proof state using <code>sorry</code> in a theorem</li> <li>Applying tactics to this proof state using <code>ProofStep</code></li> </ol>"},{"location":"user-guide/tactic-mode/#creating-a-proof-state","title":"Creating a Proof State","text":"<p>First, let's create a proof state by defining a theorem with <code>sorry</code>:</p> <pre><code>from lean_interact import LeanREPLConfig, LeanServer, Command\n\nserver = LeanServer(LeanREPLConfig())\n\n# Define a theorem with sorry\nresponse = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := by sorry\"))\nprint(response.sorries[0])\n</code></pre> <pre><code>Sorry(proof_state=0, start_pos=Pos(column=43, line=1), end_pos=Pos(column=48, line=1), goal='n : Nat\\n\u22a2 n = 5 \u2192 n = 5')\n</code></pre> <p>This response contains a <code>Sorry</code> object that includes:</p> <ul> <li>A <code>proof_state</code> ID that you can use for tactic commands</li> <li>The current goal that needs to be proven</li> </ul>"},{"location":"user-guide/tactic-mode/#applying-tactics","title":"Applying Tactics","text":"<p>Once you have a proof state, you can apply tactics using the <code>ProofStep</code> class:</p> <pre><code>from lean_interact import ProofStep\n\n# Define a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply a single tactic (intro) to the proof state\nprint(server.run(ProofStep(tactic=\"intro h\", proof_state=proof_state_id)))\n</code></pre> <pre><code>ProofStepResponse(goals=['n : Nat\\nh : n = 5\\n\u22a2 n = 5'], proof_status='Incomplete: open goals remain', proof_state=2)\n</code></pre> <p>The response contains:</p> <ul> <li>A new proof state ID for chaining additional tactics</li> <li>The current goal(s)</li> <li>The proof status (complete or incomplete)</li> </ul>"},{"location":"user-guide/tactic-mode/#chaining-tactics","title":"Chaining Tactics","text":"<p>You can chain multiple tactics by using the proof state from each response:</p> <pre><code>from lean_interact import ProofStep\n\n# Define a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem ex (n : Nat) : n = 5 \u2192 n = 5 := sorry\"))\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply 'intro' tactic\nintro_response = server.run(ProofStep(tactic=\"intro h\", proof_state=proof_state_id))\n\n# Apply 'exact' tactic to the resulting proof state\nprint(server.run(ProofStep(tactic=\"exact h\", proof_state=intro_response.proof_state)))\n</code></pre> <pre><code>ProofStepResponse(goals=[], proof_status='Completed', proof_state=5)\n</code></pre>"},{"location":"user-guide/tactic-mode/#applying-multiple-tactics-at-once","title":"Applying Multiple Tactics at Once","text":"<p>You can also apply multiple tactics at once by wrapping them in parentheses:</p> <pre><code># Apply multiple tactics at once\nmulti_response = server.run(ProofStep(tactic=\"\"\"(\nintro h\nexact h\n)\"\"\", proof_state=proof_state_id))\nprint(multi_response)\n</code></pre> <pre><code>ProofStepResponse(goals=[], proof_status='Completed', proof_state=6)\n</code></pre>"},{"location":"user-guide/tactic-mode/#complete-proof-session","title":"Complete Proof Session","text":"<p>The <code>ProofStepResponse</code> contains a <code>proof_status</code> field that indicates whether the proof is complete. Here's a complete example of working with tactics:</p> <pre><code># Create a theorem with sorry\ntheorem_response = server.run(Command(cmd=\"theorem my_theorem (x : Nat) : x = x := sorry\"))\nprint(\"Initial goal:\", theorem_response.sorries[0].goal)\n\n# Get the proof state from the sorry\nproof_state_id = theorem_response.sorries[0].proof_state\n\n# Apply reflexivity tactic\nfinal_response = server.run(ProofStep(tactic=\"rfl\", proof_state=proof_state_id))\n\n# Check if the proof is complete\nif final_response.proof_status == \"Completed\":\n    print(\"Proof completed successfully!\")\nelse:\n    print(\"Proof failed:\", final_response)\n</code></pre> <pre><code>Initial goal: x : Nat\n\u22a2 x = x\nProof completed successfully!\n</code></pre>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting","text":"<p>This guide covers common issues you might encounter when using LeanInteract.</p>"},{"location":"user-guide/troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"user-guide/troubleshooting/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Symptoms:</p> <ul> <li>The application crashes with memory-related errors</li> <li>Python process is killed by the operating system</li> <li>Error messages mentioning \"MemoryError\" or \"Killed\"</li> </ul> <p>Solutions:</p> <ul> <li>Reduce parallel processing or increase system memory</li> <li>Limit the maximum amount of memory usage allocated to the REPL with <code>LeanREPLConfig</code>:</li> </ul> <pre><code>from lean_interact import AutoLeanServer, LeanREPLConfig\nserver = AutoLeanServer(LeanREPLConfig(memory_hard_limit_mb=8192)) # Limit to 8GB\n</code></pre> <ul> <li>If you are working with large files or complex proofs in a single session, consider breaking them into smaller, more manageable pieces.</li> </ul>"},{"location":"user-guide/troubleshooting/#timeout-errors","title":"Timeout Errors","text":"<p>Symptoms:</p> <ul> <li>Commands take too long to execute</li> <li>Error messages mentioning \"TimeoutError\"</li> </ul> <p>Solutions:</p> <ul> <li>Pass a higher timeout to <code>run()</code>/<code>async_run()</code>:</li> </ul> <pre><code>server = AutoLeanServer(LeanREPLConfig())\nresult = server.run(Command(cmd=\"...\"), timeout=60)\n</code></pre> <ul> <li>Use <code>AutoLeanServer</code> for automatic recovery from timeouts:</li> </ul> <pre><code>server = AutoLeanServer(config)\n</code></pre> <ul> <li>Break complex commands into smaller, more manageable pieces</li> </ul>"},{"location":"user-guide/troubleshooting/#long-waiting-times-during-first-run","title":"Long Waiting Times During First Run","text":"<p>Symptoms:</p> <ul> <li>Initial setup takes a long time</li> <li>Process seems stuck at \"Downloading\" or \"Building\"</li> </ul> <p>Solution: This is expected behavior as LeanInteract:</p> <ol> <li>Downloads and sets up the specified Lean version</li> <li>Downloads and builds Lean REPL</li> <li>If using Mathlib, downloads it and instantiates a project using it (which is resource-intensive)</li> </ol> <p>Subsequent runs will be much faster due to caching.</p>"},{"location":"user-guide/troubleshooting/#lake-update-errors","title":"Lake Update Errors","text":"<p>Symptoms:</p> <ul> <li>Error: <code>Failed during Lean project setup: Command '['lake', 'update']' returned non-zero exit status 1.</code></li> </ul> <p>Solutions:</p> <ul> <li>Update your <code>elan</code> version (should be at least 4.0.0):</li> </ul> <pre><code>elan self update\n</code></pre> <ul> <li>Check your project's lake file for errors</li> <li>Ensure Git is properly installed and can access required repositories</li> </ul>"},{"location":"user-guide/troubleshooting/#path-too-long-error-windows","title":"Path Too Long Error (Windows)","text":"<p>Symptoms:</p> <ul> <li>On Windows, errors related to path length limitations</li> <li>Git errors about paths exceeding 260 characters</li> </ul> <p>Solutions: Enable long paths in Windows 10/11:</p> <pre><code># Run in administrator PowerShell\nNew-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" -Name LongPathsEnabled -Value 1 -PropertyType DWord -Force\ngit config --system core.longpaths true\n</code></pre>"},{"location":"user-guide/troubleshooting/#cache-issues","title":"Cache Issues","text":"<p>Symptoms:</p> <ul> <li>Unexpected behavior after upgrading LeanInteract</li> <li>Errors about incompatible versions</li> </ul> <p>Solution: Clear the LeanInteract cache:</p> <pre><code>clear-lean-cache\n</code></pre>"},{"location":"user-guide/troubleshooting/#unexpected-lean-error-messages","title":"Unexpected Lean error messages","text":"<p>Symptom: LeanInteract returns error messages while the Lean code runs fine in VSCode.</p> <p>Solutions:</p> <ul> <li>Check you are using the same Lean version in both environments</li> <li>If you are creating a temporary project using LeanInteract, make sure your dependencies are correctly set and compatible with the Lean version you are using</li> <li> <p>A frequent issue is forgetting to include <code>mathlib</code> in the dependencies:</p> <pre><code>config = LeanREPLConfig(\n    project=TempRequireProject(lean_version=\"v4.19.0\", require=\"mathlib\")\n)\n</code></pre> </li> <li> <p>Check if a similar issue for the Lean REPL has been reported</p> </li> </ul>"},{"location":"user-guide/troubleshooting/#elan-is-not-recognized-as-an-internal-or-external-command","title":"\"'elan' is not recognized as an internal or external command\"","text":"<p>Symptom: Error when running LeanInteract on a new system</p> <p>Solution: Install Lean's version manager:</p> <pre><code>install-lean\n</code></pre>"},{"location":"user-guide/troubleshooting/#getting-additional-help","title":"Getting Additional Help","text":"<p>If you encounter issues not covered in this guide:</p> <ol> <li>Check the GitHub repository for open issues</li> <li>Open a new issue with:<ul> <li>A minimal reproducible example</li> <li>Your operating system and Python version</li> <li>LeanInteract version (<code>pip show lean-interact</code>)</li> <li>Complete error message/stack trace</li> </ul> </li> </ol>"}]}